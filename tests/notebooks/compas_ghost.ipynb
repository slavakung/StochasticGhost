{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from scipy.optimize import linprog\n",
    "from qpsolvers import solve_qp\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "#import StochasticGhost\n",
    "import importlib\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import StochasticGhost\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151731/802406756.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['race_code'] = df_needed['race'].map(race_mapping)\n"
     ]
    }
   ],
   "source": [
    "SENSITIVE_CODE_1 = 1\n",
    "SENSITIVE_CODE_0 = 0\n",
    "\n",
    "raw_data = pd.read_csv(\"compas-scores-two-years.csv\")\n",
    "\n",
    "df = raw_data[['age', 'c_charge_degree', 'race', 'age_cat', 'score_text', 'sex', 'priors_count',\n",
    "               'days_b_screening_arrest', 'decile_score', 'is_recid', 'two_year_recid', 'c_jail_in', 'c_jail_out']]\n",
    "df = df[(df['days_b_screening_arrest'] <= 30) & (df['days_b_screening_arrest'] >= -30) &\n",
    "        (df['is_recid'] != -1) & (df['c_charge_degree'] != \"O\") & (df['score_text'] != 'N/A')]\n",
    "\n",
    "df['length_of_stay'] = pd.to_datetime(\n",
    "    df['c_jail_out']) - pd.to_datetime(df['c_jail_in'])\n",
    "df['length_of_stay'] = df['length_of_stay'].dt.total_seconds() / 3600\n",
    "\n",
    "df_needed = df[(df['race'] == 'Caucasian') | (df['race'] == 'African-American')]\n",
    "race_mapping = {'African-American': SENSITIVE_CODE_1, 'Caucasian': SENSITIVE_CODE_0}\n",
    "\n",
    "# Create a new column 'race_code' based on the mapping\n",
    "df_needed['race_code'] = df_needed['race'].map(race_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_151731/1847072954.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['crime_code'] = pd.Categorical(df_needed['c_charge_degree']).codes\n",
      "/tmp/ipykernel_151731/1847072954.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['age_code'] = pd.Categorical(df_needed['age_cat']).codes\n",
      "/tmp/ipykernel_151731/1847072954.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['race_code'] = df_needed['race'].map(race_mapping)\n",
      "/tmp/ipykernel_151731/1847072954.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['gender_code'] = pd.Categorical(df_needed['sex']).codes\n",
      "/tmp/ipykernel_151731/1847072954.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['score_code'] = pd.Categorical(df_needed['score_text']).codes\n",
      "/tmp/ipykernel_151731/1847072954.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_needed['charge_degree_code'] = pd.Categorical(\n"
     ]
    }
   ],
   "source": [
    "# Categorizing\n",
    "df_needed['crime_code'] = pd.Categorical(df_needed['c_charge_degree']).codes\n",
    "df_needed['age_code'] = pd.Categorical(df_needed['age_cat']).codes\n",
    "df_needed['race_code'] = df_needed['race'].map(race_mapping)\n",
    "df_needed['gender_code'] = pd.Categorical(df_needed['sex']).codes\n",
    "df_needed['score_code'] = pd.Categorical(df_needed['score_text']).codes\n",
    "df_needed['charge_degree_code'] = pd.Categorical(\n",
    "    df_needed['c_charge_degree']).codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_cols = ['priors_count', 'score_code', 'age_code', 'gender_code', 'race_code', 'crime_code', 'charge_degree_code']\n",
    "out_cols = ['two_year_recid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_df = df_needed[in_cols]\n",
    "out_df = df_needed[out_cols]\n",
    "\n",
    "RACE_IND = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514 1281\n"
     ]
    }
   ],
   "source": [
    "blacks_in = len(df_needed[(df_needed['race_code'] == SENSITIVE_CODE_1) & (df_needed['two_year_recid']== 0)])\n",
    "whites_in = len(df_needed[(df_needed['race_code'] == SENSITIVE_CODE_0) & (df_needed['two_year_recid'] == 0)])\n",
    "print(blacks_in, whites_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RACE_IND = 4\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(in_df.values, out_df.values, test_size  = 0.30)\n",
    "\n",
    "# Normalization\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "# Fitting only on training data\n",
    "scaler.fit(x_train)  \n",
    "X_train = scaler.transform(x_train)  \n",
    "\n",
    "# Applying same transformation to test data\n",
    "X_val = scaler.transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw and scaled data are saved as we need these for further analysis while selecting our final model in the model_selector file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming x_val and y_val are numpy arrays\n",
    "# Convert y_val to a column vector to match the shape of x_val\n",
    "#y_val = np.expand_dims(y_val, axis=1)\n",
    "\n",
    "# Concatenate x_val and y_val along the columns\n",
    "data_combined_raw = np.concatenate((x_val, y_val), axis=1)\n",
    "\n",
    "# Convert the combined data to a DataFrame\n",
    "df_combined = pd.DataFrame(data_combined_raw)\n",
    "\n",
    "x_val_columns = ['priors_count', 'score_code', 'age_code', 'gender_code', 'race_code', 'crime_code', 'charge_degree_code']\n",
    "y_val_columns = ['two_year_recid']\n",
    "\n",
    "df_combined.columns = x_val_columns + y_val_columns\n",
    "\n",
    "df_combined.to_csv('val_data_compas/val_data_raw_compas.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "data_combined_scaled = np.concatenate((X_val, y_val), axis=1)\n",
    "df_combined = pd.DataFrame(data_combined_scaled)\n",
    "df_combined.to_csv('val_data_compas/val_data_scaled_compas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective and constraints should be defined here.\n",
    "\n",
    "For this case the Constraint optimization problem looks like this:\n",
    "\n",
    "$$\\min\\hspace{0.1cm} \\{ \\text{MSE}(y_{\\text{pred}}-y_{\\text{true}}) \\} \\\\\n",
    "    \\text{s.t. } -\\epsilon < \\text{MSE}(y_{\\text{pred}|S=0} - y_{\\text{true}|S=0}) - \\text{MSE}(y_{\\text{pred}|S=1} - y_{\\text{true}|S=1}) < \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNetwork(nn.Module):\n",
    "\n",
    "    # For now the input data is passed as init parameters\n",
    "    def __init__(self, layer_sizes, itrain, otrain, ival, oval, itrain_raw):\n",
    "        super(CustomNetwork, self).__init__()\n",
    "\n",
    "        # Create a list of linear layers based on layer_sizes\n",
    "        self.itrain = itrain\n",
    "        self.otrain = otrain\n",
    "        self.ival = ival\n",
    "        self.oval = oval\n",
    "        self.itrain_raw = itrain_raw\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layer_norms = nn.ModuleList()\n",
    "        self.RAND_INT = 0\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = torch.relu((layer(x)))\n",
    "        x = torch.sigmoid(self.layers[-1](x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "    ######Only this loss function is used here######\n",
    "    def compute_loss(self, Y, Y_hat):\n",
    "        L_sum = 0.5*torch.sum(torch.square(Y - Y_hat))\n",
    "\n",
    "        m = Y.shape[0]\n",
    "        # print(\"Y shape is: \", m)\n",
    "        L = (1./m) * L_sum\n",
    "\n",
    "        return L\n",
    "\n",
    "    def bce_loss(self, outputs, targets):\n",
    "        criterion = nn.BCELoss()\n",
    "        loss = criterion(outputs, targets)\n",
    "        if torch.isnan(loss).any():\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name)\n",
    "                print(param.data)\n",
    "        return loss\n",
    "\n",
    "    def obj_fun(self, params, minibatch):\n",
    "        model_parameters = list(self.parameters())\n",
    "        x = self.itrain\n",
    "        y = self.otrain\n",
    "        #x_blacks = x[:, ]\n",
    "        samples = np.random.choice(len(y), minibatch, replace=False)\n",
    "        for i in range(len(params)):\n",
    "            model_parameters[i].data = torch.Tensor(params[i])\n",
    "\n",
    "        #print(\"LOOKIE:\",x[samples, :])\n",
    "        obj_fwd = self.forward(x[samples, :]).flatten()\n",
    "        if torch.isnan(obj_fwd).any():\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name)\n",
    "                print(param.data)\n",
    "        #print(\"LOOKIE the predicted values: \",obj_fwd)\n",
    "        #print(obj_fwd.shape)\n",
    "        #print(\"LOOKIE the actual values: \",y[samples].flatten())\n",
    "        fval = self.compute_loss(obj_fwd, y[samples].flatten())\n",
    "        #print(\"Training loss is: \", fval)\n",
    "        return fval.item()\n",
    "\n",
    "    def obj_grad(self, params, minibatch):\n",
    "        fgrad = []\n",
    "        x = self.itrain\n",
    "        y = self.otrain\n",
    "        samples = np.random.choice(len(y), minibatch, replace=False)\n",
    "        obj_fwd = self.forward(x[samples, :]).flatten()\n",
    "        obj_loss = self.compute_loss(obj_fwd, y[samples].flatten())\n",
    "        obj_loss.backward()\n",
    "\n",
    "        #max_norm = 0.5\n",
    "        #clip_grad_norm_(self.parameters(), max_norm)\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                # Clone to avoid modifying the original tensor\n",
    "                fgrad.append(param.grad.data.clone().view(-1))\n",
    "\n",
    "        # Manually set gradients to zero\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.zero_()\n",
    "\n",
    "        fgrad = torch.cat(fgrad, dim=0)\n",
    "        return fgrad\n",
    "    \n",
    "    def constraint_loss(self, dist1, dist2):\n",
    "        sum = 0\n",
    "        for i in range(len(dist1)):\n",
    "            sum = sum + dist1[i]*torch.log(dist1[i]/dist2[i])\n",
    "        return sum\n",
    "    \n",
    "    def jensen_shannon_divergence(self, p, q):\n",
    "        m = 0.5 * (p + q)\n",
    "        kl_div_p_m = F.kl_div(p.log(), m, reduction='batchmean')\n",
    "        kl_div_q_m = F.kl_div(q.log(), m, reduction='batchmean')\n",
    "        return 0.5 * (kl_div_p_m + kl_div_q_m)\n",
    "\n",
    "    def get_cov(self, f_val, a):\n",
    "        #print(\"Calculating Cov:\")\n",
    "        #print(len(f_val))\n",
    "        #print(len(a))\n",
    "        a_avg = torch.mean(a)\n",
    "        sum = 0\n",
    "        for i in range(len(a)):\n",
    "           sum = sum + (a[i]-a_avg)*f_val[i]\n",
    "        #print(\"Covariance between Pred and race label is: \", sum**2)\n",
    "        return sum**2\n",
    "\n",
    "\n",
    "    def conf1(self, params, minibatch):\n",
    "        #print(\"Reached at function constraint\")\n",
    "        conf_val = None\n",
    "        x_train = self.itrain\n",
    "        y_train = self.otrain\n",
    "        x_train_raw = self.itrain_raw\n",
    "        x_blacks = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1), :]\n",
    "        y_blacks = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1)]\n",
    "        x_whites = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0), :]\n",
    "        y_whites = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0)]\n",
    "        \n",
    "        # print(\"Total no of whites with y=0=\", x_whites_0_lab.shape[0])\n",
    "        #self.RANDOM_SEED = np.random.randint(0,len(y_train))\n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        black_samples = np.random.choice(len(y_blacks), minibatch, replace=False)\n",
    "        #print(\"Black samples for conf are:\", black_samples )\n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        white_samples = np.random.choice(len(y_whites), minibatch, replace=False)\n",
    "        #print(\"White samples for conf are:\", white_samples )\n",
    "        #samples = np.random.choice(len(y_val), minibatch, replace=False)\n",
    "        #conf_val = self.forward(x_val[minibatch, :])\n",
    "        cons_fwd_black = self.forward(x_blacks[black_samples, :]).flatten()\n",
    "        cons_loss_black = self.compute_loss(cons_fwd_black, y_train[black_samples].flatten())\n",
    "\n",
    "        cons_fwd_white = self.forward(x_whites[white_samples, :]).flatten()\n",
    "        cons_loss_white = self.compute_loss(cons_fwd_white, y_train[white_samples].flatten())\n",
    "\n",
    "        cons_loss = (cons_loss_black - cons_loss_white)\n",
    "        #cons_loss = cons_loss_black\n",
    "        #print(\"Minibatch size is: \", minibatch)\n",
    "        #print(\"Avg Loss over black samples ConF1: \", cons_loss_black)\n",
    "        #print(\"Avg Loss over white samples ConF1: \", cons_loss_white)\n",
    "        #print(\"Validation loss ConF1: \", cons_loss)\n",
    "        return (cons_loss.item())\n",
    "    \n",
    "    def conJ1(self, params, minibatch):\n",
    "        #print(\"Reached at function constraint grad\")\n",
    "        cgrad = []\n",
    "        x_train = self.itrain\n",
    "        y_train = self.otrain\n",
    "        x_train_raw = self.itrain_raw\n",
    "        x_blacks = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1), :]\n",
    "        y_blacks = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1)]\n",
    "        x_whites = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0), :]\n",
    "        y_whites = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0)]\n",
    "        \n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        black_samples = np.random.choice(len(y_blacks), minibatch, replace=False)\n",
    "        #print(\"Black samples for conJ are:\", black_samples)\n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        white_samples = np.random.choice(len(y_whites), minibatch, replace=False)\n",
    "        #print(\"White samples for conJ are:\", white_samples)\n",
    "        # samples = np.random.choice(len(y_val), minibatch, replace=False)\n",
    "        # conf_val = self.forward(x_val[minibatch, :])\n",
    "        cons_fwd_black = self.forward(x_blacks[black_samples, :]).flatten()\n",
    "        cons_loss_black = self.compute_loss(cons_fwd_black, y_train[black_samples].flatten())\n",
    "\n",
    "        cons_fwd_white = self.forward(x_whites[white_samples, :]).flatten()\n",
    "        cons_loss_white = self.compute_loss(cons_fwd_white, y_train[white_samples].flatten())\n",
    "        #cons_loss = cons_loss_black\n",
    "        cons_loss = (cons_loss_black - cons_loss_white)\n",
    "        cons_loss.backward()\n",
    "        #max_norm = 0.5\n",
    "        #clip_grad_norm_(self.parameters(), max_norm)\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                cgrad.append(param.grad.data.clone().view(-1))  # Clone to avoid modifying the original tensor\n",
    "\n",
    "# Manually set gradients to zero without using optimizer.zero_grad()\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.zero_()\n",
    "\n",
    "        \n",
    "        cgrad = torch.cat(cgrad, dim=0)\n",
    "        \n",
    "        return cgrad\n",
    "    \n",
    "    def conf2(self, params, minibatch):\n",
    "        #print(\"Reached at function constraint\")\n",
    "        conf_val = None\n",
    "        x_train = self.itrain\n",
    "        y_train = self.otrain\n",
    "        x_train_raw = self.itrain_raw\n",
    "        x_blacks = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1), :]\n",
    "        y_blacks = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1)]\n",
    "        x_whites = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0), :]\n",
    "        y_whites = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0)]\n",
    "        \n",
    "        # print(\"Total no of whites with y=0=\", x_whites_0_lab.shape[0])\n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        black_samples = np.random.choice(len(y_blacks), minibatch, replace=False)\n",
    "        #print(\"Black samples for conf are:\", black_samples )\n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        white_samples = np.random.choice(len(y_whites), minibatch, replace=False)\n",
    "        #print(\"White samples for conf are:\", white_samples )\n",
    "        #samples = np.random.choice(len(y_val), minibatch, replace=False)\n",
    "        #conf_val = self.forward(x_val[minibatch, :])\n",
    "        cons_fwd_black = self.forward(x_blacks[black_samples, :]).flatten()\n",
    "        cons_loss_black = self.compute_loss(cons_fwd_black, y_train[black_samples].flatten())\n",
    "\n",
    "        cons_fwd_white = self.forward(x_whites[white_samples, :]).flatten()\n",
    "        cons_loss_white = self.compute_loss(cons_fwd_white, y_train[white_samples].flatten())\n",
    "\n",
    "        cons_loss = (cons_loss_white - cons_loss_black)\n",
    "        #cons_loss = cons_loss_black\n",
    "        #print(\"Minibatch size is: \", minibatch)\n",
    "        #print(\"Avg Loss over black samples ConF2: \", cons_loss_black)\n",
    "        #print(\"Avg Loss over white samples ConF2: \", cons_loss_white)\n",
    "        #print(\"Validation loss ConF2: \", cons_loss)\n",
    "        return (cons_loss.item())\n",
    "    \n",
    "    def conJ2(self, params, minibatch):\n",
    "        #print(\"Reached at function constraint grad\")\n",
    "        cgrad = []\n",
    "        x_train = self.itrain\n",
    "        y_train = self.otrain\n",
    "        x_train_raw = self.itrain_raw\n",
    "        x_blacks = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1), :]\n",
    "        y_blacks = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_1)]\n",
    "        x_whites = x_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0), :]\n",
    "        y_whites = y_train[(x_train_raw[:, RACE_IND] == SENSITIVE_CODE_0)]\n",
    "        \n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        black_samples = np.random.choice(len(y_blacks), minibatch, replace=False)\n",
    "        #print(\"Black samples for conJ are:\", black_samples)\n",
    "        #np.random.seed(self.RANDOM_SEED)\n",
    "        white_samples = np.random.choice(len(y_whites), minibatch, replace=False)\n",
    "        #print(\"White samples for conJ are:\", white_samples)\n",
    "        # samples = np.random.choice(len(y_val), minibatch, replace=False)\n",
    "        # conf_val = self.forward(x_val[minibatch, :])\n",
    "        cons_fwd_black = self.forward(x_blacks[black_samples, :]).flatten()\n",
    "        cons_loss_black = self.compute_loss(cons_fwd_black, y_train[black_samples].flatten())\n",
    "\n",
    "        cons_fwd_white = self.forward(x_whites[white_samples, :]).flatten()\n",
    "        cons_loss_white = self.compute_loss(cons_fwd_white, y_train[white_samples].flatten())\n",
    "        #cons_loss = cons_loss_black\n",
    "        cons_loss = (cons_loss_white - cons_loss_black)\n",
    "        cons_loss.backward()\n",
    "        #max_norm = 0.5\n",
    "        #clip_grad_norm_(self.parameters(), max_norm)\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                cgrad.append(param.grad.data.clone().view(-1))  # Clone to avoid modifying the original tensor\n",
    "\n",
    "# Manually set gradients to zero without using optimizer.zero_grad()\n",
    "        for param in self.parameters():\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.zero_()\n",
    "\n",
    "        \n",
    "        cgrad = torch.cat(cgrad, dim=0)\n",
    "        \n",
    "        return cgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramvals(maxiter, beta, rho, lamb, hess, tau, mbsz, numcon, geomp, stepdecay, gammazero, zeta, N, n, lossbound, scalef):\n",
    "    params = {\n",
    "        'maxiter': maxiter,  # number of iterations performed\n",
    "        'beta': beta,  # trust region size\n",
    "        'rho': rho,  # trust region for feasibility subproblem\n",
    "        'lamb': lamb,  # weight on the subfeasibility relaxation\n",
    "        'hess': hess,  # method of computing the Hessian of the QP, options include 'diag' 'lbfgs' 'fisher' 'adamdiag' 'adagraddiag'\n",
    "        'tau': tau,  # parameter for the hessian\n",
    "        'mbsz': mbsz,  # the standard minibatch size, used for evaluating the progress of the objective and constraint\n",
    "        'numcon': numcon,  # number of constraint functions\n",
    "        'geomp': geomp,  # parameter for the geometric random variable defining the number of subproblem samples\n",
    "        # strategy for step decrease, options include 'dimin' 'stepwise' 'slowdimin' 'constant'\n",
    "        'stepdecay': stepdecay,\n",
    "        'gammazero': gammazero,  # initial stepsize\n",
    "        'zeta': zeta,  # parameter associated with the stepsize iteration\n",
    "        'N': N,  # Train/val sample size\n",
    "        'n': n,  # Total number of parameters\n",
    "        'lossbound': lossbound, #Bound on constraint loss\n",
    "        'scalef': scalef #Scaling factor for constraints\n",
    "    }\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 0\n",
      ">>>>>step_norm<<<<<< 0.7303310554630663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/qpsolvers/conversions/ensure_sparse_matrices.py:24: UserWarning: Converted P to scipy.sparse.csc.csc_matrix\n",
      "For best performance, build P as a scipy.sparse.csc_matrix rather than as a numpy.ndarray\n",
      "  warnings.warn(\n",
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/qpsolvers/conversions/ensure_sparse_matrices.py:24: UserWarning: Converted G to scipy.sparse.csc.csc_matrix\n",
      "For best performance, build G as a scipy.sparse.csc_matrix rather than as a numpy.ndarray\n",
      "  warnings.warn(\n",
      "/home/choudhar/anaconda3/envs/ghost/lib/python3.10/site-packages/qpsolvers/conversions/ensure_sparse_matrices.py:24: UserWarning: Converted A to scipy.sparse.csc.csc_matrix\n",
      "For best performance, build A as a scipy.sparse.csc_matrix rather than as a numpy.ndarray\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>step_norm<<<<<< 0.8329974215531442\n",
      ">>>>>step_norm<<<<<< 0.785726243556084\n",
      ">>>>>step_norm<<<<<< 0.49646510294457774\n",
      ">>>>>step_norm<<<<<< 0.7783157999697996\n",
      ">>>>>step_norm<<<<<< 0.31169325839997053\n",
      ">>>>>step_norm<<<<<< 0.5778718173173709\n",
      ">>>>>step_norm<<<<<< 0.4327712025678982\n",
      ">>>>>step_norm<<<<<< 0.3418135524723525\n",
      ">>>>>step_norm<<<<<< 0.6289663575840778\n",
      ">>>>>step_norm<<<<<< 0.6021175666226288\n",
      ">>>>>step_norm<<<<<< 0.43176561798779806\n",
      ">>>>>step_norm<<<<<< 0.46721532102619967\n",
      ">>>>>step_norm<<<<<< 0.30140012845070446\n",
      ">>>>>step_norm<<<<<< 0.9831735158759498\n",
      ">>>>>step_norm<<<<<< 0.4387474873812935\n",
      ">>>>>step_norm<<<<<< 0.3418069348736852\n",
      ">>>>>step_norm<<<<<< 1.0175593053660696\n",
      ">>>>>step_norm<<<<<< 0.6656739068555212\n",
      ">>>>>step_norm<<<<<< 0.7005527339586529\n",
      ">>>>>step_norm<<<<<< 0.6087074336661966\n",
      ">>>>>step_norm<<<<<< 0.6341946574991676\n",
      ">>>>>step_norm<<<<<< 0.7082087734503858\n",
      ">>>>>step_norm<<<<<< 1.1394004910651578\n",
      ">>>>>step_norm<<<<<< 0.37851847997189514\n",
      ">>>>>step_norm<<<<<< 0.7285199769218168\n",
      ">>>>>step_norm<<<<<< 0.5361348722645188\n",
      ">>>>>step_norm<<<<<< 1.203756995572507\n",
      ">>>>>step_norm<<<<<< 0.7573748021439838\n",
      ">>>>>step_norm<<<<<< 0.7931691491377992\n",
      ">>>>>step_norm<<<<<< 0.9492029789616258\n",
      ">>>>>step_norm<<<<<< 1.1382130075698618\n",
      ">>>>>step_norm<<<<<< 0.4442437758792945\n",
      ">>>>>step_norm<<<<<< 0.4218900485545132\n",
      ">>>>>step_norm<<<<<< 0.7038638129939411\n",
      ">>>>>step_norm<<<<<< 0.5135348291873697\n",
      ">>>>>step_norm<<<<<< 0.4745298403494554\n",
      ">>>>>step_norm<<<<<< 0.47916541325421325\n",
      ">>>>>step_norm<<<<<< 0.5709292133154181\n",
      ">>>>>step_norm<<<<<< 1.3106037823027132\n",
      ">>>>>step_norm<<<<<< 0.874328508267772\n",
      ">>>>>step_norm<<<<<< 0.3747040199410451\n",
      ">>>>>step_norm<<<<<< 0.3965247869183612\n",
      ">>>>>step_norm<<<<<< 0.258008590254969\n",
      ">>>>>step_norm<<<<<< 0.5184364514225617\n",
      ">>>>>step_norm<<<<<< 0.6755240828676382\n",
      ">>>>>step_norm<<<<<< 1.1654980452904804\n",
      ">>>>>step_norm<<<<<< 0.23859048436196745\n",
      ">>>>>step_norm<<<<<< 0.6398259472391813\n",
      ">>>>>step_norm<<<<<< 0.5400121750089841\n",
      ">>>>>step_norm<<<<<< 0.922688010447474\n",
      ">>>>>step_norm<<<<<< 0.5876420641647689\n",
      ">>>>>step_norm<<<<<< 0.5207984929054719\n",
      ">>>>>step_norm<<<<<< 0.5252510787392946\n",
      ">>>>>step_norm<<<<<< 0.3763126390031017\n",
      ">>>>>step_norm<<<<<< 0.5175669837306892\n",
      ">>>>>step_norm<<<<<< 0.6308136943665824\n",
      ">>>>>step_norm<<<<<< 0.7419628775943045\n",
      ">>>>>step_norm<<<<<< 0.9532750419420415\n",
      ">>>>>step_norm<<<<<< 0.4413501848854462\n",
      ">>>>>step_norm<<<<<< 0.4343809765721417\n",
      ">>>>>step_norm<<<<<< 0.612169731808857\n",
      ">>>>>step_norm<<<<<< 0.444542792066783\n",
      ">>>>>step_norm<<<<<< 0.7590838156350402\n",
      ">>>>>step_norm<<<<<< 0.31619910893679193\n",
      ">>>>>step_norm<<<<<< 0.7580414663375897\n",
      ">>>>>step_norm<<<<<< 0.7294291769814342\n",
      ">>>>>step_norm<<<<<< 0.2211241097181439\n",
      ">>>>>step_norm<<<<<< 0.49323152747964205\n",
      ">>>>>step_norm<<<<<< 0.7966405031374263\n",
      ">>>>>step_norm<<<<<< 1.0551961144645503\n",
      ">>>>>step_norm<<<<<< 0.3793437490070689\n",
      ">>>>>step_norm<<<<<< 0.7637815670964683\n",
      ">>>>>step_norm<<<<<< 0.6077931838666989\n",
      ">>>>>step_norm<<<<<< 1.1678790025247119\n",
      ">>>>>step_norm<<<<<< 0.2868272054858085\n",
      ">>>>>step_norm<<<<<< 0.5155588587283088\n",
      ">>>>>step_norm<<<<<< 0.41637399265719804\n",
      ">>>>>step_norm<<<<<< 0.48393586646363257\n",
      ">>>>>step_norm<<<<<< 0.5373306600251402\n",
      ">>>>>step_norm<<<<<< 0.6638288253918022\n",
      ">>>>>step_norm<<<<<< 0.4759564297016138\n",
      ">>>>>step_norm<<<<<< 0.4362225654946262\n",
      ">>>>>step_norm<<<<<< 1.0520016395243066\n",
      ">>>>>step_norm<<<<<< 0.5120222885874561\n",
      ">>>>>step_norm<<<<<< 0.33281214842947376\n",
      ">>>>>step_norm<<<<<< 0.611279208403553\n",
      ">>>>>step_norm<<<<<< 0.6603664629538765\n",
      ">>>>>step_norm<<<<<< 0.4318460546778353\n",
      ">>>>>step_norm<<<<<< 0.951475820980754\n",
      ">>>>>step_norm<<<<<< 1.3774416527207813\n",
      ">>>>>step_norm<<<<<< 0.430605332862002\n",
      ">>>>>step_norm<<<<<< 0.7935819939783192\n",
      ">>>>>step_norm<<<<<< 0.5577347905078731\n",
      ">>>>>step_norm<<<<<< 0.5501233473983668\n",
      ">>>>>step_norm<<<<<< 0.7399992354265239\n",
      ">>>>>step_norm<<<<<< 0.7508245567955859\n",
      ">>>>>step_norm<<<<<< 1.220414771320301\n",
      ">>>>>step_norm<<<<<< 0.43211428049608064\n",
      ">>>>>step_norm<<<<<< 0.3626126291154725\n",
      ">>>>>step_norm<<<<<< 0.558612935258124\n",
      ">>>>>step_norm<<<<<< 0.3074934459898244\n",
      ">>>>>step_norm<<<<<< 0.5370588149557017\n",
      ">>>>>step_norm<<<<<< 0.8090557426314836\n",
      ">>>>>step_norm<<<<<< 0.5119212812737167\n",
      ">>>>>step_norm<<<<<< 0.5728186532699339\n",
      ">>>>>step_norm<<<<<< 0.2579940513514838\n",
      ">>>>>step_norm<<<<<< 1.02215210252926\n",
      ">>>>>step_norm<<<<<< 0.900968877810404\n",
      ">>>>>step_norm<<<<<< 0.2659708524520917\n",
      ">>>>>step_norm<<<<<< 1.2224401956544315\n",
      ">>>>>step_norm<<<<<< 0.3137878933793536\n",
      ">>>>>step_norm<<<<<< 0.7165533285685951\n",
      ">>>>>step_norm<<<<<< 0.3541580637275028\n",
      ">>>>>step_norm<<<<<< 0.41810228983563424\n",
      ">>>>>step_norm<<<<<< 0.9920929183902215\n",
      ">>>>>step_norm<<<<<< 0.5590878453751752\n",
      ">>>>>step_norm<<<<<< 1.3394381284767847\n",
      ">>>>>step_norm<<<<<< 1.424777026769844\n",
      ">>>>>step_norm<<<<<< 0.5714498820967243\n",
      ">>>>>step_norm<<<<<< 0.6715792790918401\n",
      ">>>>>step_norm<<<<<< 0.4859716273382581\n",
      ">>>>>step_norm<<<<<< 0.2400734104293615\n",
      ">>>>>step_norm<<<<<< 0.6906630266465941\n",
      ">>>>>step_norm<<<<<< 0.49807607014331184\n",
      ">>>>>step_norm<<<<<< 0.30896858637580127\n",
      ">>>>>step_norm<<<<<< 0.6447129593235745\n",
      ">>>>>step_norm<<<<<< 0.48542574586344306\n",
      ">>>>>step_norm<<<<<< 1.1429000217323517\n",
      ">>>>>step_norm<<<<<< 1.0841666920443038\n",
      ">>>>>step_norm<<<<<< 0.8020292886083961\n",
      ">>>>>step_norm<<<<<< 1.0356726782641914\n",
      ">>>>>step_norm<<<<<< 0.3775336201714089\n",
      ">>>>>step_norm<<<<<< 1.308716014162294\n",
      ">>>>>step_norm<<<<<< 0.8345223924682769\n",
      ">>>>>step_norm<<<<<< 0.518288007461459\n",
      ">>>>>step_norm<<<<<< 1.7473266009327821\n",
      ">>>>>step_norm<<<<<< 1.4203800502303205\n",
      ">>>>>step_norm<<<<<< 0.7154003806388146\n",
      ">>>>>step_norm<<<<<< 0.799132596331845\n",
      ">>>>>step_norm<<<<<< 0.7347708931645376\n",
      ">>>>>step_norm<<<<<< 1.0670711697237545\n",
      ">>>>>step_norm<<<<<< 0.670755444017096\n",
      ">>>>>step_norm<<<<<< 0.42256143023702236\n",
      ">>>>>step_norm<<<<<< 0.9281578648717029\n",
      ">>>>>step_norm<<<<<< 0.7657926581773266\n",
      ">>>>>step_norm<<<<<< 0.5265964378375553\n",
      ">>>>>step_norm<<<<<< 0.6228769221504038\n",
      ">>>>>step_norm<<<<<< 0.35797327760657155\n",
      ">>>>>step_norm<<<<<< 2.3650925960942484\n",
      ">>>>>step_norm<<<<<< 0.4534982176077685\n",
      ">>>>>step_norm<<<<<< 1.1205352885047457\n",
      ">>>>>step_norm<<<<<< 0.7254792329645229\n",
      ">>>>>step_norm<<<<<< 0.5920167213183715\n",
      ">>>>>step_norm<<<<<< 0.46725318583883013\n",
      ">>>>>step_norm<<<<<< 0.6508547721748564\n",
      ">>>>>step_norm<<<<<< 0.41502647996578573\n",
      ">>>>>step_norm<<<<<< 0.2783008410238981\n",
      ">>>>>step_norm<<<<<< 0.41956974072690606\n",
      ">>>>>step_norm<<<<<< 0.4311416610421402\n",
      ">>>>>step_norm<<<<<< 0.6579506625342272\n",
      ">>>>>step_norm<<<<<< 0.8103086564017131\n",
      ">>>>>step_norm<<<<<< 0.6459440840598444\n",
      ">>>>>step_norm<<<<<< 0.3633706919826116\n",
      ">>>>>step_norm<<<<<< 0.5744541480299457\n",
      ">>>>>step_norm<<<<<< 0.9121258404151549\n",
      ">>>>>step_norm<<<<<< 0.7596917760825774\n",
      ">>>>>step_norm<<<<<< 0.6197449129899107\n",
      ">>>>>step_norm<<<<<< 0.3871097438448875\n",
      ">>>>>step_norm<<<<<< 0.703414250730235\n",
      ">>>>>step_norm<<<<<< 0.7205419321425276\n",
      ">>>>>step_norm<<<<<< 1.1819196281254696\n",
      ">>>>>step_norm<<<<<< 0.8410034334963026\n",
      ">>>>>step_norm<<<<<< 1.0536313394694092\n",
      ">>>>>step_norm<<<<<< 0.37977522980499395\n",
      ">>>>>step_norm<<<<<< 0.2985947661449203\n",
      ">>>>>step_norm<<<<<< 0.3640577831188409\n",
      ">>>>>step_norm<<<<<< 0.5275518562615631\n",
      ">>>>>step_norm<<<<<< 0.1822214296183983\n",
      ">>>>>step_norm<<<<<< 0.909960599583164\n",
      ">>>>>step_norm<<<<<< 0.4591924485776648\n",
      ">>>>>step_norm<<<<<< 0.5241001280648467\n",
      ">>>>>step_norm<<<<<< 0.3094601404460348\n",
      ">>>>>step_norm<<<<<< 0.7866312526664985\n",
      ">>>>>step_norm<<<<<< 0.4761936020188695\n",
      ">>>>>step_norm<<<<<< 0.6898109390570216\n",
      ">>>>>step_norm<<<<<< 0.7005328919889212\n",
      ">>>>>step_norm<<<<<< 0.7321507879207027\n",
      ">>>>>step_norm<<<<<< 0.3114320031264622\n",
      ">>>>>step_norm<<<<<< 0.6005138115380385\n",
      ">>>>>step_norm<<<<<< 0.5894116604304229\n",
      ">>>>>step_norm<<<<<< 0.7584209584349085\n",
      ">>>>>step_norm<<<<<< 0.32286838203845086\n",
      ">>>>>step_norm<<<<<< 0.6151862886079601\n",
      ">>>>>step_norm<<<<<< 0.48682910115975514\n",
      ">>>>>step_norm<<<<<< 0.8700055589259365\n",
      ">>>>>step_norm<<<<<< 1.1844002343576299\n",
      ">>>>>step_norm<<<<<< 0.31521196218715747\n",
      ">>>>>step_norm<<<<<< 0.6434578187819774\n",
      ">>>>>step_norm<<<<<< 0.36009917348513953\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 1\n",
      ">>>>>step_norm<<<<<< 0.49325595181011495\n",
      ">>>>>step_norm<<<<<< 0.8965543273399088\n",
      ">>>>>step_norm<<<<<< 1.6446099102584475\n",
      ">>>>>step_norm<<<<<< 0.3295214738041158\n",
      ">>>>>step_norm<<<<<< 0.8079748958088698\n",
      ">>>>>step_norm<<<<<< 1.53548074457327\n",
      ">>>>>step_norm<<<<<< 1.085400467595531\n",
      ">>>>>step_norm<<<<<< 0.5370699719085275\n",
      ">>>>>step_norm<<<<<< 0.521791219465507\n",
      ">>>>>step_norm<<<<<< 0.4463215744493429\n",
      ">>>>>step_norm<<<<<< 1.348599009051561\n",
      ">>>>>step_norm<<<<<< 0.37122266689600164\n",
      ">>>>>step_norm<<<<<< 0.6135474290944882\n",
      ">>>>>step_norm<<<<<< 0.43708264840966626\n",
      ">>>>>step_norm<<<<<< 0.35537065858276945\n",
      ">>>>>step_norm<<<<<< 0.48820755065447147\n",
      ">>>>>step_norm<<<<<< 0.1662112929990447\n",
      ">>>>>step_norm<<<<<< 0.38258093906214985\n",
      ">>>>>step_norm<<<<<< 0.3476510089089644\n",
      ">>>>>step_norm<<<<<< 0.7433114130913969\n",
      ">>>>>step_norm<<<<<< 0.3793049358556935\n",
      ">>>>>step_norm<<<<<< 0.7379507842390896\n",
      ">>>>>step_norm<<<<<< 0.5601941589727506\n",
      ">>>>>step_norm<<<<<< 0.5960294147841052\n",
      ">>>>>step_norm<<<<<< 0.5391434958665354\n",
      ">>>>>step_norm<<<<<< 0.6034704582143204\n",
      ">>>>>step_norm<<<<<< 0.6366442028756666\n",
      ">>>>>step_norm<<<<<< 0.394917275856617\n",
      ">>>>>step_norm<<<<<< 0.26790008539973476\n",
      ">>>>>step_norm<<<<<< 0.5585713338162893\n",
      ">>>>>step_norm<<<<<< 0.30683862969714387\n",
      ">>>>>step_norm<<<<<< 0.32387022488280826\n",
      ">>>>>step_norm<<<<<< 0.298775434680905\n",
      ">>>>>step_norm<<<<<< 0.4816582352568378\n",
      ">>>>>step_norm<<<<<< 0.5638781550184399\n",
      ">>>>>step_norm<<<<<< 0.7521437605711376\n",
      ">>>>>step_norm<<<<<< 0.9193136661001202\n",
      ">>>>>step_norm<<<<<< 0.7554813162677533\n",
      ">>>>>step_norm<<<<<< 0.800744354044163\n",
      ">>>>>step_norm<<<<<< 0.2228118033062611\n",
      ">>>>>step_norm<<<<<< 0.6344133594716408\n",
      ">>>>>step_norm<<<<<< 0.9223053587079062\n",
      ">>>>>step_norm<<<<<< 0.16426336574438644\n",
      ">>>>>step_norm<<<<<< 0.35968652644006444\n",
      ">>>>>step_norm<<<<<< 0.36281221355684046\n",
      ">>>>>step_norm<<<<<< 0.8147220393832169\n",
      ">>>>>step_norm<<<<<< 0.4957726444154198\n",
      ">>>>>step_norm<<<<<< 0.8035984424414039\n",
      ">>>>>step_norm<<<<<< 0.4786345726907856\n",
      ">>>>>step_norm<<<<<< 0.2537553016930178\n",
      ">>>>>step_norm<<<<<< 0.2575633160439643\n",
      ">>>>>step_norm<<<<<< 1.0010548784071742\n",
      ">>>>>step_norm<<<<<< 1.2063246591253132\n",
      ">>>>>step_norm<<<<<< 0.316973186274541\n",
      ">>>>>step_norm<<<<<< 0.44457402138191887\n",
      ">>>>>step_norm<<<<<< 0.5014998250534265\n",
      ">>>>>step_norm<<<<<< 1.0045134947697594\n",
      ">>>>>step_norm<<<<<< 0.5919449380271811\n",
      ">>>>>step_norm<<<<<< 0.7706772023679436\n",
      ">>>>>step_norm<<<<<< 0.6976136517264399\n",
      ">>>>>step_norm<<<<<< 0.5245720888553539\n",
      ">>>>>step_norm<<<<<< 0.3754287453708687\n",
      ">>>>>step_norm<<<<<< 0.22918676337563232\n",
      ">>>>>step_norm<<<<<< 0.23495039471153148\n",
      ">>>>>step_norm<<<<<< 0.32796726696636036\n",
      ">>>>>step_norm<<<<<< 0.5169317412379517\n",
      ">>>>>step_norm<<<<<< 0.25439343186950225\n",
      ">>>>>step_norm<<<<<< 0.7229815760461263\n",
      ">>>>>step_norm<<<<<< 0.3326585552240031\n",
      ">>>>>step_norm<<<<<< 1.2774236261631196\n",
      ">>>>>step_norm<<<<<< 0.23900810889403007\n",
      ">>>>>step_norm<<<<<< 0.5838019771946814\n",
      ">>>>>step_norm<<<<<< 0.4878191502261193\n",
      ">>>>>step_norm<<<<<< 0.3328140814340668\n",
      ">>>>>step_norm<<<<<< 0.6077029151462355\n",
      ">>>>>step_norm<<<<<< 0.25344696598433036\n",
      ">>>>>step_norm<<<<<< 1.1082796390108869\n",
      ">>>>>step_norm<<<<<< 0.3892133650896059\n",
      ">>>>>step_norm<<<<<< 0.4862245719025024\n",
      ">>>>>step_norm<<<<<< 0.8620330718247814\n",
      ">>>>>step_norm<<<<<< 0.16295904142421067\n",
      ">>>>>step_norm<<<<<< 0.5637878196071057\n",
      ">>>>>step_norm<<<<<< 0.3466947203399662\n",
      ">>>>>step_norm<<<<<< 0.5337220009096121\n",
      ">>>>>step_norm<<<<<< 0.4985052603701756\n",
      ">>>>>step_norm<<<<<< 0.7470936672801078\n",
      ">>>>>step_norm<<<<<< 0.434393229802836\n",
      ">>>>>step_norm<<<<<< 0.3588695983831524\n",
      ">>>>>step_norm<<<<<< 0.209276433418184\n",
      ">>>>>step_norm<<<<<< 0.6788180683217825\n",
      ">>>>>step_norm<<<<<< 0.9165485821201391\n",
      ">>>>>step_norm<<<<<< 1.7072452252432113\n",
      ">>>>>step_norm<<<<<< 1.162410362265599\n",
      ">>>>>step_norm<<<<<< 1.061124613315607\n",
      ">>>>>step_norm<<<<<< 0.3626909156909642\n",
      ">>>>>step_norm<<<<<< 0.8955868532764794\n",
      ">>>>>step_norm<<<<<< 0.541278599413203\n",
      ">>>>>step_norm<<<<<< 0.2642063704886006\n",
      ">>>>>step_norm<<<<<< 0.3883292988898445\n",
      ">>>>>step_norm<<<<<< 0.2159910976046575\n",
      ">>>>>step_norm<<<<<< 0.5542616836496704\n",
      ">>>>>step_norm<<<<<< 0.9737133257947073\n",
      ">>>>>step_norm<<<<<< 0.77021079665894\n",
      ">>>>>step_norm<<<<<< 0.8974233793211497\n",
      ">>>>>step_norm<<<<<< 0.4414179316715015\n",
      ">>>>>step_norm<<<<<< 0.4006755719880761\n",
      ">>>>>step_norm<<<<<< 0.5412204440365465\n",
      ">>>>>step_norm<<<<<< 0.5623855387050632\n",
      ">>>>>step_norm<<<<<< 0.86426251372314\n",
      ">>>>>step_norm<<<<<< 0.9991183460788845\n",
      ">>>>>step_norm<<<<<< 0.4556909084573309\n",
      ">>>>>step_norm<<<<<< 0.6514201705363846\n",
      ">>>>>step_norm<<<<<< 0.40716034083318065\n",
      ">>>>>step_norm<<<<<< 0.6425486622478493\n",
      ">>>>>step_norm<<<<<< 0.9358051060193552\n",
      ">>>>>step_norm<<<<<< 0.37030048388975\n",
      ">>>>>step_norm<<<<<< 0.9289449172360402\n",
      ">>>>>step_norm<<<<<< 0.4161949974901504\n",
      ">>>>>step_norm<<<<<< 0.7435824937434369\n",
      ">>>>>step_norm<<<<<< 0.29646078523218095\n",
      ">>>>>step_norm<<<<<< 0.40653544860217894\n",
      ">>>>>step_norm<<<<<< 0.4509234425350897\n",
      ">>>>>step_norm<<<<<< 0.8667507611460303\n",
      ">>>>>step_norm<<<<<< 0.6320290488242989\n",
      ">>>>>step_norm<<<<<< 0.2975974461796308\n",
      ">>>>>step_norm<<<<<< 0.3285448081121729\n",
      ">>>>>step_norm<<<<<< 0.24374939628634507\n",
      ">>>>>step_norm<<<<<< 0.2806592018234276\n",
      ">>>>>step_norm<<<<<< 0.4170655767346108\n",
      ">>>>>step_norm<<<<<< 1.1064213771100375\n",
      ">>>>>step_norm<<<<<< 0.571503070565872\n",
      ">>>>>step_norm<<<<<< 0.396508672590145\n",
      ">>>>>step_norm<<<<<< 0.7226404724027652\n",
      ">>>>>step_norm<<<<<< 0.38811598769691835\n",
      ">>>>>step_norm<<<<<< 0.3888086455207801\n",
      ">>>>>step_norm<<<<<< 0.617745802174559\n",
      ">>>>>step_norm<<<<<< 0.8887443982683669\n",
      ">>>>>step_norm<<<<<< 0.34969422749731605\n",
      ">>>>>step_norm<<<<<< 0.3418930496010724\n",
      ">>>>>step_norm<<<<<< 0.3076968832676537\n",
      ">>>>>step_norm<<<<<< 0.34080259652563755\n",
      ">>>>>step_norm<<<<<< 1.374231679027551\n",
      ">>>>>step_norm<<<<<< 0.5482089000445929\n",
      ">>>>>step_norm<<<<<< 0.6492131749512652\n",
      ">>>>>step_norm<<<<<< 0.34284254718208934\n",
      ">>>>>step_norm<<<<<< 0.5341487189659933\n",
      ">>>>>step_norm<<<<<< 0.4538898029199693\n",
      ">>>>>step_norm<<<<<< 0.5228839281210299\n",
      ">>>>>step_norm<<<<<< 0.1243963146485033\n",
      ">>>>>step_norm<<<<<< 1.3198939739461657\n",
      ">>>>>step_norm<<<<<< 0.7093284091637351\n",
      ">>>>>step_norm<<<<<< 0.3787307635576345\n",
      ">>>>>step_norm<<<<<< 0.44528019892424675\n",
      ">>>>>step_norm<<<<<< 1.0191430919301334\n",
      ">>>>>step_norm<<<<<< 0.39277618298973144\n",
      ">>>>>step_norm<<<<<< 0.27673655078719284\n",
      ">>>>>step_norm<<<<<< 0.423143870885335\n",
      ">>>>>step_norm<<<<<< 0.7174429258121306\n",
      ">>>>>step_norm<<<<<< 0.5453149414463592\n",
      ">>>>>step_norm<<<<<< 0.22641208751994982\n",
      ">>>>>step_norm<<<<<< 0.34891598365535514\n",
      ">>>>>step_norm<<<<<< 0.7763635391102864\n",
      ">>>>>step_norm<<<<<< 0.8017382091661157\n",
      ">>>>>step_norm<<<<<< 0.5059536575509892\n",
      ">>>>>step_norm<<<<<< 0.3125126518782317\n",
      ">>>>>step_norm<<<<<< 0.31511814217487544\n",
      ">>>>>step_norm<<<<<< 0.7143512650485647\n",
      ">>>>>step_norm<<<<<< 0.30656279950429327\n",
      ">>>>>step_norm<<<<<< 0.44303550472732006\n",
      ">>>>>step_norm<<<<<< 0.3446076701019136\n",
      ">>>>>step_norm<<<<<< 0.6430083948211185\n",
      ">>>>>step_norm<<<<<< 0.4505234947701007\n",
      ">>>>>step_norm<<<<<< 0.2413396311232487\n",
      ">>>>>step_norm<<<<<< 0.20626258376467338\n",
      ">>>>>step_norm<<<<<< 0.7526384473236766\n",
      ">>>>>step_norm<<<<<< 0.4210383199764074\n",
      ">>>>>step_norm<<<<<< 1.122935904549843\n",
      ">>>>>step_norm<<<<<< 0.35632529984341\n",
      ">>>>>step_norm<<<<<< 0.3424592483423143\n",
      ">>>>>step_norm<<<<<< 0.24324978175409198\n",
      ">>>>>step_norm<<<<<< 0.44481624910572964\n",
      ">>>>>step_norm<<<<<< 0.7098277363102282\n",
      ">>>>>step_norm<<<<<< 0.4574551795645771\n",
      ">>>>>step_norm<<<<<< 0.6200549518545352\n",
      ">>>>>step_norm<<<<<< 0.6477736897772166\n",
      ">>>>>step_norm<<<<<< 0.5710761955515422\n",
      ">>>>>step_norm<<<<<< 1.179146111956185\n",
      ">>>>>step_norm<<<<<< 0.47793645508969823\n",
      ">>>>>step_norm<<<<<< 1.3826159573175731\n",
      ">>>>>step_norm<<<<<< 0.5687839764152302\n",
      ">>>>>step_norm<<<<<< 0.49945802882022455\n",
      ">>>>>step_norm<<<<<< 0.4776922036921252\n",
      ">>>>>step_norm<<<<<< 0.6269545037509746\n",
      ">>>>>step_norm<<<<<< 0.3006563771320656\n",
      ">>>>>step_norm<<<<<< 0.14223533475681058\n",
      ">>>>>step_norm<<<<<< 0.8106078843726395\n",
      ">>>>>step_norm<<<<<< 0.25557020777871253\n",
      ">>>>>step_norm<<<<<< 0.4867021646370611\n",
      ">>>>>step_norm<<<<<< 0.6637659425663993\n",
      ">>>>>step_norm<<<<<< 0.3841056081179789\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 2\n",
      ">>>>>step_norm<<<<<< 0.5003437757795692\n",
      ">>>>>step_norm<<<<<< 0.26301658394347166\n",
      ">>>>>step_norm<<<<<< 0.2432268393896548\n",
      ">>>>>step_norm<<<<<< 0.6315200232112357\n",
      ">>>>>step_norm<<<<<< 1.5157511037731126\n",
      ">>>>>step_norm<<<<<< 0.9327140538101788\n",
      ">>>>>step_norm<<<<<< 1.9512636132610337\n",
      ">>>>>step_norm<<<<<< 0.6099940588720637\n",
      ">>>>>step_norm<<<<<< 0.2795428534642906\n",
      ">>>>>step_norm<<<<<< 0.4768536902133125\n",
      ">>>>>step_norm<<<<<< 0.7144025028859231\n",
      ">>>>>step_norm<<<<<< 0.32514530226041705\n",
      ">>>>>step_norm<<<<<< 0.43158546051901187\n",
      ">>>>>step_norm<<<<<< 1.1752058665724472\n",
      ">>>>>step_norm<<<<<< 0.7915801958725386\n",
      ">>>>>step_norm<<<<<< 0.5800526138778225\n",
      ">>>>>step_norm<<<<<< 0.42739687053839087\n",
      ">>>>>step_norm<<<<<< 0.34258111382645273\n",
      ">>>>>step_norm<<<<<< 0.6861137861628925\n",
      ">>>>>step_norm<<<<<< 0.5689559043881027\n",
      ">>>>>step_norm<<<<<< 0.4027578580684966\n",
      ">>>>>step_norm<<<<<< 0.4756933249420171\n",
      ">>>>>step_norm<<<<<< 1.674689826041488\n",
      ">>>>>step_norm<<<<<< 0.42996615460146\n",
      ">>>>>step_norm<<<<<< 1.3310074272137788\n",
      ">>>>>step_norm<<<<<< 0.3911223157591152\n",
      ">>>>>step_norm<<<<<< 0.6026878471666874\n",
      ">>>>>step_norm<<<<<< 1.2597484934106338\n",
      ">>>>>step_norm<<<<<< 0.5034355379663171\n",
      ">>>>>step_norm<<<<<< 0.5352292195983795\n",
      ">>>>>step_norm<<<<<< 0.5555268848374928\n",
      ">>>>>step_norm<<<<<< 0.48065912773743347\n",
      ">>>>>step_norm<<<<<< 1.3015683074526976\n",
      ">>>>>step_norm<<<<<< 0.2686840920916765\n",
      ">>>>>step_norm<<<<<< 0.6425043139085908\n",
      ">>>>>step_norm<<<<<< 0.390956924938539\n",
      ">>>>>step_norm<<<<<< 0.6690838377789152\n",
      ">>>>>step_norm<<<<<< 0.5492567306103934\n",
      ">>>>>step_norm<<<<<< 0.6797379278306981\n",
      ">>>>>step_norm<<<<<< 0.23443856572282243\n",
      ">>>>>step_norm<<<<<< 0.5280502381006804\n",
      ">>>>>step_norm<<<<<< 1.289619990736374\n",
      ">>>>>step_norm<<<<<< 0.7441175317311656\n",
      ">>>>>step_norm<<<<<< 0.19606016230757425\n",
      ">>>>>step_norm<<<<<< 0.4782090793150178\n",
      ">>>>>step_norm<<<<<< 0.5948046063626466\n",
      ">>>>>step_norm<<<<<< 0.8000497124072293\n",
      ">>>>>step_norm<<<<<< 0.5438569851826635\n",
      ">>>>>step_norm<<<<<< 0.7892352804928159\n",
      ">>>>>step_norm<<<<<< 1.113940984113756\n",
      ">>>>>step_norm<<<<<< 1.1402878214267747\n",
      ">>>>>step_norm<<<<<< 1.876799483357985\n",
      ">>>>>step_norm<<<<<< 0.9408027891567279\n",
      ">>>>>step_norm<<<<<< 0.44384680910088653\n",
      ">>>>>step_norm<<<<<< 0.3947752195081441\n",
      ">>>>>step_norm<<<<<< 0.5438934774136939\n",
      ">>>>>step_norm<<<<<< 0.5163347503847654\n",
      ">>>>>step_norm<<<<<< 0.8148819543116492\n",
      ">>>>>step_norm<<<<<< 0.6108819011253723\n",
      ">>>>>step_norm<<<<<< 0.40167283847144547\n",
      ">>>>>step_norm<<<<<< 1.4990083704894455\n",
      ">>>>>step_norm<<<<<< 0.5364456457179064\n",
      ">>>>>step_norm<<<<<< 1.222241018522589\n",
      ">>>>>step_norm<<<<<< 0.9653327904166742\n",
      ">>>>>step_norm<<<<<< 0.6065608518575041\n",
      ">>>>>step_norm<<<<<< 0.5751671066019789\n",
      ">>>>>step_norm<<<<<< 0.2618968471505311\n",
      ">>>>>step_norm<<<<<< 0.7257155519206842\n",
      ">>>>>step_norm<<<<<< 0.6054647316773388\n",
      ">>>>>step_norm<<<<<< 0.3458394188511759\n",
      ">>>>>step_norm<<<<<< 1.1245257552247159\n",
      ">>>>>step_norm<<<<<< 0.69834277728123\n",
      ">>>>>step_norm<<<<<< 0.5518854062911688\n",
      ">>>>>step_norm<<<<<< 0.5392682091159116\n",
      ">>>>>step_norm<<<<<< 1.118562365897895\n",
      ">>>>>step_norm<<<<<< 0.5863140252315614\n",
      ">>>>>step_norm<<<<<< 0.9424540358197427\n",
      ">>>>>step_norm<<<<<< 0.49441734251196673\n",
      ">>>>>step_norm<<<<<< 1.0296999420990782\n",
      ">>>>>step_norm<<<<<< 0.9060333375380868\n",
      ">>>>>step_norm<<<<<< 1.0652578032669624\n",
      ">>>>>step_norm<<<<<< 0.4196944582888029\n",
      ">>>>>step_norm<<<<<< 0.8170946926407432\n",
      ">>>>>step_norm<<<<<< 0.6495346472843437\n",
      ">>>>>step_norm<<<<<< 0.9313291299250634\n",
      ">>>>>step_norm<<<<<< 1.8325819088557471\n",
      ">>>>>step_norm<<<<<< 0.4862892569939464\n",
      ">>>>>step_norm<<<<<< 0.4493133382714232\n",
      ">>>>>step_norm<<<<<< 0.2951880779839856\n",
      ">>>>>step_norm<<<<<< 0.27422993949117375\n",
      ">>>>>step_norm<<<<<< 0.7896622396673124\n",
      ">>>>>step_norm<<<<<< 1.1199208570394483\n",
      ">>>>>step_norm<<<<<< 0.9206379226973531\n",
      ">>>>>step_norm<<<<<< 0.26512886921284534\n",
      ">>>>>step_norm<<<<<< 0.45031614150896465\n",
      ">>>>>step_norm<<<<<< 0.3896681101509111\n",
      ">>>>>step_norm<<<<<< 0.99741340747651\n",
      ">>>>>step_norm<<<<<< 1.06615300513717\n",
      ">>>>>step_norm<<<<<< 0.6460982230767766\n",
      ">>>>>step_norm<<<<<< 0.43010293556334483\n",
      ">>>>>step_norm<<<<<< 0.29656475384567593\n",
      ">>>>>step_norm<<<<<< 0.5987867064565633\n",
      ">>>>>step_norm<<<<<< 0.37655927863759625\n",
      ">>>>>step_norm<<<<<< 0.6290873952272678\n",
      ">>>>>step_norm<<<<<< 0.5656516862115696\n",
      ">>>>>step_norm<<<<<< 0.5568510601765236\n",
      ">>>>>step_norm<<<<<< 1.0961679269394609\n",
      ">>>>>step_norm<<<<<< 0.4027996806215443\n",
      ">>>>>step_norm<<<<<< 0.9559623247047294\n",
      ">>>>>step_norm<<<<<< 0.632075854852616\n",
      ">>>>>step_norm<<<<<< 0.8310826000222301\n",
      ">>>>>step_norm<<<<<< 0.6763085303369669\n",
      ">>>>>step_norm<<<<<< 0.6292962599653643\n",
      ">>>>>step_norm<<<<<< 0.5892736317132007\n",
      ">>>>>step_norm<<<<<< 0.5871682199248917\n",
      ">>>>>step_norm<<<<<< 1.1514448734808085\n",
      ">>>>>step_norm<<<<<< 0.5659830983142484\n",
      ">>>>>step_norm<<<<<< 0.42824209048648126\n",
      ">>>>>step_norm<<<<<< 0.48869515372464745\n",
      ">>>>>step_norm<<<<<< 0.4522316023409712\n",
      ">>>>>step_norm<<<<<< 0.554324140333066\n",
      ">>>>>step_norm<<<<<< 0.593927665210063\n",
      ">>>>>step_norm<<<<<< 0.8394436947167628\n",
      ">>>>>step_norm<<<<<< 0.7435747374601757\n",
      ">>>>>step_norm<<<<<< 1.2297786571640565\n",
      ">>>>>step_norm<<<<<< 0.5648955962762354\n",
      ">>>>>step_norm<<<<<< 1.0357911201381373\n",
      ">>>>>step_norm<<<<<< 0.3925253906717975\n",
      ">>>>>step_norm<<<<<< 0.5601822167186526\n",
      ">>>>>step_norm<<<<<< 0.2289696136371619\n",
      ">>>>>step_norm<<<<<< 0.7996393468373586\n",
      ">>>>>step_norm<<<<<< 0.8036033445525396\n",
      ">>>>>step_norm<<<<<< 0.9508354168925489\n",
      ">>>>>step_norm<<<<<< 0.37898311025975867\n",
      ">>>>>step_norm<<<<<< 0.481349585497042\n",
      ">>>>>step_norm<<<<<< 0.33037536868721795\n",
      ">>>>>step_norm<<<<<< 0.7636662728796163\n",
      ">>>>>step_norm<<<<<< 0.553088608344302\n",
      ">>>>>step_norm<<<<<< 0.40386090317152046\n",
      ">>>>>step_norm<<<<<< 0.43514908026466415\n",
      ">>>>>step_norm<<<<<< 0.9350862964141957\n",
      ">>>>>step_norm<<<<<< 0.7636350203031321\n",
      ">>>>>step_norm<<<<<< 0.4475884235694212\n",
      ">>>>>step_norm<<<<<< 0.58611319406932\n",
      ">>>>>step_norm<<<<<< 0.9175869935912172\n",
      ">>>>>step_norm<<<<<< 0.7125840847094909\n",
      ">>>>>step_norm<<<<<< 0.4230218631999426\n",
      ">>>>>step_norm<<<<<< 1.3609471523883232\n",
      ">>>>>step_norm<<<<<< 1.0542598483406498\n",
      ">>>>>step_norm<<<<<< 0.33406549542022773\n",
      ">>>>>step_norm<<<<<< 0.818023798711735\n",
      ">>>>>step_norm<<<<<< 1.14541839524236\n",
      ">>>>>step_norm<<<<<< 0.31243726120277315\n",
      ">>>>>step_norm<<<<<< 0.3905120864228522\n",
      ">>>>>step_norm<<<<<< 0.6710760483785548\n",
      ">>>>>step_norm<<<<<< 0.8533757359119549\n",
      ">>>>>step_norm<<<<<< 0.42127359500219863\n",
      ">>>>>step_norm<<<<<< 0.49846595664386933\n",
      ">>>>>step_norm<<<<<< 0.3061474961430509\n",
      ">>>>>step_norm<<<<<< 0.8914182743834219\n",
      ">>>>>step_norm<<<<<< 0.5241990150545154\n",
      ">>>>>step_norm<<<<<< 0.6335574754339279\n",
      ">>>>>step_norm<<<<<< 0.3640265753390007\n",
      ">>>>>step_norm<<<<<< 0.4571995531106772\n",
      ">>>>>step_norm<<<<<< 0.7199071699685339\n",
      ">>>>>step_norm<<<<<< 1.1164351766345137\n",
      ">>>>>step_norm<<<<<< 0.6550746868441885\n",
      ">>>>>step_norm<<<<<< 0.42372002812788584\n",
      ">>>>>step_norm<<<<<< 0.4705904613655027\n",
      ">>>>>step_norm<<<<<< 0.8130938017419359\n",
      ">>>>>step_norm<<<<<< 0.5402691032436214\n",
      ">>>>>step_norm<<<<<< 0.23601042869887306\n",
      ">>>>>step_norm<<<<<< 0.7384485590201812\n",
      ">>>>>step_norm<<<<<< 0.36624561548519124\n",
      ">>>>>step_norm<<<<<< 1.339787481333159\n",
      ">>>>>step_norm<<<<<< 0.7083600601599784\n",
      ">>>>>step_norm<<<<<< 0.8195457489143232\n",
      ">>>>>step_norm<<<<<< 1.1909339971692736\n",
      ">>>>>step_norm<<<<<< 0.8450785893348578\n",
      ">>>>>step_norm<<<<<< 1.2564499227348145\n",
      ">>>>>step_norm<<<<<< 1.3221856758358659\n",
      ">>>>>step_norm<<<<<< 0.4193543490667821\n",
      ">>>>>step_norm<<<<<< 0.3621874576028226\n",
      ">>>>>step_norm<<<<<< 0.36869397272435567\n",
      ">>>>>step_norm<<<<<< 0.6718877037214737\n",
      ">>>>>step_norm<<<<<< 0.7378465345768128\n",
      ">>>>>step_norm<<<<<< 1.3958532651437339\n",
      ">>>>>step_norm<<<<<< 0.5023405817077946\n",
      ">>>>>step_norm<<<<<< 0.35982737773621126\n",
      ">>>>>step_norm<<<<<< 0.7173849280365395\n",
      ">>>>>step_norm<<<<<< 0.6339591456037849\n",
      ">>>>>step_norm<<<<<< 0.7351686640779912\n",
      ">>>>>step_norm<<<<<< 0.4001697865033748\n",
      ">>>>>step_norm<<<<<< 1.6483172158540866\n",
      ">>>>>step_norm<<<<<< 0.7424628372794358\n",
      ">>>>>step_norm<<<<<< 0.49394607082191005\n",
      ">>>>>step_norm<<<<<< 1.134482624118212\n",
      ">>>>>step_norm<<<<<< 0.2760391470488704\n",
      ">>>>>step_norm<<<<<< 0.49539438971722427\n",
      ">>>>>step_norm<<<<<< 0.45245355002452337\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 3\n",
      ">>>>>step_norm<<<<<< 0.2731706867118621\n",
      ">>>>>step_norm<<<<<< 0.40418617092481574\n",
      ">>>>>step_norm<<<<<< 0.6990404056372269\n",
      ">>>>>step_norm<<<<<< 0.5001968313128526\n",
      ">>>>>step_norm<<<<<< 0.8791150191798884\n",
      ">>>>>step_norm<<<<<< 1.3556576385521306\n",
      ">>>>>step_norm<<<<<< 0.7868372027258806\n",
      ">>>>>step_norm<<<<<< 0.6338056952972758\n",
      ">>>>>step_norm<<<<<< 0.715816790452486\n",
      ">>>>>step_norm<<<<<< 0.511513781081173\n",
      ">>>>>step_norm<<<<<< 1.1911726298277405\n",
      ">>>>>step_norm<<<<<< 0.48573710926034397\n",
      ">>>>>step_norm<<<<<< 0.7010982091478724\n",
      ">>>>>step_norm<<<<<< 0.6179954181824877\n",
      ">>>>>step_norm<<<<<< 0.7318855603390019\n",
      ">>>>>step_norm<<<<<< 1.2327265731948422\n",
      ">>>>>step_norm<<<<<< 0.8179288429445168\n",
      ">>>>>step_norm<<<<<< 0.36211794193811525\n",
      ">>>>>step_norm<<<<<< 0.9219648085282679\n",
      ">>>>>step_norm<<<<<< 0.4994533017154855\n",
      ">>>>>step_norm<<<<<< 0.38248378483979556\n",
      ">>>>>step_norm<<<<<< 0.6930359727667229\n",
      ">>>>>step_norm<<<<<< 0.888540311842399\n",
      ">>>>>step_norm<<<<<< 1.2654703153057638\n",
      ">>>>>step_norm<<<<<< 0.5816406894238781\n",
      ">>>>>step_norm<<<<<< 1.1571441165251433\n",
      ">>>>>step_norm<<<<<< 0.6051967470823899\n",
      ">>>>>step_norm<<<<<< 0.3370383459487328\n",
      ">>>>>step_norm<<<<<< 1.1905286801063264\n",
      ">>>>>step_norm<<<<<< 0.41638340053422046\n",
      ">>>>>step_norm<<<<<< 0.5634435994839203\n",
      ">>>>>step_norm<<<<<< 0.6352447015678718\n",
      ">>>>>step_norm<<<<<< 0.5291459255692794\n",
      ">>>>>step_norm<<<<<< 0.311927508125276\n",
      ">>>>>step_norm<<<<<< 0.47355580605372727\n",
      ">>>>>step_norm<<<<<< 1.951951203315583\n",
      ">>>>>step_norm<<<<<< 1.1065742932984142\n",
      ">>>>>step_norm<<<<<< 0.6676801234464036\n",
      ">>>>>step_norm<<<<<< 0.48833918394333625\n",
      ">>>>>step_norm<<<<<< 0.500176660358335\n",
      ">>>>>step_norm<<<<<< 0.7485635747082755\n",
      ">>>>>step_norm<<<<<< 0.6561345292721089\n",
      ">>>>>step_norm<<<<<< 2.2804799778437315\n",
      ">>>>>step_norm<<<<<< 0.8316616226536203\n",
      ">>>>>step_norm<<<<<< 1.0336147767665937\n",
      ">>>>>step_norm<<<<<< 1.170714493210808\n",
      ">>>>>step_norm<<<<<< 1.2090241960940424\n",
      ">>>>>step_norm<<<<<< 0.574664469326058\n",
      ">>>>>step_norm<<<<<< 0.4410928077032059\n",
      ">>>>>step_norm<<<<<< 0.3281364408558465\n",
      ">>>>>step_norm<<<<<< 0.8302084780912865\n",
      ">>>>>step_norm<<<<<< 0.9815633356091353\n",
      ">>>>>step_norm<<<<<< 0.8563358370754053\n",
      ">>>>>step_norm<<<<<< 0.6853314616872429\n",
      ">>>>>step_norm<<<<<< 0.2822869894690598\n",
      ">>>>>step_norm<<<<<< 1.136255085749316\n",
      ">>>>>step_norm<<<<<< 0.30512425431141194\n",
      ">>>>>step_norm<<<<<< 0.5404028704268569\n",
      ">>>>>step_norm<<<<<< 0.45544117558744746\n",
      ">>>>>step_norm<<<<<< 0.6295316972264398\n",
      ">>>>>step_norm<<<<<< 0.5897699233859564\n",
      ">>>>>step_norm<<<<<< 0.5647936375207883\n",
      ">>>>>step_norm<<<<<< 0.7263068721595142\n",
      ">>>>>step_norm<<<<<< 0.5668226801476484\n",
      ">>>>>step_norm<<<<<< 0.5565861620762318\n",
      ">>>>>step_norm<<<<<< 0.5869534087542689\n",
      ">>>>>step_norm<<<<<< 1.3997809249197593\n",
      ">>>>>step_norm<<<<<< 0.6968422162311254\n",
      ">>>>>step_norm<<<<<< 0.8662852294358682\n",
      ">>>>>step_norm<<<<<< 0.5799750600835428\n",
      ">>>>>step_norm<<<<<< 0.23884542694639216\n",
      ">>>>>step_norm<<<<<< 0.838757269375882\n",
      ">>>>>step_norm<<<<<< 0.36255378735325866\n",
      ">>>>>step_norm<<<<<< 0.7688252759759405\n",
      ">>>>>step_norm<<<<<< 0.4731855924598342\n",
      ">>>>>step_norm<<<<<< 0.49812267050202946\n",
      ">>>>>step_norm<<<<<< 0.9043543341798992\n",
      ">>>>>step_norm<<<<<< 0.2932123140780889\n",
      ">>>>>step_norm<<<<<< 0.5454467582839708\n",
      ">>>>>step_norm<<<<<< 1.0002681167737084\n",
      ">>>>>step_norm<<<<<< 1.208979338461424\n",
      ">>>>>step_norm<<<<<< 0.9593779474315604\n",
      ">>>>>step_norm<<<<<< 0.40673984013870823\n",
      ">>>>>step_norm<<<<<< 1.8241598351774533\n",
      ">>>>>step_norm<<<<<< 0.34576239533837644\n",
      ">>>>>step_norm<<<<<< 0.31330522378328407\n",
      ">>>>>step_norm<<<<<< 0.47613241052926575\n",
      ">>>>>step_norm<<<<<< 0.7465015052986189\n",
      ">>>>>step_norm<<<<<< 0.33712485469386655\n",
      ">>>>>step_norm<<<<<< 1.4609792483378325\n",
      ">>>>>step_norm<<<<<< 0.9785832866318912\n",
      ">>>>>step_norm<<<<<< 0.8772910004777873\n",
      ">>>>>step_norm<<<<<< 0.5654375372954394\n",
      ">>>>>step_norm<<<<<< 0.41653092171100603\n",
      ">>>>>step_norm<<<<<< 0.30204223121659657\n",
      ">>>>>step_norm<<<<<< 0.2329649394898817\n",
      ">>>>>step_norm<<<<<< 0.5661771956369543\n",
      ">>>>>step_norm<<<<<< 1.0837790102475195\n",
      ">>>>>step_norm<<<<<< 0.8181135135550042\n",
      ">>>>>step_norm<<<<<< 1.1254189135108612\n",
      ">>>>>step_norm<<<<<< 1.0486030621416982\n",
      ">>>>>step_norm<<<<<< 0.6877667438780537\n",
      ">>>>>step_norm<<<<<< 1.0603972665103327\n",
      ">>>>>step_norm<<<<<< 0.6584103654760114\n",
      ">>>>>step_norm<<<<<< 0.9947212479723518\n",
      ">>>>>step_norm<<<<<< 0.5094930667851788\n",
      ">>>>>step_norm<<<<<< 1.0963935228752857\n",
      ">>>>>step_norm<<<<<< 0.5325714690721932\n",
      ">>>>>step_norm<<<<<< 0.4837984386536044\n",
      ">>>>>step_norm<<<<<< 0.7145438679070755\n",
      ">>>>>step_norm<<<<<< 0.7407363921289869\n",
      ">>>>>step_norm<<<<<< 0.5637431655979847\n",
      ">>>>>step_norm<<<<<< 0.36369709641316994\n",
      ">>>>>step_norm<<<<<< 1.3973436863534912\n",
      ">>>>>step_norm<<<<<< 0.9603792514490563\n",
      ">>>>>step_norm<<<<<< 0.8972076184435601\n",
      ">>>>>step_norm<<<<<< 0.9784123266703636\n",
      ">>>>>step_norm<<<<<< 0.7349045200020229\n",
      ">>>>>step_norm<<<<<< 0.5688414982641998\n",
      ">>>>>step_norm<<<<<< 0.9076082023636135\n",
      ">>>>>step_norm<<<<<< 1.3187548087823089\n",
      ">>>>>step_norm<<<<<< 0.5601236234172832\n",
      ">>>>>step_norm<<<<<< 0.2614625439132263\n",
      ">>>>>step_norm<<<<<< 0.615317420425078\n",
      ">>>>>step_norm<<<<<< 0.4525046489350266\n",
      ">>>>>step_norm<<<<<< 0.6081501025935205\n",
      ">>>>>step_norm<<<<<< 0.37473681316782637\n",
      ">>>>>step_norm<<<<<< 0.7949673207771165\n",
      ">>>>>step_norm<<<<<< 1.1923847211267944\n",
      ">>>>>step_norm<<<<<< 0.42209256301595094\n",
      ">>>>>step_norm<<<<<< 0.1839043868379105\n",
      ">>>>>step_norm<<<<<< 0.7169670330421256\n",
      ">>>>>step_norm<<<<<< 0.5033241484606069\n",
      ">>>>>step_norm<<<<<< 0.4296601756160627\n",
      ">>>>>step_norm<<<<<< 0.9248449649126332\n",
      ">>>>>step_norm<<<<<< 0.5952639071423739\n",
      ">>>>>step_norm<<<<<< 0.4935822543180464\n",
      ">>>>>step_norm<<<<<< 2.423184447281909\n",
      ">>>>>step_norm<<<<<< 0.4273549809780151\n",
      ">>>>>step_norm<<<<<< 0.728764844155829\n",
      ">>>>>step_norm<<<<<< 0.6914557580740254\n",
      ">>>>>step_norm<<<<<< 1.12597127294358\n",
      ">>>>>step_norm<<<<<< 0.5052238264234179\n",
      ">>>>>step_norm<<<<<< 0.6278006855778366\n",
      ">>>>>step_norm<<<<<< 0.8387944454449353\n",
      ">>>>>step_norm<<<<<< 0.2727542904829129\n",
      ">>>>>step_norm<<<<<< 2.0902463259862767\n",
      ">>>>>step_norm<<<<<< 0.34247148997961646\n",
      ">>>>>step_norm<<<<<< 0.7081019647381243\n",
      ">>>>>step_norm<<<<<< 0.6331159396638333\n",
      ">>>>>step_norm<<<<<< 0.3087692575461896\n",
      ">>>>>step_norm<<<<<< 0.4975378978593912\n",
      ">>>>>step_norm<<<<<< 0.9398315016383185\n",
      ">>>>>step_norm<<<<<< 0.5873788359983843\n",
      ">>>>>step_norm<<<<<< 0.6582489437363556\n",
      ">>>>>step_norm<<<<<< 0.3773271502042466\n",
      ">>>>>step_norm<<<<<< 0.9262300929549073\n",
      ">>>>>step_norm<<<<<< 1.5286481408539525\n",
      ">>>>>step_norm<<<<<< 0.4478113241213008\n",
      ">>>>>step_norm<<<<<< 0.5056322599192158\n",
      ">>>>>step_norm<<<<<< 1.6566932024003067\n",
      ">>>>>step_norm<<<<<< 0.46449800605947517\n",
      ">>>>>step_norm<<<<<< 0.883040381909395\n",
      ">>>>>step_norm<<<<<< 0.9133106787647736\n",
      ">>>>>step_norm<<<<<< 0.4067435415202995\n",
      ">>>>>step_norm<<<<<< 0.714062778741895\n",
      ">>>>>step_norm<<<<<< 1.0748258086340428\n",
      ">>>>>step_norm<<<<<< 0.36545130090606814\n",
      ">>>>>step_norm<<<<<< 1.0717716155709482\n",
      ">>>>>step_norm<<<<<< 0.5458738610009233\n",
      ">>>>>step_norm<<<<<< 1.456737722372281\n",
      ">>>>>step_norm<<<<<< 0.7186503671792366\n",
      ">>>>>step_norm<<<<<< 0.7954722818169074\n",
      ">>>>>step_norm<<<<<< 1.797597165563703\n",
      ">>>>>step_norm<<<<<< 0.4836852794858414\n",
      ">>>>>step_norm<<<<<< 0.6122882013013996\n",
      ">>>>>step_norm<<<<<< 0.9605777871383587\n",
      ">>>>>step_norm<<<<<< 0.9217008584577896\n",
      ">>>>>step_norm<<<<<< 0.8619022479107153\n",
      ">>>>>step_norm<<<<<< 1.131781328268374\n",
      ">>>>>step_norm<<<<<< 0.655042085273193\n",
      ">>>>>step_norm<<<<<< 0.19470082126006286\n",
      ">>>>>step_norm<<<<<< 0.9034981907850372\n",
      ">>>>>step_norm<<<<<< 0.8099467623776613\n",
      ">>>>>step_norm<<<<<< 0.43671280845830035\n",
      ">>>>>step_norm<<<<<< 0.6108762453465169\n",
      ">>>>>step_norm<<<<<< 0.6866171887332817\n",
      ">>>>>step_norm<<<<<< 0.7165216869537436\n",
      ">>>>>step_norm<<<<<< 0.19991941228891769\n",
      ">>>>>step_norm<<<<<< 0.46511311827610236\n",
      ">>>>>step_norm<<<<<< 1.167338654065063\n",
      ">>>>>step_norm<<<<<< 0.5240337452790508\n",
      ">>>>>step_norm<<<<<< 1.8913035461019907\n",
      ">>>>>step_norm<<<<<< 0.41298796882618966\n",
      ">>>>>step_norm<<<<<< 0.9134542517636457\n",
      ">>>>>step_norm<<<<<< 0.5939644337159343\n",
      ">>>>>step_norm<<<<<< 1.312309709390194\n",
      ">>>>>step_norm<<<<<< 0.9082273054038353\n",
      ">>>>>step_norm<<<<<< 1.7078261452326617\n",
      ">>>>>step_norm<<<<<< 0.4883317509136941\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 4\n",
      ">>>>>step_norm<<<<<< 0.9097825795121287\n",
      ">>>>>step_norm<<<<<< 0.2807944912721953\n",
      ">>>>>step_norm<<<<<< 0.3810132323444568\n",
      ">>>>>step_norm<<<<<< 0.4182341430218838\n",
      ">>>>>step_norm<<<<<< 0.46428823961114984\n",
      ">>>>>step_norm<<<<<< 0.7001992799082931\n",
      ">>>>>step_norm<<<<<< 0.7319509406593883\n",
      ">>>>>step_norm<<<<<< 0.6318640820339899\n",
      ">>>>>step_norm<<<<<< 0.6588806717365019\n",
      ">>>>>step_norm<<<<<< 0.3778151996063904\n",
      ">>>>>step_norm<<<<<< 0.6945283407501642\n",
      ">>>>>step_norm<<<<<< 0.9684376054884566\n",
      ">>>>>step_norm<<<<<< 0.38215800685773627\n",
      ">>>>>step_norm<<<<<< 0.963475505121572\n",
      ">>>>>step_norm<<<<<< 0.4721964607571484\n",
      ">>>>>step_norm<<<<<< 0.6819420933231034\n",
      ">>>>>step_norm<<<<<< 0.24021519676849723\n",
      ">>>>>step_norm<<<<<< 0.40317129034407795\n",
      ">>>>>step_norm<<<<<< 0.4716047518687049\n",
      ">>>>>step_norm<<<<<< 0.5896338195040504\n",
      ">>>>>step_norm<<<<<< 0.3870336913538374\n",
      ">>>>>step_norm<<<<<< 0.38115186657014266\n",
      ">>>>>step_norm<<<<<< 0.7488073926583696\n",
      ">>>>>step_norm<<<<<< 1.6228753046454323\n",
      ">>>>>step_norm<<<<<< 0.278492453752924\n",
      ">>>>>step_norm<<<<<< 0.5774655673976876\n",
      ">>>>>step_norm<<<<<< 0.205611056665668\n",
      ">>>>>step_norm<<<<<< 1.1252988420423735\n",
      ">>>>>step_norm<<<<<< 0.5207536280611219\n",
      ">>>>>step_norm<<<<<< 0.4109203049484142\n",
      ">>>>>step_norm<<<<<< 0.5256886679852143\n",
      ">>>>>step_norm<<<<<< 0.5058263084739173\n",
      ">>>>>step_norm<<<<<< 0.48318353250538626\n",
      ">>>>>step_norm<<<<<< 0.5833381171421225\n",
      ">>>>>step_norm<<<<<< 1.1180484880194368\n",
      ">>>>>step_norm<<<<<< 0.5729552070166364\n",
      ">>>>>step_norm<<<<<< 0.708127622459238\n",
      ">>>>>step_norm<<<<<< 0.8760509172508352\n",
      ">>>>>step_norm<<<<<< 0.5432716480107074\n",
      ">>>>>step_norm<<<<<< 0.5278247382519593\n",
      ">>>>>step_norm<<<<<< 0.3612212334968085\n",
      ">>>>>step_norm<<<<<< 0.7818555031292648\n",
      ">>>>>step_norm<<<<<< 0.8506540619435309\n",
      ">>>>>step_norm<<<<<< 0.5862782795039906\n",
      ">>>>>step_norm<<<<<< 0.4409547560565224\n",
      ">>>>>step_norm<<<<<< 1.0077700691363545\n",
      ">>>>>step_norm<<<<<< 0.4562677964138158\n",
      ">>>>>step_norm<<<<<< 0.823902831209546\n",
      ">>>>>step_norm<<<<<< 0.49728061486328473\n",
      ">>>>>step_norm<<<<<< 0.4965022108407088\n",
      ">>>>>step_norm<<<<<< 0.81523439794325\n",
      ">>>>>step_norm<<<<<< 0.4222374946697955\n",
      ">>>>>step_norm<<<<<< 0.5383559642114157\n",
      ">>>>>step_norm<<<<<< 0.4752575349376802\n",
      ">>>>>step_norm<<<<<< 0.6313777418808577\n",
      ">>>>>step_norm<<<<<< 0.7719420772967013\n",
      ">>>>>step_norm<<<<<< 0.4489244957083431\n",
      ">>>>>step_norm<<<<<< 0.8073730766819043\n",
      ">>>>>step_norm<<<<<< 0.8651754263904164\n",
      ">>>>>step_norm<<<<<< 0.5969717255614471\n",
      ">>>>>step_norm<<<<<< 0.5149071030718361\n",
      ">>>>>step_norm<<<<<< 0.49831313775362734\n",
      ">>>>>step_norm<<<<<< 0.21503307534992108\n",
      ">>>>>step_norm<<<<<< 0.5599807258656582\n",
      ">>>>>step_norm<<<<<< 0.6161011603650814\n",
      ">>>>>step_norm<<<<<< 0.4325871653784842\n",
      ">>>>>step_norm<<<<<< 1.3184024825652987\n",
      ">>>>>step_norm<<<<<< 0.7003068986952744\n",
      ">>>>>step_norm<<<<<< 0.5846810215040258\n",
      ">>>>>step_norm<<<<<< 0.39523517447506007\n",
      ">>>>>step_norm<<<<<< 0.3072019975993705\n",
      ">>>>>step_norm<<<<<< 0.6214675184444535\n",
      ">>>>>step_norm<<<<<< 0.7089170781857228\n",
      ">>>>>step_norm<<<<<< 0.6932152053328903\n",
      ">>>>>step_norm<<<<<< 0.40578020715002705\n",
      ">>>>>step_norm<<<<<< 0.49969714677313437\n",
      ">>>>>step_norm<<<<<< 0.3368949867683356\n",
      ">>>>>step_norm<<<<<< 0.8277905449540405\n",
      ">>>>>step_norm<<<<<< 0.40200152886122037\n",
      ">>>>>step_norm<<<<<< 1.2182182908487522\n",
      ">>>>>step_norm<<<<<< 0.6109330892116469\n",
      ">>>>>step_norm<<<<<< 1.045653722208902\n",
      ">>>>>step_norm<<<<<< 0.6744859360971597\n",
      ">>>>>step_norm<<<<<< 0.6720834201306402\n",
      ">>>>>step_norm<<<<<< 0.9180310720855694\n",
      ">>>>>step_norm<<<<<< 0.942960900205555\n",
      ">>>>>step_norm<<<<<< 0.6805533184256161\n",
      ">>>>>step_norm<<<<<< 0.3548548537310772\n",
      ">>>>>step_norm<<<<<< 0.6201405964891292\n",
      ">>>>>step_norm<<<<<< 1.310072005237359\n",
      ">>>>>step_norm<<<<<< 0.7302999840414078\n",
      ">>>>>step_norm<<<<<< 0.45497236137245767\n",
      ">>>>>step_norm<<<<<< 0.6752552748349471\n",
      ">>>>>step_norm<<<<<< 0.591957211994578\n",
      ">>>>>step_norm<<<<<< 0.9786939052091892\n",
      ">>>>>step_norm<<<<<< 0.8304364435364849\n",
      ">>>>>step_norm<<<<<< 0.48731464796908075\n",
      ">>>>>step_norm<<<<<< 0.6173842701151724\n",
      ">>>>>step_norm<<<<<< 0.782587756035145\n",
      ">>>>>step_norm<<<<<< 0.512744945141627\n",
      ">>>>>step_norm<<<<<< 0.7547024368128997\n",
      ">>>>>step_norm<<<<<< 0.7681798862185503\n",
      ">>>>>step_norm<<<<<< 0.7974055370830956\n",
      ">>>>>step_norm<<<<<< 0.836789635864621\n",
      ">>>>>step_norm<<<<<< 0.926002670504143\n",
      ">>>>>step_norm<<<<<< 0.30945430177208705\n",
      ">>>>>step_norm<<<<<< 1.025032568807605\n",
      ">>>>>step_norm<<<<<< 1.113615050710147\n",
      ">>>>>step_norm<<<<<< 0.6499561438389971\n",
      ">>>>>step_norm<<<<<< 0.5128045810380046\n",
      ">>>>>step_norm<<<<<< 1.1777660228945799\n",
      ">>>>>step_norm<<<<<< 0.40138997001393406\n",
      ">>>>>step_norm<<<<<< 0.540359774129718\n",
      ">>>>>step_norm<<<<<< 0.4206847608946964\n",
      ">>>>>step_norm<<<<<< 0.5830979781049085\n",
      ">>>>>step_norm<<<<<< 0.8120343899812197\n",
      ">>>>>step_norm<<<<<< 0.7452339229002337\n",
      ">>>>>step_norm<<<<<< 0.3374449081716868\n",
      ">>>>>step_norm<<<<<< 1.0835471425252048\n",
      ">>>>>step_norm<<<<<< 0.44291374984315585\n",
      ">>>>>step_norm<<<<<< 0.43182280750040514\n",
      ">>>>>step_norm<<<<<< 0.47673071211700296\n",
      ">>>>>step_norm<<<<<< 0.46862491325587247\n",
      ">>>>>step_norm<<<<<< 0.44301276576824267\n",
      ">>>>>step_norm<<<<<< 0.5334541286904831\n",
      ">>>>>step_norm<<<<<< 0.30856332346559434\n",
      ">>>>>step_norm<<<<<< 0.9582778962216785\n",
      ">>>>>step_norm<<<<<< 0.5653290563502522\n",
      ">>>>>step_norm<<<<<< 0.5143636240846413\n",
      ">>>>>step_norm<<<<<< 0.3094843676026608\n",
      ">>>>>step_norm<<<<<< 0.6635949492119974\n",
      ">>>>>step_norm<<<<<< 0.6658011350517641\n",
      ">>>>>step_norm<<<<<< 1.0158040190011302\n",
      ">>>>>step_norm<<<<<< 0.8046416366502304\n",
      ">>>>>step_norm<<<<<< 1.325630928814715\n",
      ">>>>>step_norm<<<<<< 0.8144084371902756\n",
      ">>>>>step_norm<<<<<< 0.2712061350379015\n",
      ">>>>>step_norm<<<<<< 0.7352217575009324\n",
      ">>>>>step_norm<<<<<< 0.32074240784706787\n",
      ">>>>>step_norm<<<<<< 1.08593464186055\n",
      ">>>>>step_norm<<<<<< 0.3262591504848786\n",
      ">>>>>step_norm<<<<<< 0.6033122107774337\n",
      ">>>>>step_norm<<<<<< 2.231253655388517\n",
      ">>>>>step_norm<<<<<< 0.7035479186533271\n",
      ">>>>>step_norm<<<<<< 1.2159338223078877\n",
      ">>>>>step_norm<<<<<< 1.4191340837861592\n",
      ">>>>>step_norm<<<<<< 1.1637085406499343\n",
      ">>>>>step_norm<<<<<< 1.4079779202543903\n",
      ">>>>>step_norm<<<<<< 0.9138805341177392\n",
      ">>>>>step_norm<<<<<< 0.8999766278675492\n",
      ">>>>>step_norm<<<<<< 0.943933757236048\n",
      ">>>>>step_norm<<<<<< 1.1017844315084897\n",
      ">>>>>step_norm<<<<<< 0.6104208129010145\n",
      ">>>>>step_norm<<<<<< 0.49853980758266675\n",
      ">>>>>step_norm<<<<<< 1.1242185906751194\n",
      ">>>>>step_norm<<<<<< 0.7755475432650603\n",
      ">>>>>step_norm<<<<<< 0.3289127879566269\n",
      ">>>>>step_norm<<<<<< 1.1598948260478963\n",
      ">>>>>step_norm<<<<<< 1.0757500977434216\n",
      ">>>>>step_norm<<<<<< 1.0194604961758358\n",
      ">>>>>step_norm<<<<<< 0.9272671291680832\n",
      ">>>>>step_norm<<<<<< 0.4346879311522992\n",
      ">>>>>step_norm<<<<<< 0.7850757322121329\n",
      ">>>>>step_norm<<<<<< 1.0328215400995353\n",
      ">>>>>step_norm<<<<<< 0.6032213212333819\n",
      ">>>>>step_norm<<<<<< 1.3990503581527884\n",
      ">>>>>step_norm<<<<<< 1.1352218401207836\n",
      ">>>>>step_norm<<<<<< 0.5001177678249835\n",
      ">>>>>step_norm<<<<<< 0.5203010763793109\n",
      ">>>>>step_norm<<<<<< 0.6363589030677286\n",
      ">>>>>step_norm<<<<<< 0.4323455911474905\n",
      ">>>>>step_norm<<<<<< 1.613000725426171\n",
      ">>>>>step_norm<<<<<< 0.7854656877875609\n",
      ">>>>>step_norm<<<<<< 0.6387763564277407\n",
      ">>>>>step_norm<<<<<< 0.6249706311581306\n",
      ">>>>>step_norm<<<<<< 0.9867201455407489\n",
      ">>>>>step_norm<<<<<< 0.6044282004050536\n",
      ">>>>>step_norm<<<<<< 0.7504599090592506\n",
      ">>>>>step_norm<<<<<< 0.6049058897492147\n",
      ">>>>>step_norm<<<<<< 0.9684057658082672\n",
      ">>>>>step_norm<<<<<< 1.179199998481763\n",
      ">>>>>step_norm<<<<<< 0.4747671218234858\n",
      ">>>>>step_norm<<<<<< 0.8876982965246912\n",
      ">>>>>step_norm<<<<<< 0.9352926841678088\n",
      ">>>>>step_norm<<<<<< 0.7841487839940195\n",
      ">>>>>step_norm<<<<<< 1.0521544986036735\n",
      ">>>>>step_norm<<<<<< 1.0540213202057211\n",
      ">>>>>step_norm<<<<<< 1.655143139349964\n",
      ">>>>>step_norm<<<<<< 0.934434441193076\n",
      ">>>>>step_norm<<<<<< 0.5697115108155023\n",
      ">>>>>step_norm<<<<<< 0.7440504296797914\n",
      ">>>>>step_norm<<<<<< 0.5575204589764102\n",
      ">>>>>step_norm<<<<<< 1.6903768682195097\n",
      ">>>>>step_norm<<<<<< 1.0203394965744108\n",
      ">>>>>step_norm<<<<<< 1.0753345823563523\n",
      ">>>>>step_norm<<<<<< 0.5491505845742752\n",
      ">>>>>step_norm<<<<<< 1.291229388311852\n",
      ">>>>>step_norm<<<<<< 1.564479477049248\n",
      ">>>>>step_norm<<<<<< 0.45786266577647033\n",
      ">>>>>step_norm<<<<<< 0.783862816475702\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 5\n",
      ">>>>>step_norm<<<<<< 0.7776816592009955\n",
      ">>>>>step_norm<<<<<< 0.4881137526605877\n",
      ">>>>>step_norm<<<<<< 0.7198532036682674\n",
      ">>>>>step_norm<<<<<< 0.18733477370608814\n",
      ">>>>>step_norm<<<<<< 1.1240242937582596\n",
      ">>>>>step_norm<<<<<< 0.6256405141904781\n",
      ">>>>>step_norm<<<<<< 0.33684425172780813\n",
      ">>>>>step_norm<<<<<< 0.2932853422708365\n",
      ">>>>>step_norm<<<<<< 0.28153308561981444\n",
      ">>>>>step_norm<<<<<< 0.3485962213728354\n",
      ">>>>>step_norm<<<<<< 0.29780781474305135\n",
      ">>>>>step_norm<<<<<< 0.4035937640246264\n",
      ">>>>>step_norm<<<<<< 0.6761674373961264\n",
      ">>>>>step_norm<<<<<< 0.5387335122067894\n",
      ">>>>>step_norm<<<<<< 1.1343948133462316\n",
      ">>>>>step_norm<<<<<< 0.342625679509515\n",
      ">>>>>step_norm<<<<<< 1.6378442817286902\n",
      ">>>>>step_norm<<<<<< 0.4605733904710433\n",
      ">>>>>step_norm<<<<<< 0.5239274234175921\n",
      ">>>>>step_norm<<<<<< 0.2712669746497894\n",
      ">>>>>step_norm<<<<<< 0.5012595453795812\n",
      ">>>>>step_norm<<<<<< 0.18489182166305662\n",
      ">>>>>step_norm<<<<<< 0.4392492410570461\n",
      ">>>>>step_norm<<<<<< 0.5151209668913979\n",
      ">>>>>step_norm<<<<<< 0.36447020267431374\n",
      ">>>>>step_norm<<<<<< 0.5622736212844214\n",
      ">>>>>step_norm<<<<<< 0.43139131397107183\n",
      ">>>>>step_norm<<<<<< 1.0190664251651027\n",
      ">>>>>step_norm<<<<<< 1.1430749081613245\n",
      ">>>>>step_norm<<<<<< 0.4865208545920606\n",
      ">>>>>step_norm<<<<<< 0.31799994084054845\n",
      ">>>>>step_norm<<<<<< 0.15894450793081225\n",
      ">>>>>step_norm<<<<<< 0.37710495653990955\n",
      ">>>>>step_norm<<<<<< 0.2958224901383389\n",
      ">>>>>step_norm<<<<<< 0.7460050009672783\n",
      ">>>>>step_norm<<<<<< 0.5925515922600844\n",
      ">>>>>step_norm<<<<<< 0.45158561658377727\n",
      ">>>>>step_norm<<<<<< 0.8242186730551085\n",
      ">>>>>step_norm<<<<<< 0.16673907941138474\n",
      ">>>>>step_norm<<<<<< 0.3320836650090277\n",
      ">>>>>step_norm<<<<<< 0.15967936396510873\n",
      ">>>>>step_norm<<<<<< 0.7657736485381514\n",
      ">>>>>step_norm<<<<<< 1.0004321398355611\n",
      ">>>>>step_norm<<<<<< 0.9015027177228379\n",
      ">>>>>step_norm<<<<<< 0.4376413297104593\n",
      ">>>>>step_norm<<<<<< 0.31415054239506135\n",
      ">>>>>step_norm<<<<<< 0.8559635900452824\n",
      ">>>>>step_norm<<<<<< 0.7102480454334574\n",
      ">>>>>step_norm<<<<<< 0.8876165812018227\n",
      ">>>>>step_norm<<<<<< 0.5277589772792032\n",
      ">>>>>step_norm<<<<<< 1.0731358335573855\n",
      ">>>>>step_norm<<<<<< 0.18261944508761435\n",
      ">>>>>step_norm<<<<<< 0.5262197614379523\n",
      ">>>>>step_norm<<<<<< 0.3128186680381151\n",
      ">>>>>step_norm<<<<<< 0.5941557327646433\n",
      ">>>>>step_norm<<<<<< 0.8784391299744237\n",
      ">>>>>step_norm<<<<<< 0.6624263456066843\n",
      ">>>>>step_norm<<<<<< 1.2522947985261534\n",
      ">>>>>step_norm<<<<<< 1.0048405522345907\n",
      ">>>>>step_norm<<<<<< 0.36964290736915584\n",
      ">>>>>step_norm<<<<<< 1.1567977127894928\n",
      ">>>>>step_norm<<<<<< 0.5979878402575572\n",
      ">>>>>step_norm<<<<<< 0.39842222432341273\n",
      ">>>>>step_norm<<<<<< 0.7099833289548187\n",
      ">>>>>step_norm<<<<<< 0.5118043592429578\n",
      ">>>>>step_norm<<<<<< 0.5876472454825715\n",
      ">>>>>step_norm<<<<<< 1.2160890923458116\n",
      ">>>>>step_norm<<<<<< 0.4917511275989927\n",
      ">>>>>step_norm<<<<<< 0.8688489656551506\n",
      ">>>>>step_norm<<<<<< 0.8429592287255803\n",
      ">>>>>step_norm<<<<<< 0.3443846486480381\n",
      ">>>>>step_norm<<<<<< 0.7159910260075959\n",
      ">>>>>step_norm<<<<<< 0.9176698101594202\n",
      ">>>>>step_norm<<<<<< 0.5606192712381391\n",
      ">>>>>step_norm<<<<<< 0.2886026526345156\n",
      ">>>>>step_norm<<<<<< 0.29352088008756655\n",
      ">>>>>step_norm<<<<<< 0.20692501171147618\n",
      ">>>>>step_norm<<<<<< 0.6510564115434649\n",
      ">>>>>step_norm<<<<<< 0.26452016307223797\n",
      ">>>>>step_norm<<<<<< 0.34613684338191303\n",
      ">>>>>step_norm<<<<<< 0.48694637921804873\n",
      ">>>>>step_norm<<<<<< 0.5464023710451957\n",
      ">>>>>step_norm<<<<<< 0.5078079249339502\n",
      ">>>>>step_norm<<<<<< 0.5051051057420589\n",
      ">>>>>step_norm<<<<<< 0.36266933999449397\n",
      ">>>>>step_norm<<<<<< 0.8850895325692311\n",
      ">>>>>step_norm<<<<<< 0.6729902460642727\n",
      ">>>>>step_norm<<<<<< 1.079928914671992\n",
      ">>>>>step_norm<<<<<< 0.8708650286262366\n",
      ">>>>>step_norm<<<<<< 0.10998375918876259\n",
      ">>>>>step_norm<<<<<< 0.3560576814723462\n",
      ">>>>>step_norm<<<<<< 0.6159464523708884\n",
      ">>>>>step_norm<<<<<< 0.5334684396629372\n",
      ">>>>>step_norm<<<<<< 0.5696544748427261\n",
      ">>>>>step_norm<<<<<< 0.5264516277488576\n",
      ">>>>>step_norm<<<<<< 0.2978559062673776\n",
      ">>>>>step_norm<<<<<< 0.5574299195899389\n",
      ">>>>>step_norm<<<<<< 0.7166818893785819\n",
      ">>>>>step_norm<<<<<< 0.5622852201385768\n",
      ">>>>>step_norm<<<<<< 0.35914332098080276\n",
      ">>>>>step_norm<<<<<< 0.7809539584848483\n",
      ">>>>>step_norm<<<<<< 0.41291728149760343\n",
      ">>>>>step_norm<<<<<< 0.45816638304197355\n",
      ">>>>>step_norm<<<<<< 0.41094373535107304\n",
      ">>>>>step_norm<<<<<< 0.4626089256211363\n",
      ">>>>>step_norm<<<<<< 0.4108123486268204\n",
      ">>>>>step_norm<<<<<< 0.7716155901050633\n",
      ">>>>>step_norm<<<<<< 0.5051876797497471\n",
      ">>>>>step_norm<<<<<< 2.0138313659051175\n",
      ">>>>>step_norm<<<<<< 1.1717668869234725\n",
      ">>>>>step_norm<<<<<< 0.25416080503652627\n",
      ">>>>>step_norm<<<<<< 0.3065745633887761\n",
      ">>>>>step_norm<<<<<< 0.5502866429983316\n",
      ">>>>>step_norm<<<<<< 0.4487229858608505\n",
      ">>>>>step_norm<<<<<< 1.499011110284757\n",
      ">>>>>step_norm<<<<<< 0.3644896232155935\n",
      ">>>>>step_norm<<<<<< 0.49790816201996196\n",
      ">>>>>step_norm<<<<<< 0.8389156420671512\n",
      ">>>>>step_norm<<<<<< 0.3778417831101529\n",
      ">>>>>step_norm<<<<<< 0.42914579114805124\n",
      ">>>>>step_norm<<<<<< 0.947564158608626\n",
      ">>>>>step_norm<<<<<< 0.32786346404694017\n",
      ">>>>>step_norm<<<<<< 0.7538243840924603\n",
      ">>>>>step_norm<<<<<< 0.7169148552879948\n",
      ">>>>>step_norm<<<<<< 0.29159371245509\n",
      ">>>>>step_norm<<<<<< 0.619462994079584\n",
      ">>>>>step_norm<<<<<< 1.0404549339821483\n",
      ">>>>>step_norm<<<<<< 0.36137990915595286\n",
      ">>>>>step_norm<<<<<< 0.6050989224914959\n",
      ">>>>>step_norm<<<<<< 0.7250428994756347\n",
      ">>>>>step_norm<<<<<< 0.25677618183761064\n",
      ">>>>>step_norm<<<<<< 0.5502868377821075\n",
      ">>>>>step_norm<<<<<< 0.9570988851957081\n",
      ">>>>>step_norm<<<<<< 0.370814976595974\n",
      ">>>>>step_norm<<<<<< 0.42391985898475953\n",
      ">>>>>step_norm<<<<<< 0.7945086449228446\n",
      ">>>>>step_norm<<<<<< 0.6417362931943126\n",
      ">>>>>step_norm<<<<<< 0.2698893960276274\n",
      ">>>>>step_norm<<<<<< 0.1800278012168988\n",
      ">>>>>step_norm<<<<<< 0.9234927867236753\n",
      ">>>>>step_norm<<<<<< 0.4414334295434418\n",
      ">>>>>step_norm<<<<<< 1.5507050959347903\n",
      ">>>>>step_norm<<<<<< 1.1616824697421442\n",
      ">>>>>step_norm<<<<<< 0.4670855562190208\n",
      ">>>>>step_norm<<<<<< 0.2321787475220038\n",
      ">>>>>step_norm<<<<<< 0.3294065084253467\n",
      ">>>>>step_norm<<<<<< 0.6625162368999762\n",
      ">>>>>step_norm<<<<<< 0.2711551566053136\n",
      ">>>>>step_norm<<<<<< 0.472228199213365\n",
      ">>>>>step_norm<<<<<< 0.41661315722654074\n",
      ">>>>>step_norm<<<<<< 0.33699075844518384\n",
      ">>>>>step_norm<<<<<< 0.4699327137908481\n",
      ">>>>>step_norm<<<<<< 0.38214389881202604\n",
      ">>>>>step_norm<<<<<< 0.5219385752101958\n",
      ">>>>>step_norm<<<<<< 0.33486453015894274\n",
      ">>>>>step_norm<<<<<< 0.2754974832331395\n",
      ">>>>>step_norm<<<<<< 0.6059682749968682\n",
      ">>>>>step_norm<<<<<< 0.3195308214374001\n",
      ">>>>>step_norm<<<<<< 0.3844598012720854\n",
      ">>>>>step_norm<<<<<< 0.46164016848215494\n",
      ">>>>>step_norm<<<<<< 0.4017564505318763\n",
      ">>>>>step_norm<<<<<< 0.265523062288005\n",
      ">>>>>step_norm<<<<<< 0.17273303539975496\n",
      ">>>>>step_norm<<<<<< 0.5818538077740067\n",
      ">>>>>step_norm<<<<<< 0.22195045603794797\n",
      ">>>>>step_norm<<<<<< 0.2935536651008702\n",
      ">>>>>step_norm<<<<<< 1.1967856406210857\n",
      ">>>>>step_norm<<<<<< 0.9093793170900323\n",
      ">>>>>step_norm<<<<<< 0.39514870488076903\n",
      ">>>>>step_norm<<<<<< 0.5411322507225208\n",
      ">>>>>step_norm<<<<<< 1.1003304344753848\n",
      ">>>>>step_norm<<<<<< 0.2061355662890388\n",
      ">>>>>step_norm<<<<<< 0.46598930642790354\n",
      ">>>>>step_norm<<<<<< 0.3037072814117874\n",
      ">>>>>step_norm<<<<<< 0.31438224183505065\n",
      ">>>>>step_norm<<<<<< 0.2951769161407661\n",
      ">>>>>step_norm<<<<<< 0.34474733789524165\n",
      ">>>>>step_norm<<<<<< 0.3466773601325883\n",
      ">>>>>step_norm<<<<<< 0.2134239711790277\n",
      ">>>>>step_norm<<<<<< 0.2691461556427663\n",
      ">>>>>step_norm<<<<<< 0.37010697284352323\n",
      ">>>>>step_norm<<<<<< 0.1944831430670656\n",
      ">>>>>step_norm<<<<<< 0.37097384341881473\n",
      ">>>>>step_norm<<<<<< 0.5023867810931795\n",
      ">>>>>step_norm<<<<<< 0.31277709905357565\n",
      ">>>>>step_norm<<<<<< 0.5145808703859671\n",
      ">>>>>step_norm<<<<<< 0.6894015670899507\n",
      ">>>>>step_norm<<<<<< 0.5324842155969718\n",
      ">>>>>step_norm<<<<<< 0.3462178238087487\n",
      ">>>>>step_norm<<<<<< 0.7103382501308471\n",
      ">>>>>step_norm<<<<<< 0.2802068352493902\n",
      ">>>>>step_norm<<<<<< 0.6349235590516239\n",
      ">>>>>step_norm<<<<<< 0.30509050174866276\n",
      ">>>>>step_norm<<<<<< 0.4125177424807036\n",
      ">>>>>step_norm<<<<<< 0.3160164550834518\n",
      ">>>>>step_norm<<<<<< 0.35489819382754456\n",
      ">>>>>step_norm<<<<<< 0.29618612598493005\n",
      ">>>>>step_norm<<<<<< 0.5069771407957998\n",
      ">>>>>step_norm<<<<<< 0.8562269268607752\n",
      ">>>>>step_norm<<<<<< 0.2638796660644533\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 6\n",
      ">>>>>step_norm<<<<<< 0.4425427237942074\n",
      ">>>>>step_norm<<<<<< 1.2234834883950685\n",
      ">>>>>step_norm<<<<<< 0.6853373506737731\n",
      ">>>>>step_norm<<<<<< 0.7715940971329128\n",
      ">>>>>step_norm<<<<<< 0.5606286396747127\n",
      ">>>>>step_norm<<<<<< 0.3410800304731158\n",
      ">>>>>step_norm<<<<<< 0.2792027383138658\n",
      ">>>>>step_norm<<<<<< 0.23414442571501912\n",
      ">>>>>step_norm<<<<<< 0.24270016576132755\n",
      ">>>>>step_norm<<<<<< 0.39093359389844246\n",
      ">>>>>step_norm<<<<<< 1.4081817290459424\n",
      ">>>>>step_norm<<<<<< 0.6845807423012209\n",
      ">>>>>step_norm<<<<<< 0.8678645327984527\n",
      ">>>>>step_norm<<<<<< 0.4325918586859723\n",
      ">>>>>step_norm<<<<<< 0.6436558471624814\n",
      ">>>>>step_norm<<<<<< 0.7519767645790728\n",
      ">>>>>step_norm<<<<<< 0.7465414499248776\n",
      ">>>>>step_norm<<<<<< 0.2669431158502125\n",
      ">>>>>step_norm<<<<<< 0.5497236459041072\n",
      ">>>>>step_norm<<<<<< 0.295390152902218\n",
      ">>>>>step_norm<<<<<< 0.5321193362657125\n",
      ">>>>>step_norm<<<<<< 0.8471535615311259\n",
      ">>>>>step_norm<<<<<< 0.3182037305416665\n",
      ">>>>>step_norm<<<<<< 0.5269337192629143\n",
      ">>>>>step_norm<<<<<< 0.8260005665178829\n",
      ">>>>>step_norm<<<<<< 0.8756955670258921\n",
      ">>>>>step_norm<<<<<< 0.5581386727822957\n",
      ">>>>>step_norm<<<<<< 0.5578984498962452\n",
      ">>>>>step_norm<<<<<< 0.21103669464389055\n",
      ">>>>>step_norm<<<<<< 0.5588357338382008\n",
      ">>>>>step_norm<<<<<< 0.9455342663057673\n",
      ">>>>>step_norm<<<<<< 0.701451243818085\n",
      ">>>>>step_norm<<<<<< 0.46267680816134693\n",
      ">>>>>step_norm<<<<<< 0.8381936376397877\n",
      ">>>>>step_norm<<<<<< 0.33392720119439684\n",
      ">>>>>step_norm<<<<<< 0.2991958051111447\n",
      ">>>>>step_norm<<<<<< 1.3505722980392287\n",
      ">>>>>step_norm<<<<<< 1.269186134379418\n",
      ">>>>>step_norm<<<<<< 1.139203961042337\n",
      ">>>>>step_norm<<<<<< 0.4149330806252506\n",
      ">>>>>step_norm<<<<<< 0.5110884969544007\n",
      ">>>>>step_norm<<<<<< 0.30187992034064715\n",
      ">>>>>step_norm<<<<<< 0.21236416107168699\n",
      ">>>>>step_norm<<<<<< 0.689142944334874\n",
      ">>>>>step_norm<<<<<< 0.9533860599811167\n",
      ">>>>>step_norm<<<<<< 0.9800454501569144\n",
      ">>>>>step_norm<<<<<< 0.8672714435267461\n",
      ">>>>>step_norm<<<<<< 0.43004506718340857\n",
      ">>>>>step_norm<<<<<< 0.4402299223934464\n",
      ">>>>>step_norm<<<<<< 1.225863397195965\n",
      ">>>>>step_norm<<<<<< 0.325166855412415\n",
      ">>>>>step_norm<<<<<< 0.5487520270885853\n",
      ">>>>>step_norm<<<<<< 0.7214425245224152\n",
      ">>>>>step_norm<<<<<< 0.35413426025681327\n",
      ">>>>>step_norm<<<<<< 0.45737313949551583\n",
      ">>>>>step_norm<<<<<< 0.47722307623325033\n",
      ">>>>>step_norm<<<<<< 0.21626100700819212\n",
      ">>>>>step_norm<<<<<< 1.0825328840479098\n",
      ">>>>>step_norm<<<<<< 0.5182517898649747\n",
      ">>>>>step_norm<<<<<< 0.2951109386928373\n",
      ">>>>>step_norm<<<<<< 0.7785370597921151\n",
      ">>>>>step_norm<<<<<< 0.3255086068509699\n",
      ">>>>>step_norm<<<<<< 0.6667388172362452\n",
      ">>>>>step_norm<<<<<< 0.5578743532482228\n",
      ">>>>>step_norm<<<<<< 0.3290549898081926\n",
      ">>>>>step_norm<<<<<< 0.4648665800386488\n",
      ">>>>>step_norm<<<<<< 0.24196677130417685\n",
      ">>>>>step_norm<<<<<< 0.5575122915168822\n",
      ">>>>>step_norm<<<<<< 0.7350716893527433\n",
      ">>>>>step_norm<<<<<< 0.5821019047990473\n",
      ">>>>>step_norm<<<<<< 0.22672292166484584\n",
      ">>>>>step_norm<<<<<< 0.37405238676763747\n",
      ">>>>>step_norm<<<<<< 0.9470650601059357\n",
      ">>>>>step_norm<<<<<< 0.7104254537742721\n",
      ">>>>>step_norm<<<<<< 0.504518541892522\n",
      ">>>>>step_norm<<<<<< 0.6416416293264587\n",
      ">>>>>step_norm<<<<<< 0.36683774787533446\n",
      ">>>>>step_norm<<<<<< 0.41413230280699953\n",
      ">>>>>step_norm<<<<<< 0.996543693613791\n",
      ">>>>>step_norm<<<<<< 0.6876288205699882\n",
      ">>>>>step_norm<<<<<< 0.24384427751742\n",
      ">>>>>step_norm<<<<<< 0.7902005947247227\n",
      ">>>>>step_norm<<<<<< 0.8330558869762863\n",
      ">>>>>step_norm<<<<<< 0.36838640709788567\n",
      ">>>>>step_norm<<<<<< 0.2166063970500343\n",
      ">>>>>step_norm<<<<<< 0.5700733137367665\n",
      ">>>>>step_norm<<<<<< 0.17564311141767308\n",
      ">>>>>step_norm<<<<<< 0.8935411495391273\n",
      ">>>>>step_norm<<<<<< 0.5151113803082272\n",
      ">>>>>step_norm<<<<<< 0.42408740361975494\n",
      ">>>>>step_norm<<<<<< 0.5166747812547969\n",
      ">>>>>step_norm<<<<<< 0.36199505411799254\n",
      ">>>>>step_norm<<<<<< 0.9884675515624203\n",
      ">>>>>step_norm<<<<<< 0.893256916969738\n",
      ">>>>>step_norm<<<<<< 0.7155450796381162\n",
      ">>>>>step_norm<<<<<< 0.5903344972730099\n",
      ">>>>>step_norm<<<<<< 0.8768295548962852\n",
      ">>>>>step_norm<<<<<< 0.24855025476723253\n",
      ">>>>>step_norm<<<<<< 0.6898514135966234\n",
      ">>>>>step_norm<<<<<< 0.31441845051085043\n",
      ">>>>>step_norm<<<<<< 0.35523477158513805\n",
      ">>>>>step_norm<<<<<< 0.3641272892748563\n",
      ">>>>>step_norm<<<<<< 0.45927908637860904\n",
      ">>>>>step_norm<<<<<< 0.3691783359710342\n",
      ">>>>>step_norm<<<<<< 0.6628880600878639\n",
      ">>>>>step_norm<<<<<< 0.4822368794617705\n",
      ">>>>>step_norm<<<<<< 0.4543913403711398\n",
      ">>>>>step_norm<<<<<< 0.6912365605055992\n",
      ">>>>>step_norm<<<<<< 0.5902704786961831\n",
      ">>>>>step_norm<<<<<< 0.5731954083272075\n",
      ">>>>>step_norm<<<<<< 0.4043699329244442\n",
      ">>>>>step_norm<<<<<< 0.550675228609954\n",
      ">>>>>step_norm<<<<<< 0.25536687581480183\n",
      ">>>>>step_norm<<<<<< 0.2183588683160324\n",
      ">>>>>step_norm<<<<<< 0.4644461845471479\n",
      ">>>>>step_norm<<<<<< 0.8852396853059739\n",
      ">>>>>step_norm<<<<<< 0.8387603415037519\n",
      ">>>>>step_norm<<<<<< 0.546632798973521\n",
      ">>>>>step_norm<<<<<< 0.3442299607914076\n",
      ">>>>>step_norm<<<<<< 0.7100688899868386\n",
      ">>>>>step_norm<<<<<< 0.6342062310351916\n",
      ">>>>>step_norm<<<<<< 0.3392951660351601\n",
      ">>>>>step_norm<<<<<< 1.1596693826625386\n",
      ">>>>>step_norm<<<<<< 1.5852216172810205\n",
      ">>>>>step_norm<<<<<< 0.41700179717919617\n",
      ">>>>>step_norm<<<<<< 0.8520872229286518\n",
      ">>>>>step_norm<<<<<< 0.6900740760658132\n",
      ">>>>>step_norm<<<<<< 0.8373364992212273\n",
      ">>>>>step_norm<<<<<< 0.2529031459487509\n",
      ">>>>>step_norm<<<<<< 0.24419069699476667\n",
      ">>>>>step_norm<<<<<< 1.0805624052113803\n",
      ">>>>>step_norm<<<<<< 0.5852818996985016\n",
      ">>>>>step_norm<<<<<< 1.276592394479099\n",
      ">>>>>step_norm<<<<<< 0.42174020799697876\n",
      ">>>>>step_norm<<<<<< 0.260064898449015\n",
      ">>>>>step_norm<<<<<< 0.42565844227018634\n",
      ">>>>>step_norm<<<<<< 0.4796754170078762\n",
      ">>>>>step_norm<<<<<< 0.8742686757942416\n",
      ">>>>>step_norm<<<<<< 0.2760811263000195\n",
      ">>>>>step_norm<<<<<< 0.5201493259578203\n",
      ">>>>>step_norm<<<<<< 0.7157398405885934\n",
      ">>>>>step_norm<<<<<< 0.8092033109668288\n",
      ">>>>>step_norm<<<<<< 1.0785312716865858\n",
      ">>>>>step_norm<<<<<< 0.576795049224104\n",
      ">>>>>step_norm<<<<<< 0.6761113898589951\n",
      ">>>>>step_norm<<<<<< 0.32828040749184484\n",
      ">>>>>step_norm<<<<<< 0.6572539283825223\n",
      ">>>>>step_norm<<<<<< 0.2872147152684462\n",
      ">>>>>step_norm<<<<<< 0.5169558742705473\n",
      ">>>>>step_norm<<<<<< 0.41192761474975736\n",
      ">>>>>step_norm<<<<<< 0.7449421681960499\n",
      ">>>>>step_norm<<<<<< 0.9651775589332695\n",
      ">>>>>step_norm<<<<<< 0.2211970297938571\n",
      ">>>>>step_norm<<<<<< 1.2136313722421295\n",
      ">>>>>step_norm<<<<<< 0.5819654398284023\n",
      ">>>>>step_norm<<<<<< 0.6028485826531521\n",
      ">>>>>step_norm<<<<<< 0.9081423112084103\n",
      ">>>>>step_norm<<<<<< 1.4600242949700928\n",
      ">>>>>step_norm<<<<<< 0.35622146993362724\n",
      ">>>>>step_norm<<<<<< 0.7446043835142722\n",
      ">>>>>step_norm<<<<<< 0.5327728030906458\n",
      ">>>>>step_norm<<<<<< 0.47106082860924076\n",
      ">>>>>step_norm<<<<<< 0.31315148446397717\n",
      ">>>>>step_norm<<<<<< 0.433997864008414\n",
      ">>>>>step_norm<<<<<< 0.28390874054082893\n",
      ">>>>>step_norm<<<<<< 0.504881148912981\n",
      ">>>>>step_norm<<<<<< 0.550129834190821\n",
      ">>>>>step_norm<<<<<< 0.5728323327606695\n",
      ">>>>>step_norm<<<<<< 0.3992386379369187\n",
      ">>>>>step_norm<<<<<< 0.29611877617930843\n",
      ">>>>>step_norm<<<<<< 0.6804032736442588\n",
      ">>>>>step_norm<<<<<< 0.41301401660387965\n",
      ">>>>>step_norm<<<<<< 0.42398141413502916\n",
      ">>>>>step_norm<<<<<< 0.3486492405724904\n",
      ">>>>>step_norm<<<<<< 0.5637118743071627\n",
      ">>>>>step_norm<<<<<< 0.3205861390612831\n",
      ">>>>>step_norm<<<<<< 0.6652322029301277\n",
      ">>>>>step_norm<<<<<< 0.4004874548118698\n",
      ">>>>>step_norm<<<<<< 0.8755485036158779\n",
      ">>>>>step_norm<<<<<< 0.2736866631383514\n",
      ">>>>>step_norm<<<<<< 0.5530677075504374\n",
      ">>>>>step_norm<<<<<< 0.9631740371837277\n",
      ">>>>>step_norm<<<<<< 0.4437695889599648\n",
      ">>>>>step_norm<<<<<< 0.22598111332080134\n",
      ">>>>>step_norm<<<<<< 0.2886051277360288\n",
      ">>>>>step_norm<<<<<< 0.7676293665351023\n",
      ">>>>>step_norm<<<<<< 0.5370421130605543\n",
      ">>>>>step_norm<<<<<< 1.1256568181393865\n",
      ">>>>>step_norm<<<<<< 0.11752840401769823\n",
      ">>>>>step_norm<<<<<< 0.791607231853211\n",
      ">>>>>step_norm<<<<<< 0.2039648970256254\n",
      ">>>>>step_norm<<<<<< 0.23852916216191447\n",
      ">>>>>step_norm<<<<<< 0.6260772802924403\n",
      ">>>>>step_norm<<<<<< 0.44963552128815976\n",
      ">>>>>step_norm<<<<<< 0.6260639745097083\n",
      ">>>>>step_norm<<<<<< 0.2960552328191307\n",
      ">>>>>step_norm<<<<<< 0.43754584407374936\n",
      ">>>>>step_norm<<<<<< 1.4876376929295585\n",
      ">>>>>step_norm<<<<<< 0.14754456426876908\n",
      ">>>>>step_norm<<<<<< 0.806153121804811\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 7\n",
      ">>>>>step_norm<<<<<< 0.5638454716651832\n",
      ">>>>>step_norm<<<<<< 0.5597224110614267\n",
      ">>>>>step_norm<<<<<< 0.39773748853279617\n",
      ">>>>>step_norm<<<<<< 0.7567642837771361\n",
      ">>>>>step_norm<<<<<< 0.3334913889082554\n",
      ">>>>>step_norm<<<<<< 0.5436541239693783\n",
      ">>>>>step_norm<<<<<< 0.552658355140055\n",
      ">>>>>step_norm<<<<<< 0.299504419633655\n",
      ">>>>>step_norm<<<<<< 0.34935552489004107\n",
      ">>>>>step_norm<<<<<< 0.47192701627920863\n",
      ">>>>>step_norm<<<<<< 0.26083005415576066\n",
      ">>>>>step_norm<<<<<< 0.7125179709577164\n",
      ">>>>>step_norm<<<<<< 1.2968461107852707\n",
      ">>>>>step_norm<<<<<< 0.4258296078006347\n",
      ">>>>>step_norm<<<<<< 0.6617639531922809\n",
      ">>>>>step_norm<<<<<< 0.79764200229578\n",
      ">>>>>step_norm<<<<<< 0.3686338722417396\n",
      ">>>>>step_norm<<<<<< 0.563649182798614\n",
      ">>>>>step_norm<<<<<< 0.7187512805117556\n",
      ">>>>>step_norm<<<<<< 0.40749678292531194\n",
      ">>>>>step_norm<<<<<< 0.27627036248095704\n",
      ">>>>>step_norm<<<<<< 0.27521234863593563\n",
      ">>>>>step_norm<<<<<< 0.9603636887913272\n",
      ">>>>>step_norm<<<<<< 1.3087526957865037\n",
      ">>>>>step_norm<<<<<< 0.6083690148435856\n",
      ">>>>>step_norm<<<<<< 0.46090836358331205\n",
      ">>>>>step_norm<<<<<< 0.6431704547580993\n",
      ">>>>>step_norm<<<<<< 0.6265097354943925\n",
      ">>>>>step_norm<<<<<< 0.19005290652157467\n",
      ">>>>>step_norm<<<<<< 1.514817302718394\n",
      ">>>>>step_norm<<<<<< 0.7141767536198927\n",
      ">>>>>step_norm<<<<<< 0.8937049154715916\n",
      ">>>>>step_norm<<<<<< 0.4437791337707784\n",
      ">>>>>step_norm<<<<<< 0.9958644001947087\n",
      ">>>>>step_norm<<<<<< 0.5967149655564236\n",
      ">>>>>step_norm<<<<<< 0.18841954719775414\n",
      ">>>>>step_norm<<<<<< 0.23771638721289953\n",
      ">>>>>step_norm<<<<<< 0.39671573812045346\n",
      ">>>>>step_norm<<<<<< 0.4767084091081992\n",
      ">>>>>step_norm<<<<<< 0.3535099878351225\n",
      ">>>>>step_norm<<<<<< 0.5413606714880429\n",
      ">>>>>step_norm<<<<<< 0.24052705277872782\n",
      ">>>>>step_norm<<<<<< 0.9137915055689105\n",
      ">>>>>step_norm<<<<<< 1.196619101376993\n",
      ">>>>>step_norm<<<<<< 0.19738539473596925\n",
      ">>>>>step_norm<<<<<< 0.7157601392966039\n",
      ">>>>>step_norm<<<<<< 0.40535564697057286\n",
      ">>>>>step_norm<<<<<< 0.640270266106144\n",
      ">>>>>step_norm<<<<<< 0.24953191767679092\n",
      ">>>>>step_norm<<<<<< 1.150952912803349\n",
      ">>>>>step_norm<<<<<< 0.4712593900019233\n",
      ">>>>>step_norm<<<<<< 0.7316584415127996\n",
      ">>>>>step_norm<<<<<< 0.2433844228339119\n",
      ">>>>>step_norm<<<<<< 1.3957772713226475\n",
      ">>>>>step_norm<<<<<< 0.322643600060002\n",
      ">>>>>step_norm<<<<<< 0.6134131963399642\n",
      ">>>>>step_norm<<<<<< 0.7546823845808082\n",
      ">>>>>step_norm<<<<<< 0.4534846707656383\n",
      ">>>>>step_norm<<<<<< 0.2573831445271427\n",
      ">>>>>step_norm<<<<<< 0.936649109867636\n",
      ">>>>>step_norm<<<<<< 0.5833715740868782\n",
      ">>>>>step_norm<<<<<< 0.5028470075420055\n",
      ">>>>>step_norm<<<<<< 0.8795802285700383\n",
      ">>>>>step_norm<<<<<< 0.43356285615772694\n",
      ">>>>>step_norm<<<<<< 0.33245860924502535\n",
      ">>>>>step_norm<<<<<< 0.3786215615609101\n",
      ">>>>>step_norm<<<<<< 0.2893538055047508\n",
      ">>>>>step_norm<<<<<< 0.8779339879542742\n",
      ">>>>>step_norm<<<<<< 0.44545475865155576\n",
      ">>>>>step_norm<<<<<< 0.6557471125894766\n",
      ">>>>>step_norm<<<<<< 0.15953296300406403\n",
      ">>>>>step_norm<<<<<< 0.47002162861663155\n",
      ">>>>>step_norm<<<<<< 0.29208886402021195\n",
      ">>>>>step_norm<<<<<< 0.6879235498191092\n",
      ">>>>>step_norm<<<<<< 0.6133671208903447\n",
      ">>>>>step_norm<<<<<< 0.6387378298166102\n",
      ">>>>>step_norm<<<<<< 0.5135759975291269\n",
      ">>>>>step_norm<<<<<< 0.43200757407382556\n",
      ">>>>>step_norm<<<<<< 0.2533790436339895\n",
      ">>>>>step_norm<<<<<< 0.30869116914301253\n",
      ">>>>>step_norm<<<<<< 0.3484028274650568\n",
      ">>>>>step_norm<<<<<< 0.25599041586954635\n",
      ">>>>>step_norm<<<<<< 0.2449719444427835\n",
      ">>>>>step_norm<<<<<< 0.2505658657929908\n",
      ">>>>>step_norm<<<<<< 0.3008778878359322\n",
      ">>>>>step_norm<<<<<< 0.24015942902390267\n",
      ">>>>>step_norm<<<<<< 0.2579441852034783\n",
      ">>>>>step_norm<<<<<< 0.49590902966143896\n",
      ">>>>>step_norm<<<<<< 0.5916652648110667\n",
      ">>>>>step_norm<<<<<< 0.3961026361195926\n",
      ">>>>>step_norm<<<<<< 0.3689944763734987\n",
      ">>>>>step_norm<<<<<< 0.18785994860532837\n",
      ">>>>>step_norm<<<<<< 0.5095695569509191\n",
      ">>>>>step_norm<<<<<< 0.517707160160372\n",
      ">>>>>step_norm<<<<<< 0.537127353366563\n",
      ">>>>>step_norm<<<<<< 0.38136422847011575\n",
      ">>>>>step_norm<<<<<< 0.31198729055984376\n",
      ">>>>>step_norm<<<<<< 0.23370979040584258\n",
      ">>>>>step_norm<<<<<< 0.959053757545398\n",
      ">>>>>step_norm<<<<<< 0.5280983024653368\n",
      ">>>>>step_norm<<<<<< 0.3283767781925525\n",
      ">>>>>step_norm<<<<<< 0.37015339916315304\n",
      ">>>>>step_norm<<<<<< 0.16711153510591636\n",
      ">>>>>step_norm<<<<<< 1.5508369033779401\n",
      ">>>>>step_norm<<<<<< 0.45203809326834177\n",
      ">>>>>step_norm<<<<<< 0.2464237858555423\n",
      ">>>>>step_norm<<<<<< 0.7645512916617023\n",
      ">>>>>step_norm<<<<<< 0.3819288582913807\n",
      ">>>>>step_norm<<<<<< 0.8850272763468855\n",
      ">>>>>step_norm<<<<<< 1.4260059694930276\n",
      ">>>>>step_norm<<<<<< 0.6830133380520438\n",
      ">>>>>step_norm<<<<<< 0.4711900612264724\n",
      ">>>>>step_norm<<<<<< 0.311424362748095\n",
      ">>>>>step_norm<<<<<< 0.24036107853411254\n",
      ">>>>>step_norm<<<<<< 0.37672196221279985\n",
      ">>>>>step_norm<<<<<< 0.6116019647136733\n",
      ">>>>>step_norm<<<<<< 0.30250821310426945\n",
      ">>>>>step_norm<<<<<< 0.4657580868507077\n",
      ">>>>>step_norm<<<<<< 0.2943391379487917\n",
      ">>>>>step_norm<<<<<< 0.34897404653683733\n",
      ">>>>>step_norm<<<<<< 0.34071052552654585\n",
      ">>>>>step_norm<<<<<< 0.5909566996216743\n",
      ">>>>>step_norm<<<<<< 0.40947695357865094\n",
      ">>>>>step_norm<<<<<< 0.3623714658378317\n",
      ">>>>>step_norm<<<<<< 0.481590519882135\n",
      ">>>>>step_norm<<<<<< 0.40935842337372763\n",
      ">>>>>step_norm<<<<<< 1.000246026386085\n",
      ">>>>>step_norm<<<<<< 0.27788120927418614\n",
      ">>>>>step_norm<<<<<< 0.7817553405903567\n",
      ">>>>>step_norm<<<<<< 0.847508104170376\n",
      ">>>>>step_norm<<<<<< 0.4916099328204963\n",
      ">>>>>step_norm<<<<<< 0.585983951769207\n",
      ">>>>>step_norm<<<<<< 0.2035177158963079\n",
      ">>>>>step_norm<<<<<< 0.4808382065070035\n",
      ">>>>>step_norm<<<<<< 0.33175707278370475\n",
      ">>>>>step_norm<<<<<< 0.24826104883260192\n",
      ">>>>>step_norm<<<<<< 0.3361846826924021\n",
      ">>>>>step_norm<<<<<< 0.7444118585069588\n",
      ">>>>>step_norm<<<<<< 0.3831810209536705\n",
      ">>>>>step_norm<<<<<< 0.2789231718788978\n",
      ">>>>>step_norm<<<<<< 1.0706123096096696\n",
      ">>>>>step_norm<<<<<< 0.21373246451541045\n",
      ">>>>>step_norm<<<<<< 0.23004008618478639\n",
      ">>>>>step_norm<<<<<< 1.0273352405600535\n",
      ">>>>>step_norm<<<<<< 0.21884846445252723\n",
      ">>>>>step_norm<<<<<< 0.29535973167777935\n",
      ">>>>>step_norm<<<<<< 0.22501893896251232\n",
      ">>>>>step_norm<<<<<< 0.24032788608725666\n",
      ">>>>>step_norm<<<<<< 0.637777002968114\n",
      ">>>>>step_norm<<<<<< 0.49333444829549394\n",
      ">>>>>step_norm<<<<<< 0.6609260337236728\n",
      ">>>>>step_norm<<<<<< 1.3171055726583483\n",
      ">>>>>step_norm<<<<<< 0.8085661493080505\n",
      ">>>>>step_norm<<<<<< 0.8268984046953833\n",
      ">>>>>step_norm<<<<<< 0.3786603603253417\n",
      ">>>>>step_norm<<<<<< 0.42882777228045277\n",
      ">>>>>step_norm<<<<<< 0.6764578869763826\n",
      ">>>>>step_norm<<<<<< 0.26719122162720543\n",
      ">>>>>step_norm<<<<<< 0.24122790300406036\n",
      ">>>>>step_norm<<<<<< 0.4011710521629687\n",
      ">>>>>step_norm<<<<<< 0.5066794392221322\n",
      ">>>>>step_norm<<<<<< 0.3785584182229395\n",
      ">>>>>step_norm<<<<<< 0.2280147077619106\n",
      ">>>>>step_norm<<<<<< 0.4377696198945591\n",
      ">>>>>step_norm<<<<<< 0.8953834841642045\n",
      ">>>>>step_norm<<<<<< 0.24430360396229595\n",
      ">>>>>step_norm<<<<<< 0.16799136840578746\n",
      ">>>>>step_norm<<<<<< 0.5020329823317565\n",
      ">>>>>step_norm<<<<<< 0.7435726458817696\n",
      ">>>>>step_norm<<<<<< 0.6954695557912017\n",
      ">>>>>step_norm<<<<<< 0.33331845051200454\n",
      ">>>>>step_norm<<<<<< 0.2457207360345425\n",
      ">>>>>step_norm<<<<<< 0.737082586234617\n",
      ">>>>>step_norm<<<<<< 0.5350328625158498\n",
      ">>>>>step_norm<<<<<< 0.5080392451378967\n",
      ">>>>>step_norm<<<<<< 0.3820781720099829\n",
      ">>>>>step_norm<<<<<< 0.5659066659887901\n",
      ">>>>>step_norm<<<<<< 0.3994488774354633\n",
      ">>>>>step_norm<<<<<< 0.5841962266446711\n",
      ">>>>>step_norm<<<<<< 0.3055345842699834\n",
      ">>>>>step_norm<<<<<< 0.4389296980430913\n",
      ">>>>>step_norm<<<<<< 0.4269471776339485\n",
      ">>>>>step_norm<<<<<< 0.6385958690376796\n",
      ">>>>>step_norm<<<<<< 0.4652172246180414\n",
      ">>>>>step_norm<<<<<< 0.22061981386939614\n",
      ">>>>>step_norm<<<<<< 0.7178554341236733\n",
      ">>>>>step_norm<<<<<< 1.0002595252371955\n",
      ">>>>>step_norm<<<<<< 0.23366135976568095\n",
      ">>>>>step_norm<<<<<< 0.39872332678375805\n",
      ">>>>>step_norm<<<<<< 0.20288747281591507\n",
      ">>>>>step_norm<<<<<< 0.5762341601719565\n",
      ">>>>>step_norm<<<<<< 0.43752510404892375\n",
      ">>>>>step_norm<<<<<< 0.46936777060784474\n",
      ">>>>>step_norm<<<<<< 0.3172879208526347\n",
      ">>>>>step_norm<<<<<< 0.518024815618718\n",
      ">>>>>step_norm<<<<<< 0.7769845037105639\n",
      ">>>>>step_norm<<<<<< 0.8655315577445087\n",
      ">>>>>step_norm<<<<<< 0.2743916330686447\n",
      ">>>>>step_norm<<<<<< 0.8397635185979891\n",
      ">>>>>step_norm<<<<<< 0.28282606907142527\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 8\n",
      ">>>>>step_norm<<<<<< 0.5127265004189033\n",
      ">>>>>step_norm<<<<<< 0.9452109768504783\n",
      ">>>>>step_norm<<<<<< 0.289627114751466\n",
      ">>>>>step_norm<<<<<< 0.23473049038173932\n",
      ">>>>>step_norm<<<<<< 0.7060706782507433\n",
      ">>>>>step_norm<<<<<< 1.323397856659643\n",
      ">>>>>step_norm<<<<<< 0.36645264424168816\n",
      ">>>>>step_norm<<<<<< 0.21583628490638165\n",
      ">>>>>step_norm<<<<<< 0.3132772539205335\n",
      ">>>>>step_norm<<<<<< 1.1308380053197358\n",
      ">>>>>step_norm<<<<<< 0.5973015442429895\n",
      ">>>>>step_norm<<<<<< 0.4008809238533987\n",
      ">>>>>step_norm<<<<<< 1.219727804399504\n",
      ">>>>>step_norm<<<<<< 0.8244242421008428\n",
      ">>>>>step_norm<<<<<< 0.5746931096169462\n",
      ">>>>>step_norm<<<<<< 0.528233283574053\n",
      ">>>>>step_norm<<<<<< 0.7606044644057973\n",
      ">>>>>step_norm<<<<<< 0.4679927826909353\n",
      ">>>>>step_norm<<<<<< 0.8886485287696042\n",
      ">>>>>step_norm<<<<<< 0.5307279602807041\n",
      ">>>>>step_norm<<<<<< 0.6968337972538834\n",
      ">>>>>step_norm<<<<<< 0.7520595420968498\n",
      ">>>>>step_norm<<<<<< 0.6590846700550029\n",
      ">>>>>step_norm<<<<<< 0.3626851394079567\n",
      ">>>>>step_norm<<<<<< 0.5646599571975238\n",
      ">>>>>step_norm<<<<<< 0.6798521812221526\n",
      ">>>>>step_norm<<<<<< 0.557181604582449\n",
      ">>>>>step_norm<<<<<< 0.6560771572894512\n",
      ">>>>>step_norm<<<<<< 0.5875838944780896\n",
      ">>>>>step_norm<<<<<< 0.5598448848507366\n",
      ">>>>>step_norm<<<<<< 0.628727499213684\n",
      ">>>>>step_norm<<<<<< 0.8201061920702057\n",
      ">>>>>step_norm<<<<<< 0.5813581911940938\n",
      ">>>>>step_norm<<<<<< 0.3492255796264617\n",
      ">>>>>step_norm<<<<<< 0.466006913308437\n",
      ">>>>>step_norm<<<<<< 0.6344837710170751\n",
      ">>>>>step_norm<<<<<< 0.5270097861644584\n",
      ">>>>>step_norm<<<<<< 0.5862446697136807\n",
      ">>>>>step_norm<<<<<< 0.8474058742950724\n",
      ">>>>>step_norm<<<<<< 1.8834718770965753\n",
      ">>>>>step_norm<<<<<< 0.4030322318475664\n",
      ">>>>>step_norm<<<<<< 0.8475065198731382\n",
      ">>>>>step_norm<<<<<< 1.1262720036042708\n",
      ">>>>>step_norm<<<<<< 1.8557221772193413\n",
      ">>>>>step_norm<<<<<< 0.6910332711137193\n",
      ">>>>>step_norm<<<<<< 1.6896726183260105\n",
      ">>>>>step_norm<<<<<< 1.0016674561227044\n",
      ">>>>>step_norm<<<<<< 0.4152630897225563\n",
      ">>>>>step_norm<<<<<< 0.9059192744607445\n",
      ">>>>>step_norm<<<<<< 1.0446251784302933\n",
      ">>>>>step_norm<<<<<< 1.538482072325221\n",
      ">>>>>step_norm<<<<<< 0.35778625023129584\n",
      ">>>>>step_norm<<<<<< 1.2297510619610725\n",
      ">>>>>step_norm<<<<<< 1.069806135332146\n",
      ">>>>>step_norm<<<<<< 0.5662371300712766\n",
      ">>>>>step_norm<<<<<< 1.3795293589334718\n",
      ">>>>>step_norm<<<<<< 0.3982768693881935\n",
      ">>>>>step_norm<<<<<< 0.2595951535114268\n",
      ">>>>>step_norm<<<<<< 0.9970847376264196\n",
      ">>>>>step_norm<<<<<< 0.5430328123676206\n",
      ">>>>>step_norm<<<<<< 0.7571633937847039\n",
      ">>>>>step_norm<<<<<< 0.2721569940341538\n",
      ">>>>>step_norm<<<<<< 0.3390217315287094\n",
      ">>>>>step_norm<<<<<< 0.5456702995256637\n",
      ">>>>>step_norm<<<<<< 0.2305877769727459\n",
      ">>>>>step_norm<<<<<< 0.9382959756500695\n",
      ">>>>>step_norm<<<<<< 0.5172405383074352\n",
      ">>>>>step_norm<<<<<< 0.4100379261744955\n",
      ">>>>>step_norm<<<<<< 1.1738141099755217\n",
      ">>>>>step_norm<<<<<< 0.7097807185468737\n",
      ">>>>>step_norm<<<<<< 0.855551723891938\n",
      ">>>>>step_norm<<<<<< 0.4810838508134044\n",
      ">>>>>step_norm<<<<<< 0.4191113040785747\n",
      ">>>>>step_norm<<<<<< 0.5019993865060437\n",
      ">>>>>step_norm<<<<<< 0.5871930566886874\n",
      ">>>>>step_norm<<<<<< 1.0655126024797978\n",
      ">>>>>step_norm<<<<<< 0.43703642177282825\n",
      ">>>>>step_norm<<<<<< 0.540628458320113\n",
      ">>>>>step_norm<<<<<< 0.5616685538584224\n",
      ">>>>>step_norm<<<<<< 0.8137326430957719\n",
      ">>>>>step_norm<<<<<< 0.48235874326548356\n",
      ">>>>>step_norm<<<<<< 0.4546973029631022\n",
      ">>>>>step_norm<<<<<< 0.5050156583455007\n",
      ">>>>>step_norm<<<<<< 0.6283316291645095\n",
      ">>>>>step_norm<<<<<< 0.9596877612021734\n",
      ">>>>>step_norm<<<<<< 0.7575749745042232\n",
      ">>>>>step_norm<<<<<< 0.46222209260546626\n",
      ">>>>>step_norm<<<<<< 0.3791526944496865\n",
      ">>>>>step_norm<<<<<< 0.5690616209689191\n",
      ">>>>>step_norm<<<<<< 0.7591336865010058\n",
      ">>>>>step_norm<<<<<< 1.0985036514241282\n",
      ">>>>>step_norm<<<<<< 0.5687526838483155\n",
      ">>>>>step_norm<<<<<< 0.816503389091753\n",
      ">>>>>step_norm<<<<<< 0.5089798144780305\n",
      ">>>>>step_norm<<<<<< 0.7601400831429304\n",
      ">>>>>step_norm<<<<<< 0.7288706476012136\n",
      ">>>>>step_norm<<<<<< 0.39283227107478447\n",
      ">>>>>step_norm<<<<<< 0.7991540006617369\n",
      ">>>>>step_norm<<<<<< 0.6768979829936017\n",
      ">>>>>step_norm<<<<<< 0.6360050169613752\n",
      ">>>>>step_norm<<<<<< 1.7176477408148156\n",
      ">>>>>step_norm<<<<<< 0.5780201679588172\n",
      ">>>>>step_norm<<<<<< 1.2490230249935261\n",
      ">>>>>step_norm<<<<<< 0.3440996757048292\n",
      ">>>>>step_norm<<<<<< 0.5212637481471531\n",
      ">>>>>step_norm<<<<<< 1.1867756490508585\n",
      ">>>>>step_norm<<<<<< 0.7970172783753436\n",
      ">>>>>step_norm<<<<<< 0.4850696533310156\n",
      ">>>>>step_norm<<<<<< 0.5921750159793552\n",
      ">>>>>step_norm<<<<<< 0.6119018824692358\n",
      ">>>>>step_norm<<<<<< 0.527309743466722\n",
      ">>>>>step_norm<<<<<< 0.453909951835453\n",
      ">>>>>step_norm<<<<<< 0.7604304874475861\n",
      ">>>>>step_norm<<<<<< 0.5842921439824235\n",
      ">>>>>step_norm<<<<<< 1.2924159128416963\n",
      ">>>>>step_norm<<<<<< 0.5364165120605413\n",
      ">>>>>step_norm<<<<<< 0.727296521378873\n",
      ">>>>>step_norm<<<<<< 0.6666908849025831\n",
      ">>>>>step_norm<<<<<< 0.4455895234039462\n",
      ">>>>>step_norm<<<<<< 0.5834373734502771\n",
      ">>>>>step_norm<<<<<< 0.8884151543270208\n",
      ">>>>>step_norm<<<<<< 0.43086069706765195\n",
      ">>>>>step_norm<<<<<< 0.7104600960528222\n",
      ">>>>>step_norm<<<<<< 1.0281113356837814\n",
      ">>>>>step_norm<<<<<< 0.9086746949275479\n",
      ">>>>>step_norm<<<<<< 0.42328712417387293\n",
      ">>>>>step_norm<<<<<< 1.1181524054628742\n",
      ">>>>>step_norm<<<<<< 0.34364765290788474\n",
      ">>>>>step_norm<<<<<< 1.0266743419796076\n",
      ">>>>>step_norm<<<<<< 0.5754267863721316\n",
      ">>>>>step_norm<<<<<< 0.5772256684434973\n",
      ">>>>>step_norm<<<<<< 1.3191176632401556\n",
      ">>>>>step_norm<<<<<< 0.532185692149348\n",
      ">>>>>step_norm<<<<<< 0.8428807769681729\n",
      ">>>>>step_norm<<<<<< 0.8568652291720463\n",
      ">>>>>step_norm<<<<<< 0.5772591044965171\n",
      ">>>>>step_norm<<<<<< 0.811649865399472\n",
      ">>>>>step_norm<<<<<< 0.5162474415093055\n",
      ">>>>>step_norm<<<<<< 1.3735498654008398\n",
      ">>>>>step_norm<<<<<< 0.8853877275717498\n",
      ">>>>>step_norm<<<<<< 0.5392498729546295\n",
      ">>>>>step_norm<<<<<< 1.084573735685749\n",
      ">>>>>step_norm<<<<<< 0.6811917661031743\n",
      ">>>>>step_norm<<<<<< 0.39415312935861424\n",
      ">>>>>step_norm<<<<<< 0.5008147828547104\n",
      ">>>>>step_norm<<<<<< 0.6046373623842672\n",
      ">>>>>step_norm<<<<<< 0.744349733161327\n",
      ">>>>>step_norm<<<<<< 0.5274487832494518\n",
      ">>>>>step_norm<<<<<< 0.8817233921071045\n",
      ">>>>>step_norm<<<<<< 0.8590031990871884\n",
      ">>>>>step_norm<<<<<< 0.5548184893403538\n",
      ">>>>>step_norm<<<<<< 0.331987237621981\n",
      ">>>>>step_norm<<<<<< 0.5099035267681032\n",
      ">>>>>step_norm<<<<<< 0.6390473156132835\n",
      ">>>>>step_norm<<<<<< 0.44307569009149295\n",
      ">>>>>step_norm<<<<<< 0.3110354511822271\n",
      ">>>>>step_norm<<<<<< 0.46557600035444574\n",
      ">>>>>step_norm<<<<<< 0.9158943436347172\n",
      ">>>>>step_norm<<<<<< 0.2728188798578353\n",
      ">>>>>step_norm<<<<<< 0.4812154318933383\n",
      ">>>>>step_norm<<<<<< 1.4720966373100042\n",
      ">>>>>step_norm<<<<<< 0.7451015553988446\n",
      ">>>>>step_norm<<<<<< 0.3953021126993409\n",
      ">>>>>step_norm<<<<<< 0.5958491026208004\n",
      ">>>>>step_norm<<<<<< 0.43364517289345095\n",
      ">>>>>step_norm<<<<<< 0.3866450791511336\n",
      ">>>>>step_norm<<<<<< 1.3568217877231072\n",
      ">>>>>step_norm<<<<<< 0.24265500067729998\n",
      ">>>>>step_norm<<<<<< 1.6082341650422132\n",
      ">>>>>step_norm<<<<<< 0.5688994104642673\n",
      ">>>>>step_norm<<<<<< 0.45851489538113577\n",
      ">>>>>step_norm<<<<<< 0.9677109303066399\n",
      ">>>>>step_norm<<<<<< 1.1704482974974413\n",
      ">>>>>step_norm<<<<<< 0.565983902296601\n",
      ">>>>>step_norm<<<<<< 1.5903345633683972\n",
      ">>>>>step_norm<<<<<< 0.392080359200333\n",
      ">>>>>step_norm<<<<<< 0.3783298729681724\n",
      ">>>>>step_norm<<<<<< 0.8454365909355972\n",
      ">>>>>step_norm<<<<<< 0.6900969781202657\n",
      ">>>>>step_norm<<<<<< 0.8030315939269884\n",
      ">>>>>step_norm<<<<<< 0.9194261016404863\n",
      ">>>>>step_norm<<<<<< 0.7031307881225468\n",
      ">>>>>step_norm<<<<<< 0.9467997127851518\n",
      ">>>>>step_norm<<<<<< 1.0784768182411877\n",
      ">>>>>step_norm<<<<<< 1.2565918732769434\n",
      ">>>>>step_norm<<<<<< 0.6535082897087963\n",
      ">>>>>step_norm<<<<<< 0.5673235698508163\n",
      ">>>>>step_norm<<<<<< 1.1828646706171342\n",
      ">>>>>step_norm<<<<<< 0.5561808387649024\n",
      ">>>>>step_norm<<<<<< 1.0941099372626666\n",
      ">>>>>step_norm<<<<<< 0.3356967815679485\n",
      ">>>>>step_norm<<<<<< 0.4925521900923935\n",
      ">>>>>step_norm<<<<<< 0.26585592381962925\n",
      ">>>>>step_norm<<<<<< 0.5324534285390465\n",
      ">>>>>step_norm<<<<<< 0.986669672020024\n",
      ">>>>>step_norm<<<<<< 0.7341993756792013\n",
      ">>>>>step_norm<<<<<< 0.6396689821548228\n",
      ">>>>>step_norm<<<<<< 0.9246627481486089\n",
      ">>>>>step_norm<<<<<< 0.7024824980196742\n",
      ">>>>>step_norm<<<<<< 1.3520412855336992\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 9\n",
      ">>>>>step_norm<<<<<< 0.14354102455913106\n",
      ">>>>>step_norm<<<<<< 0.40095171726099355\n",
      ">>>>>step_norm<<<<<< 0.39264294466847643\n",
      ">>>>>step_norm<<<<<< 1.0068418892687103\n",
      ">>>>>step_norm<<<<<< 0.5293378834408753\n",
      ">>>>>step_norm<<<<<< 0.848828728836164\n",
      ">>>>>step_norm<<<<<< 0.8327383354204915\n",
      ">>>>>step_norm<<<<<< 0.6950419578612121\n",
      ">>>>>step_norm<<<<<< 0.5491297081149731\n",
      ">>>>>step_norm<<<<<< 0.478512458194202\n",
      ">>>>>step_norm<<<<<< 0.701755923995827\n",
      ">>>>>step_norm<<<<<< 0.5094192018844313\n",
      ">>>>>step_norm<<<<<< 0.32636007559918473\n",
      ">>>>>step_norm<<<<<< 0.8935283446447656\n",
      ">>>>>step_norm<<<<<< 0.15719061823183372\n",
      ">>>>>step_norm<<<<<< 0.40845720521143786\n",
      ">>>>>step_norm<<<<<< 0.08728081060257356\n",
      ">>>>>step_norm<<<<<< 0.29603094999741963\n",
      ">>>>>step_norm<<<<<< 0.3088421979499774\n",
      ">>>>>step_norm<<<<<< 0.1943446977313273\n",
      ">>>>>step_norm<<<<<< 0.48216108995326806\n",
      ">>>>>step_norm<<<<<< 0.75179488146625\n",
      ">>>>>step_norm<<<<<< 0.5573740978626118\n",
      ">>>>>step_norm<<<<<< 0.3033692153955225\n",
      ">>>>>step_norm<<<<<< 0.3860264527099731\n",
      ">>>>>step_norm<<<<<< 0.19969881305632706\n",
      ">>>>>step_norm<<<<<< 1.2132833935525387\n",
      ">>>>>step_norm<<<<<< 0.33738531604129873\n",
      ">>>>>step_norm<<<<<< 0.714576344058041\n",
      ">>>>>step_norm<<<<<< 0.3480226061604957\n",
      ">>>>>step_norm<<<<<< 0.36118368598622463\n",
      ">>>>>step_norm<<<<<< 0.7817058726201418\n",
      ">>>>>step_norm<<<<<< 0.41705071506488167\n",
      ">>>>>step_norm<<<<<< 0.5426794838742746\n",
      ">>>>>step_norm<<<<<< 0.11999346577376506\n",
      ">>>>>step_norm<<<<<< 0.18721443433337145\n",
      ">>>>>step_norm<<<<<< 0.522721268298533\n",
      ">>>>>step_norm<<<<<< 0.3973831010097125\n",
      ">>>>>step_norm<<<<<< 0.2065368849425064\n",
      ">>>>>step_norm<<<<<< 0.9990329803506536\n",
      ">>>>>step_norm<<<<<< 0.48757183318137043\n",
      ">>>>>step_norm<<<<<< 0.42360212002078895\n",
      ">>>>>step_norm<<<<<< 0.20114453919925554\n",
      ">>>>>step_norm<<<<<< 0.1669563768147734\n",
      ">>>>>step_norm<<<<<< 0.5095749125571519\n",
      ">>>>>step_norm<<<<<< 0.21398174670234416\n",
      ">>>>>step_norm<<<<<< 0.8507435845022984\n",
      ">>>>>step_norm<<<<<< 0.2026579894310789\n",
      ">>>>>step_norm<<<<<< 0.22844113597763194\n",
      ">>>>>step_norm<<<<<< 0.162106211771761\n",
      ">>>>>step_norm<<<<<< 0.2922727766360777\n",
      ">>>>>step_norm<<<<<< 0.25376650470511003\n",
      ">>>>>step_norm<<<<<< 1.0288997912567586\n",
      ">>>>>step_norm<<<<<< 0.24387605233403561\n",
      ">>>>>step_norm<<<<<< 0.2436190798624755\n",
      ">>>>>step_norm<<<<<< 0.6405284826054493\n",
      ">>>>>step_norm<<<<<< 0.44812687861469064\n",
      ">>>>>step_norm<<<<<< 0.7078527438268887\n",
      ">>>>>step_norm<<<<<< 0.5270730379370258\n",
      ">>>>>step_norm<<<<<< 0.9689528275033178\n",
      ">>>>>step_norm<<<<<< 0.3474949987847223\n",
      ">>>>>step_norm<<<<<< 0.20375696339073207\n",
      ">>>>>step_norm<<<<<< 0.22272846846683614\n",
      ">>>>>step_norm<<<<<< 0.32855954961185285\n",
      ">>>>>step_norm<<<<<< 0.957103715509382\n",
      ">>>>>step_norm<<<<<< 0.3826490998101539\n",
      ">>>>>step_norm<<<<<< 1.733562929598498\n",
      ">>>>>step_norm<<<<<< 0.48890775039398227\n",
      ">>>>>step_norm<<<<<< 0.22525250751845705\n",
      ">>>>>step_norm<<<<<< 0.5456617268602179\n",
      ">>>>>step_norm<<<<<< 0.6213480177096773\n",
      ">>>>>step_norm<<<<<< 0.124693429399648\n",
      ">>>>>step_norm<<<<<< 0.215084111336973\n",
      ">>>>>step_norm<<<<<< 0.41051940198575504\n",
      ">>>>>step_norm<<<<<< 0.6912108504676361\n",
      ">>>>>step_norm<<<<<< 0.4077936498534599\n",
      ">>>>>step_norm<<<<<< 0.3141679737905054\n",
      ">>>>>step_norm<<<<<< 0.7525228034463922\n",
      ">>>>>step_norm<<<<<< 0.16233230216819144\n",
      ">>>>>step_norm<<<<<< 0.4945178112401089\n",
      ">>>>>step_norm<<<<<< 0.8896597194297341\n",
      ">>>>>step_norm<<<<<< 0.3191784863958059\n",
      ">>>>>step_norm<<<<<< 0.2474553071988496\n",
      ">>>>>step_norm<<<<<< 0.1813265237963112\n",
      ">>>>>step_norm<<<<<< 0.9518696671410714\n",
      ">>>>>step_norm<<<<<< 0.5541561089720058\n",
      ">>>>>step_norm<<<<<< 0.3872284784975381\n",
      ">>>>>step_norm<<<<<< 0.6839849094478803\n",
      ">>>>>step_norm<<<<<< 0.33733750538461\n",
      ">>>>>step_norm<<<<<< 0.49352737500763744\n",
      ">>>>>step_norm<<<<<< 0.5310595833465608\n",
      ">>>>>step_norm<<<<<< 0.2681738494923033\n",
      ">>>>>step_norm<<<<<< 0.5870540376265961\n",
      ">>>>>step_norm<<<<<< 1.0493646107052284\n",
      ">>>>>step_norm<<<<<< 1.0641946172777523\n",
      ">>>>>step_norm<<<<<< 0.5564297143759224\n",
      ">>>>>step_norm<<<<<< 0.8191256621705196\n",
      ">>>>>step_norm<<<<<< 0.47884485809554667\n",
      ">>>>>step_norm<<<<<< 0.34085027890547503\n",
      ">>>>>step_norm<<<<<< 0.6293172199261751\n",
      ">>>>>step_norm<<<<<< 0.42569667125520905\n",
      ">>>>>step_norm<<<<<< 0.506627682632779\n",
      ">>>>>step_norm<<<<<< 0.6180563977410789\n",
      ">>>>>step_norm<<<<<< 0.41511128173458467\n",
      ">>>>>step_norm<<<<<< 0.7257463798935946\n",
      ">>>>>step_norm<<<<<< 0.6795725360808986\n",
      ">>>>>step_norm<<<<<< 0.5656702776582053\n",
      ">>>>>step_norm<<<<<< 0.9489585744445721\n",
      ">>>>>step_norm<<<<<< 1.2380980218241846\n",
      ">>>>>step_norm<<<<<< 0.7620707527630524\n",
      ">>>>>step_norm<<<<<< 0.5490569606168474\n",
      ">>>>>step_norm<<<<<< 0.3031870604063143\n",
      ">>>>>step_norm<<<<<< 0.3906852478439318\n",
      ">>>>>step_norm<<<<<< 0.2285539785118125\n",
      ">>>>>step_norm<<<<<< 0.7914861076325285\n",
      ">>>>>step_norm<<<<<< 0.4007494101093359\n",
      ">>>>>step_norm<<<<<< 1.3535638551395555\n",
      ">>>>>step_norm<<<<<< 0.21985012871458884\n",
      ">>>>>step_norm<<<<<< 0.5754098263275185\n",
      ">>>>>step_norm<<<<<< 0.2132769764720371\n",
      ">>>>>step_norm<<<<<< 0.3091225741634446\n",
      ">>>>>step_norm<<<<<< 0.7236818116930029\n",
      ">>>>>step_norm<<<<<< 0.9463402836227726\n",
      ">>>>>step_norm<<<<<< 0.37409369373986023\n",
      ">>>>>step_norm<<<<<< 0.4052197492420987\n",
      ">>>>>step_norm<<<<<< 0.4503150150339952\n",
      ">>>>>step_norm<<<<<< 0.5980332490952694\n",
      ">>>>>step_norm<<<<<< 0.4407342793164534\n",
      ">>>>>step_norm<<<<<< 0.2220641872718644\n",
      ">>>>>step_norm<<<<<< 0.31605943100842454\n",
      ">>>>>step_norm<<<<<< 0.7890257597383343\n",
      ">>>>>step_norm<<<<<< 0.30740288565511986\n",
      ">>>>>step_norm<<<<<< 0.26073213304923615\n",
      ">>>>>step_norm<<<<<< 0.32967720842744935\n",
      ">>>>>step_norm<<<<<< 0.32984955744279576\n",
      ">>>>>step_norm<<<<<< 0.5085128467918989\n",
      ">>>>>step_norm<<<<<< 0.5931262973615393\n",
      ">>>>>step_norm<<<<<< 0.3675229326745024\n",
      ">>>>>step_norm<<<<<< 0.40215002673459826\n",
      ">>>>>step_norm<<<<<< 1.5699447994640263\n",
      ">>>>>step_norm<<<<<< 0.4938819844500327\n",
      ">>>>>step_norm<<<<<< 0.4133761111259438\n",
      ">>>>>step_norm<<<<<< 0.8355344362456358\n",
      ">>>>>step_norm<<<<<< 1.6587580048244561\n",
      ">>>>>step_norm<<<<<< 1.0314268500766175\n",
      ">>>>>step_norm<<<<<< 0.21520716532925122\n",
      ">>>>>step_norm<<<<<< 0.47954249365653023\n",
      ">>>>>step_norm<<<<<< 0.24950099865598124\n",
      ">>>>>step_norm<<<<<< 0.49094150239475726\n",
      ">>>>>step_norm<<<<<< 1.7113287461937043\n",
      ">>>>>step_norm<<<<<< 0.34579806743002084\n",
      ">>>>>step_norm<<<<<< 0.3713331842153915\n",
      ">>>>>step_norm<<<<<< 0.8517715880358653\n",
      ">>>>>step_norm<<<<<< 0.37296947514640894\n",
      ">>>>>step_norm<<<<<< 0.6196848821017371\n",
      ">>>>>step_norm<<<<<< 0.18315826746615926\n",
      ">>>>>step_norm<<<<<< 0.9038910730810421\n",
      ">>>>>step_norm<<<<<< 0.6013506823715348\n",
      ">>>>>step_norm<<<<<< 0.368837410868257\n",
      ">>>>>step_norm<<<<<< 0.5649790580342362\n",
      ">>>>>step_norm<<<<<< 0.6652685405359658\n",
      ">>>>>step_norm<<<<<< 0.4715177173121368\n",
      ">>>>>step_norm<<<<<< 0.7159908537139593\n",
      ">>>>>step_norm<<<<<< 0.5828965418395682\n",
      ">>>>>step_norm<<<<<< 0.6579734782683705\n",
      ">>>>>step_norm<<<<<< 0.3833061212568697\n",
      ">>>>>step_norm<<<<<< 0.34635216802705904\n",
      ">>>>>step_norm<<<<<< 0.20478269302903995\n",
      ">>>>>step_norm<<<<<< 0.1916489020534672\n",
      ">>>>>step_norm<<<<<< 0.5264840232386325\n",
      ">>>>>step_norm<<<<<< 0.47170208294881805\n",
      ">>>>>step_norm<<<<<< 0.636105459855886\n",
      ">>>>>step_norm<<<<<< 0.18059127520911872\n",
      ">>>>>step_norm<<<<<< 0.47744697706692807\n",
      ">>>>>step_norm<<<<<< 0.48070572868743544\n",
      ">>>>>step_norm<<<<<< 1.4507994046245714\n",
      ">>>>>step_norm<<<<<< 0.5015006529516001\n",
      ">>>>>step_norm<<<<<< 0.7460012892593831\n",
      ">>>>>step_norm<<<<<< 0.4594781843850419\n",
      ">>>>>step_norm<<<<<< 0.5398533735478486\n",
      ">>>>>step_norm<<<<<< 0.7964291591913669\n",
      ">>>>>step_norm<<<<<< 0.5152070838614938\n",
      ">>>>>step_norm<<<<<< 0.38810486641239367\n",
      ">>>>>step_norm<<<<<< 0.20818199577664323\n",
      ">>>>>step_norm<<<<<< 0.40257876321798514\n",
      ">>>>>step_norm<<<<<< 0.2376165344497826\n",
      ">>>>>step_norm<<<<<< 1.0084319489282372\n",
      ">>>>>step_norm<<<<<< 0.5946945581056521\n",
      ">>>>>step_norm<<<<<< 0.311954905946478\n",
      ">>>>>step_norm<<<<<< 0.20723597225059234\n",
      ">>>>>step_norm<<<<<< 0.7920850835405024\n",
      ">>>>>step_norm<<<<<< 0.4066294044650836\n",
      ">>>>>step_norm<<<<<< 0.43527717037925123\n",
      ">>>>>step_norm<<<<<< 0.48432130885545505\n",
      ">>>>>step_norm<<<<<< 0.5755100595500873\n",
      ">>>>>step_norm<<<<<< 0.7972891706600894\n",
      ">>>>>step_norm<<<<<< 0.3316032684707206\n",
      ">>>>>step_norm<<<<<< 0.43422775211520825\n",
      ">>>>>step_norm<<<<<< 0.351558762307768\n",
      ">>>>>step_norm<<<<<< 0.9865139863545407\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 10\n",
      ">>>>>step_norm<<<<<< 0.6980957607453188\n",
      ">>>>>step_norm<<<<<< 0.3867258777934852\n",
      ">>>>>step_norm<<<<<< 0.2590299746525974\n",
      ">>>>>step_norm<<<<<< 0.30049821349133876\n",
      ">>>>>step_norm<<<<<< 0.44410597794897705\n",
      ">>>>>step_norm<<<<<< 0.5322725745443854\n",
      ">>>>>step_norm<<<<<< 0.5806828110010882\n",
      ">>>>>step_norm<<<<<< 0.3796367714505316\n",
      ">>>>>step_norm<<<<<< 0.30073652940706136\n",
      ">>>>>step_norm<<<<<< 0.5039845059685534\n",
      ">>>>>step_norm<<<<<< 0.33570524449794775\n",
      ">>>>>step_norm<<<<<< 1.2156801537789228\n",
      ">>>>>step_norm<<<<<< 0.6082797067221698\n",
      ">>>>>step_norm<<<<<< 0.9934958280725013\n",
      ">>>>>step_norm<<<<<< 0.9100595873352314\n",
      ">>>>>step_norm<<<<<< 1.1621832261546654\n",
      ">>>>>step_norm<<<<<< 0.7184810297754135\n",
      ">>>>>step_norm<<<<<< 0.3430837504032127\n",
      ">>>>>step_norm<<<<<< 0.9847407603311618\n",
      ">>>>>step_norm<<<<<< 1.4432808611388541\n",
      ">>>>>step_norm<<<<<< 0.296840502897226\n",
      ">>>>>step_norm<<<<<< 0.5473836576663552\n",
      ">>>>>step_norm<<<<<< 1.1648855150690345\n",
      ">>>>>step_norm<<<<<< 1.8241257606583925\n",
      ">>>>>step_norm<<<<<< 0.35232834423370035\n",
      ">>>>>step_norm<<<<<< 0.45928490240737985\n",
      ">>>>>step_norm<<<<<< 0.3308991619139666\n",
      ">>>>>step_norm<<<<<< 0.36518665627581287\n",
      ">>>>>step_norm<<<<<< 0.7769451902884407\n",
      ">>>>>step_norm<<<<<< 0.513194037560075\n",
      ">>>>>step_norm<<<<<< 0.42726778854680136\n",
      ">>>>>step_norm<<<<<< 1.1858083157607169\n",
      ">>>>>step_norm<<<<<< 0.4961018877855987\n",
      ">>>>>step_norm<<<<<< 1.178483736855571\n",
      ">>>>>step_norm<<<<<< 0.3955448970998432\n",
      ">>>>>step_norm<<<<<< 0.7543854548678478\n",
      ">>>>>step_norm<<<<<< 0.8282345488626792\n",
      ">>>>>step_norm<<<<<< 0.3191329580645005\n",
      ">>>>>step_norm<<<<<< 0.2235733435490542\n",
      ">>>>>step_norm<<<<<< 0.6412777316699368\n",
      ">>>>>step_norm<<<<<< 0.4523450783981143\n",
      ">>>>>step_norm<<<<<< 0.5449453166664003\n",
      ">>>>>step_norm<<<<<< 0.44456995236961394\n",
      ">>>>>step_norm<<<<<< 0.475619386100837\n",
      ">>>>>step_norm<<<<<< 0.8325620966225966\n",
      ">>>>>step_norm<<<<<< 0.6266697717775348\n",
      ">>>>>step_norm<<<<<< 0.3061760697042218\n",
      ">>>>>step_norm<<<<<< 0.5710465307319671\n",
      ">>>>>step_norm<<<<<< 0.5122691923379392\n",
      ">>>>>step_norm<<<<<< 0.5699977057583074\n",
      ">>>>>step_norm<<<<<< 0.42711550722513447\n",
      ">>>>>step_norm<<<<<< 0.38269218031871455\n",
      ">>>>>step_norm<<<<<< 0.3940712024215432\n",
      ">>>>>step_norm<<<<<< 0.7640422669962246\n",
      ">>>>>step_norm<<<<<< 0.48466265881799764\n",
      ">>>>>step_norm<<<<<< 1.2975807955610823\n",
      ">>>>>step_norm<<<<<< 0.8487938410685631\n",
      ">>>>>step_norm<<<<<< 0.2979311693813754\n",
      ">>>>>step_norm<<<<<< 1.0062216563585216\n",
      ">>>>>step_norm<<<<<< 1.0671467172469433\n",
      ">>>>>step_norm<<<<<< 0.3187830198583672\n",
      ">>>>>step_norm<<<<<< 0.2208845539536099\n",
      ">>>>>step_norm<<<<<< 0.687912622805954\n",
      ">>>>>step_norm<<<<<< 0.8585495761520984\n",
      ">>>>>step_norm<<<<<< 1.5033805994372544\n",
      ">>>>>step_norm<<<<<< 0.5497912348283949\n",
      ">>>>>step_norm<<<<<< 0.8127889702495944\n",
      ">>>>>step_norm<<<<<< 0.4638626718221169\n",
      ">>>>>step_norm<<<<<< 1.4976690318532249\n",
      ">>>>>step_norm<<<<<< 0.19532962981038687\n",
      ">>>>>step_norm<<<<<< 0.7461084286239792\n",
      ">>>>>step_norm<<<<<< 0.7025311336320684\n",
      ">>>>>step_norm<<<<<< 0.3845390701013605\n",
      ">>>>>step_norm<<<<<< 0.35935498634748225\n",
      ">>>>>step_norm<<<<<< 0.27873840436650554\n",
      ">>>>>step_norm<<<<<< 0.6890384087021142\n",
      ">>>>>step_norm<<<<<< 0.7416535013731415\n",
      ">>>>>step_norm<<<<<< 0.8074195838315628\n",
      ">>>>>step_norm<<<<<< 0.5476232117945214\n",
      ">>>>>step_norm<<<<<< 0.3585389508591843\n",
      ">>>>>step_norm<<<<<< 0.35519112209464293\n",
      ">>>>>step_norm<<<<<< 0.34134036982777066\n",
      ">>>>>step_norm<<<<<< 0.8645018272524422\n",
      ">>>>>step_norm<<<<<< 1.1857215289711331\n",
      ">>>>>step_norm<<<<<< 0.6839869689020487\n",
      ">>>>>step_norm<<<<<< 0.5741207884727534\n",
      ">>>>>step_norm<<<<<< 0.5253451469478452\n",
      ">>>>>step_norm<<<<<< 0.37055548854118375\n",
      ">>>>>step_norm<<<<<< 0.540090559380872\n",
      ">>>>>step_norm<<<<<< 0.43666466934255455\n",
      ">>>>>step_norm<<<<<< 0.7063437406173726\n",
      ">>>>>step_norm<<<<<< 0.6568373486563581\n",
      ">>>>>step_norm<<<<<< 0.2826679371474069\n",
      ">>>>>step_norm<<<<<< 0.3873764176729866\n",
      ">>>>>step_norm<<<<<< 0.6047246519993106\n",
      ">>>>>step_norm<<<<<< 0.33557747084440587\n",
      ">>>>>step_norm<<<<<< 0.3542623031149279\n",
      ">>>>>step_norm<<<<<< 0.491149809525258\n",
      ">>>>>step_norm<<<<<< 0.5199653532914078\n",
      ">>>>>step_norm<<<<<< 0.7389250277212794\n",
      ">>>>>step_norm<<<<<< 0.8250541480172157\n",
      ">>>>>step_norm<<<<<< 0.5603226455450426\n",
      ">>>>>step_norm<<<<<< 0.39928271339395244\n",
      ">>>>>step_norm<<<<<< 0.6270902702214433\n",
      ">>>>>step_norm<<<<<< 0.2514939435354648\n",
      ">>>>>step_norm<<<<<< 0.9623329709051649\n",
      ">>>>>step_norm<<<<<< 4.16989351491207\n",
      ">>>>>step_norm<<<<<< 0.5054086747156784\n",
      ">>>>>step_norm<<<<<< 0.6353592674683802\n",
      ">>>>>step_norm<<<<<< 0.23126040798159828\n",
      ">>>>>step_norm<<<<<< 0.6913624109290071\n",
      ">>>>>step_norm<<<<<< 0.5164041987196364\n",
      ">>>>>step_norm<<<<<< 0.4517848584541442\n",
      ">>>>>step_norm<<<<<< 0.32839700819063355\n",
      ">>>>>step_norm<<<<<< 0.3911296647489552\n",
      ">>>>>step_norm<<<<<< 0.25802957767260687\n",
      ">>>>>step_norm<<<<<< 0.34282958456375556\n",
      ">>>>>step_norm<<<<<< 0.6189159186353776\n",
      ">>>>>step_norm<<<<<< 0.7876285144067323\n",
      ">>>>>step_norm<<<<<< 0.6021898737883682\n",
      ">>>>>step_norm<<<<<< 0.6958262502759497\n",
      ">>>>>step_norm<<<<<< 0.49130104029527694\n",
      ">>>>>step_norm<<<<<< 0.5707724563386192\n",
      ">>>>>step_norm<<<<<< 0.5957963803162191\n",
      ">>>>>step_norm<<<<<< 1.0593446326340699\n",
      ">>>>>step_norm<<<<<< 0.712129318340504\n",
      ">>>>>step_norm<<<<<< 0.6063259028156981\n",
      ">>>>>step_norm<<<<<< 1.9569715582417495\n",
      ">>>>>step_norm<<<<<< 3.3990553967872796\n",
      ">>>>>step_norm<<<<<< 0.7112743093753938\n",
      ">>>>>step_norm<<<<<< 0.6222030237407545\n",
      ">>>>>step_norm<<<<<< 0.9001614935518317\n",
      ">>>>>step_norm<<<<<< 0.2800699634351231\n",
      ">>>>>step_norm<<<<<< 0.6832542333477634\n",
      ">>>>>step_norm<<<<<< 0.46022154233868623\n",
      ">>>>>step_norm<<<<<< 0.5348406585782951\n",
      ">>>>>step_norm<<<<<< 1.069285350887583\n",
      ">>>>>step_norm<<<<<< 0.8304524311359682\n",
      ">>>>>step_norm<<<<<< 1.8144833572448233\n",
      ">>>>>step_norm<<<<<< 1.4033000027402251\n",
      ">>>>>step_norm<<<<<< 0.6580289689569347\n",
      ">>>>>step_norm<<<<<< 0.5652880439899457\n",
      ">>>>>step_norm<<<<<< 1.7275475467926436\n",
      ">>>>>step_norm<<<<<< 0.7737736672911173\n",
      ">>>>>step_norm<<<<<< 0.6698209873581507\n",
      ">>>>>step_norm<<<<<< 0.37567282224762344\n",
      ">>>>>step_norm<<<<<< 0.9702453190748974\n",
      ">>>>>step_norm<<<<<< 0.5178700337090418\n",
      ">>>>>step_norm<<<<<< 1.2999284418985926\n",
      ">>>>>step_norm<<<<<< 0.41606129361115707\n",
      ">>>>>step_norm<<<<<< 0.7506912547536025\n",
      ">>>>>step_norm<<<<<< 0.6343506800113072\n",
      ">>>>>step_norm<<<<<< 0.6849462046482756\n",
      ">>>>>step_norm<<<<<< 2.348450274496595\n",
      ">>>>>step_norm<<<<<< 1.6708854457480915\n",
      ">>>>>step_norm<<<<<< 1.6739607790438322\n",
      ">>>>>step_norm<<<<<< 0.9732324615269239\n",
      ">>>>>step_norm<<<<<< 0.5547148774850394\n",
      ">>>>>step_norm<<<<<< 0.7487303798724145\n",
      ">>>>>step_norm<<<<<< 0.9068251412316767\n",
      ">>>>>step_norm<<<<<< 3.179843930383451\n",
      ">>>>>step_norm<<<<<< 0.9367481307952948\n",
      ">>>>>step_norm<<<<<< 0.8486472198279088\n",
      ">>>>>step_norm<<<<<< 1.4399477042403226\n",
      ">>>>>step_norm<<<<<< 0.6072295220422906\n",
      ">>>>>step_norm<<<<<< 0.4064394177135668\n",
      ">>>>>step_norm<<<<<< 1.457209393062105\n",
      ">>>>>step_norm<<<<<< 0.5330835686968763\n",
      ">>>>>step_norm<<<<<< 1.5755703910816623\n",
      ">>>>>step_norm<<<<<< 0.5830649266769286\n",
      ">>>>>step_norm<<<<<< 1.426055695026887\n",
      ">>>>>step_norm<<<<<< 1.0705432275227775\n",
      ">>>>>step_norm<<<<<< 2.9688334064334536\n",
      ">>>>>step_norm<<<<<< 0.38281358542379174\n",
      ">>>>>step_norm<<<<<< 0.5925367392526006\n",
      ">>>>>step_norm<<<<<< 0.8032564042174575\n",
      ">>>>>step_norm<<<<<< 0.6980413535238754\n",
      ">>>>>step_norm<<<<<< 0.532621716857306\n",
      ">>>>>step_norm<<<<<< 2.3357580196449352\n",
      ">>>>>step_norm<<<<<< 0.7798658255191335\n",
      ">>>>>step_norm<<<<<< 0.5606270315180384\n",
      ">>>>>step_norm<<<<<< 0.7258398019456732\n",
      ">>>>>step_norm<<<<<< 0.939984104254779\n",
      ">>>>>step_norm<<<<<< 0.5291523142557223\n",
      ">>>>>step_norm<<<<<< 1.0785641047032226\n",
      ">>>>>step_norm<<<<<< 0.6089166103251374\n",
      ">>>>>step_norm<<<<<< 1.1455282005623662\n",
      ">>>>>step_norm<<<<<< 0.5524049424224206\n",
      ">>>>>step_norm<<<<<< 2.762462773194291\n",
      ">>>>>step_norm<<<<<< 0.9140898178416119\n",
      ">>>>>step_norm<<<<<< 0.6650145195563253\n",
      ">>>>>step_norm<<<<<< 0.6063269236544521\n",
      ">>>>>step_norm<<<<<< 0.642006566332673\n",
      ">>>>>step_norm<<<<<< 1.2115835288523202\n",
      ">>>>>step_norm<<<<<< 1.0132147373269775\n",
      ">>>>>step_norm<<<<<< 0.6214538688408443\n",
      ">>>>>step_norm<<<<<< 0.9878475205087505\n",
      ">>>>>step_norm<<<<<< 0.9449815958307819\n",
      ">>>>>step_norm<<<<<< 1.1970338709178954\n",
      ">>>>>step_norm<<<<<< 0.2697656978685531\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 11\n",
      ">>>>>step_norm<<<<<< 0.9523667281571364\n",
      ">>>>>step_norm<<<<<< 0.5004277565090023\n",
      ">>>>>step_norm<<<<<< 0.26579230809488164\n",
      ">>>>>step_norm<<<<<< 0.3952739284027329\n",
      ">>>>>step_norm<<<<<< 0.4120413616985008\n",
      ">>>>>step_norm<<<<<< 1.0945464727204377\n",
      ">>>>>step_norm<<<<<< 1.3616235895083468\n",
      ">>>>>step_norm<<<<<< 0.4037407109709475\n",
      ">>>>>step_norm<<<<<< 0.6700681522780191\n",
      ">>>>>step_norm<<<<<< 0.5370080390038791\n",
      ">>>>>step_norm<<<<<< 1.337042672749314\n",
      ">>>>>step_norm<<<<<< 1.6263645593839071\n",
      ">>>>>step_norm<<<<<< 0.6731696872512803\n",
      ">>>>>step_norm<<<<<< 0.6822293458026669\n",
      ">>>>>step_norm<<<<<< 0.5674775521580543\n",
      ">>>>>step_norm<<<<<< 1.2341461780466885\n",
      ">>>>>step_norm<<<<<< 0.17825753364528085\n",
      ">>>>>step_norm<<<<<< 0.5200539276874634\n",
      ">>>>>step_norm<<<<<< 0.4232083777650026\n",
      ">>>>>step_norm<<<<<< 1.1764468314569667\n",
      ">>>>>step_norm<<<<<< 0.4704373188304138\n",
      ">>>>>step_norm<<<<<< 0.42882721454275896\n",
      ">>>>>step_norm<<<<<< 0.42587647866998884\n",
      ">>>>>step_norm<<<<<< 0.3745381015747389\n",
      ">>>>>step_norm<<<<<< 0.40830716320708826\n",
      ">>>>>step_norm<<<<<< 1.2418623565126103\n",
      ">>>>>step_norm<<<<<< 0.3155609521835216\n",
      ">>>>>step_norm<<<<<< 0.476787782840478\n",
      ">>>>>step_norm<<<<<< 0.785461945777041\n",
      ">>>>>step_norm<<<<<< 0.6685730012679131\n",
      ">>>>>step_norm<<<<<< 0.43362690908174406\n",
      ">>>>>step_norm<<<<<< 0.36017392915894675\n",
      ">>>>>step_norm<<<<<< 0.5878407140965808\n",
      ">>>>>step_norm<<<<<< 0.5846081206749126\n",
      ">>>>>step_norm<<<<<< 0.29336097441567444\n",
      ">>>>>step_norm<<<<<< 0.42056920341135223\n",
      ">>>>>step_norm<<<<<< 0.5254618779576938\n",
      ">>>>>step_norm<<<<<< 0.61650123396214\n",
      ">>>>>step_norm<<<<<< 0.3274501055801623\n",
      ">>>>>step_norm<<<<<< 0.8891369301164292\n",
      ">>>>>step_norm<<<<<< 0.534978552742564\n",
      ">>>>>step_norm<<<<<< 0.5378383892163074\n",
      ">>>>>step_norm<<<<<< 0.2651624344698425\n",
      ">>>>>step_norm<<<<<< 0.5016744314376748\n",
      ">>>>>step_norm<<<<<< 0.6223507755482279\n",
      ">>>>>step_norm<<<<<< 1.5242520546348692\n",
      ">>>>>step_norm<<<<<< 0.2576604999152815\n",
      ">>>>>step_norm<<<<<< 0.2896139255310325\n",
      ">>>>>step_norm<<<<<< 0.39598333291343274\n",
      ">>>>>step_norm<<<<<< 0.6719336489593324\n",
      ">>>>>step_norm<<<<<< 0.9342072408024653\n",
      ">>>>>step_norm<<<<<< 0.6434782545964601\n",
      ">>>>>step_norm<<<<<< 0.7076840979230868\n",
      ">>>>>step_norm<<<<<< 0.16747952176783362\n",
      ">>>>>step_norm<<<<<< 0.29171381057923884\n",
      ">>>>>step_norm<<<<<< 0.29003865914716437\n",
      ">>>>>step_norm<<<<<< 0.663581214126688\n",
      ">>>>>step_norm<<<<<< 0.35988976029401076\n",
      ">>>>>step_norm<<<<<< 0.4843915917951801\n",
      ">>>>>step_norm<<<<<< 0.41658140417964434\n",
      ">>>>>step_norm<<<<<< 0.46652968476316825\n",
      ">>>>>step_norm<<<<<< 0.322645852275649\n",
      ">>>>>step_norm<<<<<< 0.44953398251831256\n",
      ">>>>>step_norm<<<<<< 0.20243875983032517\n",
      ">>>>>step_norm<<<<<< 0.24842603268899863\n",
      ">>>>>step_norm<<<<<< 0.6106158797388292\n",
      ">>>>>step_norm<<<<<< 0.32046264047663214\n",
      ">>>>>step_norm<<<<<< 0.5447196533453325\n",
      ">>>>>step_norm<<<<<< 1.217940458348459\n",
      ">>>>>step_norm<<<<<< 0.7188090234177742\n",
      ">>>>>step_norm<<<<<< 0.44670754142985175\n",
      ">>>>>step_norm<<<<<< 0.3808769467845796\n",
      ">>>>>step_norm<<<<<< 0.5467775969606959\n",
      ">>>>>step_norm<<<<<< 0.41077824032994703\n",
      ">>>>>step_norm<<<<<< 0.9528042077314648\n",
      ">>>>>step_norm<<<<<< 0.4343793953511154\n",
      ">>>>>step_norm<<<<<< 0.5857321647269647\n",
      ">>>>>step_norm<<<<<< 0.5360547149521808\n",
      ">>>>>step_norm<<<<<< 0.6777590069768223\n",
      ">>>>>step_norm<<<<<< 0.271658307270766\n",
      ">>>>>step_norm<<<<<< 0.23858503984979862\n",
      ">>>>>step_norm<<<<<< 0.6335381341583959\n",
      ">>>>>step_norm<<<<<< 0.5260180483935063\n",
      ">>>>>step_norm<<<<<< 0.30035055306774466\n",
      ">>>>>step_norm<<<<<< 0.3219051178191402\n",
      ">>>>>step_norm<<<<<< 0.22691370156600035\n",
      ">>>>>step_norm<<<<<< 0.8567849990891341\n",
      ">>>>>step_norm<<<<<< 0.7584794335868934\n",
      ">>>>>step_norm<<<<<< 0.2679267819564688\n",
      ">>>>>step_norm<<<<<< 0.276500780279035\n",
      ">>>>>step_norm<<<<<< 0.6984142268729289\n",
      ">>>>>step_norm<<<<<< 0.29949885699492224\n",
      ">>>>>step_norm<<<<<< 0.9062929474884474\n",
      ">>>>>step_norm<<<<<< 0.580709930296906\n",
      ">>>>>step_norm<<<<<< 0.4208887775754274\n",
      ">>>>>step_norm<<<<<< 0.9166818325412749\n",
      ">>>>>step_norm<<<<<< 1.950692961554254\n",
      ">>>>>step_norm<<<<<< 0.9956354886898993\n",
      ">>>>>step_norm<<<<<< 0.3195167559128362\n",
      ">>>>>step_norm<<<<<< 0.6802193090363134\n",
      ">>>>>step_norm<<<<<< 0.9910234397209395\n",
      ">>>>>step_norm<<<<<< 0.5301951476785651\n",
      ">>>>>step_norm<<<<<< 0.8489259630181043\n",
      ">>>>>step_norm<<<<<< 1.3616916430817698\n",
      ">>>>>step_norm<<<<<< 0.41819926992060735\n",
      ">>>>>step_norm<<<<<< 0.3404550302982789\n",
      ">>>>>step_norm<<<<<< 0.6123058634791381\n",
      ">>>>>step_norm<<<<<< 0.9953339077466317\n",
      ">>>>>step_norm<<<<<< 1.118283711127709\n",
      ">>>>>step_norm<<<<<< 0.8199907033354707\n",
      ">>>>>step_norm<<<<<< 0.9896324486824137\n",
      ">>>>>step_norm<<<<<< 0.6116024610207372\n",
      ">>>>>step_norm<<<<<< 0.9474180265851289\n",
      ">>>>>step_norm<<<<<< 0.626249678066808\n",
      ">>>>>step_norm<<<<<< 0.6291817710233077\n",
      ">>>>>step_norm<<<<<< 0.6641274281627365\n",
      ">>>>>step_norm<<<<<< 1.2755184965828426\n",
      ">>>>>step_norm<<<<<< 0.9679555683799739\n",
      ">>>>>step_norm<<<<<< 0.5860098401777354\n",
      ">>>>>step_norm<<<<<< 0.9092980079818985\n",
      ">>>>>step_norm<<<<<< 0.5706022706361947\n",
      ">>>>>step_norm<<<<<< 1.124232743324279\n",
      ">>>>>step_norm<<<<<< 1.0061852164750034\n",
      ">>>>>step_norm<<<<<< 0.824727191747426\n",
      ">>>>>step_norm<<<<<< 0.27752337919891773\n",
      ">>>>>step_norm<<<<<< 1.2933149265133455\n",
      ">>>>>step_norm<<<<<< 1.0313746761439455\n",
      ">>>>>step_norm<<<<<< 0.8721968828028726\n",
      ">>>>>step_norm<<<<<< 1.1316801363392217\n",
      ">>>>>step_norm<<<<<< 1.0128200983927031\n",
      ">>>>>step_norm<<<<<< 0.5702479451322672\n",
      ">>>>>step_norm<<<<<< 0.444732431668648\n",
      ">>>>>step_norm<<<<<< 0.2878820611335507\n",
      ">>>>>step_norm<<<<<< 1.468893815576123\n",
      ">>>>>step_norm<<<<<< 0.8297316646157004\n",
      ">>>>>step_norm<<<<<< 0.9490455820814909\n",
      ">>>>>step_norm<<<<<< 0.5986196779219625\n",
      ">>>>>step_norm<<<<<< 0.7776151406027969\n",
      ">>>>>step_norm<<<<<< 0.42094621572516633\n",
      ">>>>>step_norm<<<<<< 0.8978882064423583\n",
      ">>>>>step_norm<<<<<< 0.9437601684311263\n",
      ">>>>>step_norm<<<<<< 0.3618829987747924\n",
      ">>>>>step_norm<<<<<< 0.7385058182191825\n",
      ">>>>>step_norm<<<<<< 0.5006519029600629\n",
      ">>>>>step_norm<<<<<< 0.8924408366991828\n",
      ">>>>>step_norm<<<<<< 0.47319308972510793\n",
      ">>>>>step_norm<<<<<< 0.6397123073696174\n",
      ">>>>>step_norm<<<<<< 1.4530083155544113\n",
      ">>>>>step_norm<<<<<< 0.5793131240901878\n",
      ">>>>>step_norm<<<<<< 0.658266225695986\n",
      ">>>>>step_norm<<<<<< 0.5047721056068504\n",
      ">>>>>step_norm<<<<<< 0.7889838192744262\n",
      ">>>>>step_norm<<<<<< 0.5164801664158246\n",
      ">>>>>step_norm<<<<<< 0.8267563311255396\n",
      ">>>>>step_norm<<<<<< 0.2306749739569135\n",
      ">>>>>step_norm<<<<<< 0.38886408221436514\n",
      ">>>>>step_norm<<<<<< 0.45276238374016453\n",
      ">>>>>step_norm<<<<<< 0.9782975882376412\n",
      ">>>>>step_norm<<<<<< 0.48482530424206144\n",
      ">>>>>step_norm<<<<<< 0.43068950087552216\n",
      ">>>>>step_norm<<<<<< 0.4376670797128555\n",
      ">>>>>step_norm<<<<<< 0.9807470350567501\n",
      ">>>>>step_norm<<<<<< 0.5703555031935151\n",
      ">>>>>step_norm<<<<<< 0.39339630639474915\n",
      ">>>>>step_norm<<<<<< 0.8230310689425278\n",
      ">>>>>step_norm<<<<<< 0.7178156307874034\n",
      ">>>>>step_norm<<<<<< 1.2505139186489167\n",
      ">>>>>step_norm<<<<<< 0.9054298581251164\n",
      ">>>>>step_norm<<<<<< 0.76493585204349\n",
      ">>>>>step_norm<<<<<< 1.0388573344924363\n",
      ">>>>>step_norm<<<<<< 0.7414138827159474\n",
      ">>>>>step_norm<<<<<< 1.0009850505506601\n",
      ">>>>>step_norm<<<<<< 1.3479394625300598\n",
      ">>>>>step_norm<<<<<< 1.0757736620745217\n",
      ">>>>>step_norm<<<<<< 1.2472967146794052\n",
      ">>>>>step_norm<<<<<< 0.33066838622676314\n",
      ">>>>>step_norm<<<<<< 0.5772545282101395\n",
      ">>>>>step_norm<<<<<< 0.5272077325706719\n",
      ">>>>>step_norm<<<<<< 1.2458174887461908\n",
      ">>>>>step_norm<<<<<< 0.9319617053801829\n",
      ">>>>>step_norm<<<<<< 0.45325909828596944\n",
      ">>>>>step_norm<<<<<< 0.6161020551724852\n",
      ">>>>>step_norm<<<<<< 0.6984103526590675\n",
      ">>>>>step_norm<<<<<< 0.6430815074682429\n",
      ">>>>>step_norm<<<<<< 0.4653966297693845\n",
      ">>>>>step_norm<<<<<< 0.7708266016709966\n",
      ">>>>>step_norm<<<<<< 0.9883454089604814\n",
      ">>>>>step_norm<<<<<< 0.5922078853623134\n",
      ">>>>>step_norm<<<<<< 0.32023284434138183\n",
      ">>>>>step_norm<<<<<< 0.5334606573351977\n",
      ">>>>>step_norm<<<<<< 1.2857798845258495\n",
      ">>>>>step_norm<<<<<< 0.5805735021581354\n",
      ">>>>>step_norm<<<<<< 0.4882434341826976\n",
      ">>>>>step_norm<<<<<< 0.7747239192479661\n",
      ">>>>>step_norm<<<<<< 0.7881141191851183\n",
      ">>>>>step_norm<<<<<< 0.5195990787130889\n",
      ">>>>>step_norm<<<<<< 0.3809368026995022\n",
      ">>>>>step_norm<<<<<< 0.6602758711377549\n",
      ">>>>>step_norm<<<<<< 0.38222918571167075\n",
      ">>>>>step_norm<<<<<< 0.8176159697813205\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 12\n",
      ">>>>>step_norm<<<<<< 0.39879730348454473\n",
      ">>>>>step_norm<<<<<< 0.5060677296701831\n",
      ">>>>>step_norm<<<<<< 0.8107778311478605\n",
      ">>>>>step_norm<<<<<< 0.9006733353594351\n",
      ">>>>>step_norm<<<<<< 0.5931867734321193\n",
      ">>>>>step_norm<<<<<< 0.6497108127669959\n",
      ">>>>>step_norm<<<<<< 0.9756528334521777\n",
      ">>>>>step_norm<<<<<< 0.4375560379295937\n",
      ">>>>>step_norm<<<<<< 0.5043865157103659\n",
      ">>>>>step_norm<<<<<< 0.4941179782394493\n",
      ">>>>>step_norm<<<<<< 0.3196974709289814\n",
      ">>>>>step_norm<<<<<< 0.7959429132739986\n",
      ">>>>>step_norm<<<<<< 0.8753548954023647\n",
      ">>>>>step_norm<<<<<< 0.5834608332412319\n",
      ">>>>>step_norm<<<<<< 1.7858226156244084\n",
      ">>>>>step_norm<<<<<< 0.5769065488723024\n",
      ">>>>>step_norm<<<<<< 0.8972008463794682\n",
      ">>>>>step_norm<<<<<< 0.4463094980282077\n",
      ">>>>>step_norm<<<<<< 1.2549302635502295\n",
      ">>>>>step_norm<<<<<< 0.7171451341020323\n",
      ">>>>>step_norm<<<<<< 0.5847892271242031\n",
      ">>>>>step_norm<<<<<< 0.31040790820615227\n",
      ">>>>>step_norm<<<<<< 0.4697372020825168\n",
      ">>>>>step_norm<<<<<< 0.9126554432054527\n",
      ">>>>>step_norm<<<<<< 0.7104843062937682\n",
      ">>>>>step_norm<<<<<< 1.7798699473998307\n",
      ">>>>>step_norm<<<<<< 0.694586488263799\n",
      ">>>>>step_norm<<<<<< 0.6606091700995543\n",
      ">>>>>step_norm<<<<<< 0.44571283179595855\n",
      ">>>>>step_norm<<<<<< 0.40989902036410736\n",
      ">>>>>step_norm<<<<<< 0.5345538365050132\n",
      ">>>>>step_norm<<<<<< 0.883380901990975\n",
      ">>>>>step_norm<<<<<< 1.5840213005923343\n",
      ">>>>>step_norm<<<<<< 0.7387601838329744\n",
      ">>>>>step_norm<<<<<< 0.4321701519900955\n",
      ">>>>>step_norm<<<<<< 0.628294082008926\n",
      ">>>>>step_norm<<<<<< 0.24993213594823208\n",
      ">>>>>step_norm<<<<<< 1.9267986302464402\n",
      ">>>>>step_norm<<<<<< 0.8818558495578495\n",
      ">>>>>step_norm<<<<<< 1.1656401142151571\n",
      ">>>>>step_norm<<<<<< 0.4574218674774393\n",
      ">>>>>step_norm<<<<<< 0.8225236406797722\n",
      ">>>>>step_norm<<<<<< 0.8763643396044032\n",
      ">>>>>step_norm<<<<<< 0.8451876273846172\n",
      ">>>>>step_norm<<<<<< 0.9608784848564278\n",
      ">>>>>step_norm<<<<<< 0.32106762311506687\n",
      ">>>>>step_norm<<<<<< 0.3218964495497815\n",
      ">>>>>step_norm<<<<<< 0.7367572195426302\n",
      ">>>>>step_norm<<<<<< 0.7188166140860572\n",
      ">>>>>step_norm<<<<<< 0.6243351528292941\n",
      ">>>>>step_norm<<<<<< 0.6436404218259618\n",
      ">>>>>step_norm<<<<<< 0.7238185024406961\n",
      ">>>>>step_norm<<<<<< 0.25769210240557283\n",
      ">>>>>step_norm<<<<<< 0.4800734093309928\n",
      ">>>>>step_norm<<<<<< 0.4445509598991407\n",
      ">>>>>step_norm<<<<<< 0.4715870156296162\n",
      ">>>>>step_norm<<<<<< 0.7812529567242344\n",
      ">>>>>step_norm<<<<<< 1.7401340971618455\n",
      ">>>>>step_norm<<<<<< 0.92868823396796\n",
      ">>>>>step_norm<<<<<< 1.4258980383741988\n",
      ">>>>>step_norm<<<<<< 0.6532227163381673\n",
      ">>>>>step_norm<<<<<< 0.6772804009708754\n",
      ">>>>>step_norm<<<<<< 0.6075712128681905\n",
      ">>>>>step_norm<<<<<< 0.453806201019552\n",
      ">>>>>step_norm<<<<<< 0.3541284693661465\n",
      ">>>>>step_norm<<<<<< 1.0135418873885993\n",
      ">>>>>step_norm<<<<<< 0.6588859298173253\n",
      ">>>>>step_norm<<<<<< 0.7511920077376404\n",
      ">>>>>step_norm<<<<<< 0.6748327196956689\n",
      ">>>>>step_norm<<<<<< 1.313326123246945\n",
      ">>>>>step_norm<<<<<< 0.7140567887703354\n",
      ">>>>>step_norm<<<<<< 0.5238230261045198\n",
      ">>>>>step_norm<<<<<< 0.7199796422314388\n",
      ">>>>>step_norm<<<<<< 0.22233553204171264\n",
      ">>>>>step_norm<<<<<< 0.2771626185204201\n",
      ">>>>>step_norm<<<<<< 0.2987000002287359\n",
      ">>>>>step_norm<<<<<< 0.6887173627366101\n",
      ">>>>>step_norm<<<<<< 0.7086158679540746\n",
      ">>>>>step_norm<<<<<< 0.6011105339616735\n",
      ">>>>>step_norm<<<<<< 0.31581737950553784\n",
      ">>>>>step_norm<<<<<< 1.4608933397753954\n",
      ">>>>>step_norm<<<<<< 0.44202245728990175\n",
      ">>>>>step_norm<<<<<< 0.5645421246736867\n",
      ">>>>>step_norm<<<<<< 0.3911131984658419\n",
      ">>>>>step_norm<<<<<< 0.902367968112412\n",
      ">>>>>step_norm<<<<<< 1.5665213558323263\n",
      ">>>>>step_norm<<<<<< 0.43939972621668194\n",
      ">>>>>step_norm<<<<<< 0.5929583131414782\n",
      ">>>>>step_norm<<<<<< 1.02421343973053\n",
      ">>>>>step_norm<<<<<< 0.2708900880649832\n",
      ">>>>>step_norm<<<<<< 1.0244211678837352\n",
      ">>>>>step_norm<<<<<< 0.40787271362350336\n",
      ">>>>>step_norm<<<<<< 0.7798404641121154\n",
      ">>>>>step_norm<<<<<< 0.47866289959471614\n",
      ">>>>>step_norm<<<<<< 0.6897457159076914\n",
      ">>>>>step_norm<<<<<< 0.3147643243368918\n",
      ">>>>>step_norm<<<<<< 0.6441166825170944\n",
      ">>>>>step_norm<<<<<< 0.47032337869025037\n",
      ">>>>>step_norm<<<<<< 0.4484016521221541\n",
      ">>>>>step_norm<<<<<< 0.35332991787592394\n",
      ">>>>>step_norm<<<<<< 1.6984021086398033\n",
      ">>>>>step_norm<<<<<< 1.733644589130422\n",
      ">>>>>step_norm<<<<<< 1.0340368851328003\n",
      ">>>>>step_norm<<<<<< 0.9238787907511312\n",
      ">>>>>step_norm<<<<<< 0.7529661602166444\n",
      ">>>>>step_norm<<<<<< 1.075340981678879\n",
      ">>>>>step_norm<<<<<< 0.5263078665115516\n",
      ">>>>>step_norm<<<<<< 0.638428345648258\n",
      ">>>>>step_norm<<<<<< 0.4510895401225715\n",
      ">>>>>step_norm<<<<<< 0.23319715345001535\n",
      ">>>>>step_norm<<<<<< 0.40702584622757354\n",
      ">>>>>step_norm<<<<<< 0.3026455745088412\n",
      ">>>>>step_norm<<<<<< 1.2496888708252296\n",
      ">>>>>step_norm<<<<<< 0.4004901603477947\n",
      ">>>>>step_norm<<<<<< 1.0474552242380912\n",
      ">>>>>step_norm<<<<<< 1.0167212082994694\n",
      ">>>>>step_norm<<<<<< 0.852855098423724\n",
      ">>>>>step_norm<<<<<< 0.7228374002855874\n",
      ">>>>>step_norm<<<<<< 0.4979059612971328\n",
      ">>>>>step_norm<<<<<< 0.5565881522860977\n",
      ">>>>>step_norm<<<<<< 0.3630462940330845\n",
      ">>>>>step_norm<<<<<< 0.640181483151891\n",
      ">>>>>step_norm<<<<<< 1.35349799778962\n",
      ">>>>>step_norm<<<<<< 0.8059192250909877\n",
      ">>>>>step_norm<<<<<< 0.6269881326273316\n",
      ">>>>>step_norm<<<<<< 0.42014058955519873\n",
      ">>>>>step_norm<<<<<< 0.5495966864300752\n",
      ">>>>>step_norm<<<<<< 0.8588316030403484\n",
      ">>>>>step_norm<<<<<< 0.627884061784405\n",
      ">>>>>step_norm<<<<<< 0.7747116614639113\n",
      ">>>>>step_norm<<<<<< 0.47008871766751875\n",
      ">>>>>step_norm<<<<<< 0.6842504365341523\n",
      ">>>>>step_norm<<<<<< 1.3922391820017983\n",
      ">>>>>step_norm<<<<<< 0.3001696565678539\n",
      ">>>>>step_norm<<<<<< 0.4131406240867741\n",
      ">>>>>step_norm<<<<<< 0.5795377905903762\n",
      ">>>>>step_norm<<<<<< 0.7154657230901313\n",
      ">>>>>step_norm<<<<<< 0.6367818254520996\n",
      ">>>>>step_norm<<<<<< 1.4766232324860675\n",
      ">>>>>step_norm<<<<<< 0.47163167202609496\n",
      ">>>>>step_norm<<<<<< 0.4588449503132477\n",
      ">>>>>step_norm<<<<<< 0.3314576666742776\n",
      ">>>>>step_norm<<<<<< 0.34108854029927077\n",
      ">>>>>step_norm<<<<<< 0.5819724740254064\n",
      ">>>>>step_norm<<<<<< 0.9509198220499679\n",
      ">>>>>step_norm<<<<<< 0.3471048416898188\n",
      ">>>>>step_norm<<<<<< 1.195397289242973\n",
      ">>>>>step_norm<<<<<< 0.49049716512551816\n",
      ">>>>>step_norm<<<<<< 0.8196758410122781\n",
      ">>>>>step_norm<<<<<< 0.5420218028652412\n",
      ">>>>>step_norm<<<<<< 0.9741987429395452\n",
      ">>>>>step_norm<<<<<< 0.294411710701945\n",
      ">>>>>step_norm<<<<<< 0.347714550975755\n",
      ">>>>>step_norm<<<<<< 0.5918226474118153\n",
      ">>>>>step_norm<<<<<< 0.6208838420010104\n",
      ">>>>>step_norm<<<<<< 1.1827423666940085\n",
      ">>>>>step_norm<<<<<< 0.5561538590068783\n",
      ">>>>>step_norm<<<<<< 0.30412582436592434\n",
      ">>>>>step_norm<<<<<< 0.45909047713913614\n",
      ">>>>>step_norm<<<<<< 0.47463690205191195\n",
      ">>>>>step_norm<<<<<< 0.8656739861782361\n",
      ">>>>>step_norm<<<<<< 0.6032981250344353\n",
      ">>>>>step_norm<<<<<< 0.939917243962151\n",
      ">>>>>step_norm<<<<<< 0.46867038924628945\n",
      ">>>>>step_norm<<<<<< 1.0147240094614953\n",
      ">>>>>step_norm<<<<<< 0.6464994920143157\n",
      ">>>>>step_norm<<<<<< 0.8445684887060462\n",
      ">>>>>step_norm<<<<<< 0.8556978213792166\n",
      ">>>>>step_norm<<<<<< 0.8214676295884343\n",
      ">>>>>step_norm<<<<<< 0.7960425273032395\n",
      ">>>>>step_norm<<<<<< 0.5572657341077875\n",
      ">>>>>step_norm<<<<<< 0.41776047511943243\n",
      ">>>>>step_norm<<<<<< 0.7923595476917077\n",
      ">>>>>step_norm<<<<<< 1.039591998651211\n",
      ">>>>>step_norm<<<<<< 1.0486005127637257\n",
      ">>>>>step_norm<<<<<< 0.41926244155822767\n",
      ">>>>>step_norm<<<<<< 1.1303844173216129\n",
      ">>>>>step_norm<<<<<< 1.0249253900545783\n",
      ">>>>>step_norm<<<<<< 1.0276477440740082\n",
      ">>>>>step_norm<<<<<< 0.7579338849380209\n",
      ">>>>>step_norm<<<<<< 0.6427572399733527\n",
      ">>>>>step_norm<<<<<< 0.8526155459892444\n",
      ">>>>>step_norm<<<<<< 0.6340493469255876\n",
      ">>>>>step_norm<<<<<< 0.5617362490828541\n",
      ">>>>>step_norm<<<<<< 0.7380313045606195\n",
      ">>>>>step_norm<<<<<< 1.1188199998115549\n",
      ">>>>>step_norm<<<<<< 0.3928067926514911\n",
      ">>>>>step_norm<<<<<< 0.5707768868617095\n",
      ">>>>>step_norm<<<<<< 0.98321329732799\n",
      ">>>>>step_norm<<<<<< 0.7461213895349786\n",
      ">>>>>step_norm<<<<<< 0.7586311951726453\n",
      ">>>>>step_norm<<<<<< 1.2617582129309255\n",
      ">>>>>step_norm<<<<<< 0.8822072266813559\n",
      ">>>>>step_norm<<<<<< 0.7967862890606278\n",
      ">>>>>step_norm<<<<<< 0.7679245259603694\n",
      ">>>>>step_norm<<<<<< 1.457841321341756\n",
      ">>>>>step_norm<<<<<< 1.8336936180568777\n",
      ">>>>>step_norm<<<<<< 1.0150235555780591\n",
      ">>>>>step_norm<<<<<< 0.5798940298413423\n",
      ">>>>>step_norm<<<<<< 0.4857152217186202\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 13\n",
      ">>>>>step_norm<<<<<< 0.8595674699657236\n",
      ">>>>>step_norm<<<<<< 0.5492506934381999\n",
      ">>>>>step_norm<<<<<< 0.47380112646126354\n",
      ">>>>>step_norm<<<<<< 0.43414816432574027\n",
      ">>>>>step_norm<<<<<< 0.4555388797348637\n",
      ">>>>>step_norm<<<<<< 0.30241085129316403\n",
      ">>>>>step_norm<<<<<< 0.3467274225215045\n",
      ">>>>>step_norm<<<<<< 0.3999930522287291\n",
      ">>>>>step_norm<<<<<< 0.4474494238273\n",
      ">>>>>step_norm<<<<<< 0.5867606337085163\n",
      ">>>>>step_norm<<<<<< 0.5039249211345269\n",
      ">>>>>step_norm<<<<<< 0.42552964882561056\n",
      ">>>>>step_norm<<<<<< 1.4217253209545013\n",
      ">>>>>step_norm<<<<<< 0.4492785523866294\n",
      ">>>>>step_norm<<<<<< 0.7882323347539645\n",
      ">>>>>step_norm<<<<<< 0.4036522935230867\n",
      ">>>>>step_norm<<<<<< 0.5421019915436964\n",
      ">>>>>step_norm<<<<<< 0.4722687026323619\n",
      ">>>>>step_norm<<<<<< 0.559533083781583\n",
      ">>>>>step_norm<<<<<< 0.32032862341986185\n",
      ">>>>>step_norm<<<<<< 0.2981460626399059\n",
      ">>>>>step_norm<<<<<< 0.7031362986842113\n",
      ">>>>>step_norm<<<<<< 0.19445648393725656\n",
      ">>>>>step_norm<<<<<< 0.5588350467721457\n",
      ">>>>>step_norm<<<<<< 0.8401882937461946\n",
      ">>>>>step_norm<<<<<< 0.7265573090216256\n",
      ">>>>>step_norm<<<<<< 0.45438562585286946\n",
      ">>>>>step_norm<<<<<< 0.5270553442524265\n",
      ">>>>>step_norm<<<<<< 0.9707582610252362\n",
      ">>>>>step_norm<<<<<< 1.5293540779331587\n",
      ">>>>>step_norm<<<<<< 0.33632085430797004\n",
      ">>>>>step_norm<<<<<< 0.37232087862505253\n",
      ">>>>>step_norm<<<<<< 0.4007995879116358\n",
      ">>>>>step_norm<<<<<< 0.5410220881177196\n",
      ">>>>>step_norm<<<<<< 0.5440944246154665\n",
      ">>>>>step_norm<<<<<< 0.7276989504019918\n",
      ">>>>>step_norm<<<<<< 0.209361610178082\n",
      ">>>>>step_norm<<<<<< 0.4953215568703165\n",
      ">>>>>step_norm<<<<<< 0.7370215331591284\n",
      ">>>>>step_norm<<<<<< 0.917926874552389\n",
      ">>>>>step_norm<<<<<< 0.5572404939481723\n",
      ">>>>>step_norm<<<<<< 0.3095384942866361\n",
      ">>>>>step_norm<<<<<< 1.0868034124519987\n",
      ">>>>>step_norm<<<<<< 0.4835197846090895\n",
      ">>>>>step_norm<<<<<< 0.23063405635055054\n",
      ">>>>>step_norm<<<<<< 0.34870536598027974\n",
      ">>>>>step_norm<<<<<< 0.42522523301709114\n",
      ">>>>>step_norm<<<<<< 0.36640474814175267\n",
      ">>>>>step_norm<<<<<< 0.7068849832851416\n",
      ">>>>>step_norm<<<<<< 0.5024532850346157\n",
      ">>>>>step_norm<<<<<< 0.6777649217457286\n",
      ">>>>>step_norm<<<<<< 0.5958340167143777\n",
      ">>>>>step_norm<<<<<< 0.18880172988944002\n",
      ">>>>>step_norm<<<<<< 0.6230774752141475\n",
      ">>>>>step_norm<<<<<< 0.22168419235652237\n",
      ">>>>>step_norm<<<<<< 0.5582433393325109\n",
      ">>>>>step_norm<<<<<< 0.21392101160478794\n",
      ">>>>>step_norm<<<<<< 0.35282584150733026\n",
      ">>>>>step_norm<<<<<< 0.31239144632729854\n",
      ">>>>>step_norm<<<<<< 0.49759355419557816\n",
      ">>>>>step_norm<<<<<< 0.8562499549755723\n",
      ">>>>>step_norm<<<<<< 0.4817985466487303\n",
      ">>>>>step_norm<<<<<< 0.3911398730032871\n",
      ">>>>>step_norm<<<<<< 0.4490148921079641\n",
      ">>>>>step_norm<<<<<< 0.4534638545713691\n",
      ">>>>>step_norm<<<<<< 0.5062666777173259\n",
      ">>>>>step_norm<<<<<< 0.3918706708220794\n",
      ">>>>>step_norm<<<<<< 0.7182120724536794\n",
      ">>>>>step_norm<<<<<< 0.3718617669330484\n",
      ">>>>>step_norm<<<<<< 0.27636898302015905\n",
      ">>>>>step_norm<<<<<< 0.6594584876110282\n",
      ">>>>>step_norm<<<<<< 0.47326917478528374\n",
      ">>>>>step_norm<<<<<< 0.47348809143888865\n",
      ">>>>>step_norm<<<<<< 0.5335348036969961\n",
      ">>>>>step_norm<<<<<< 0.8252908627526163\n",
      ">>>>>step_norm<<<<<< 0.995480674793822\n",
      ">>>>>step_norm<<<<<< 0.4855649978404673\n",
      ">>>>>step_norm<<<<<< 0.6916487712623123\n",
      ">>>>>step_norm<<<<<< 0.8350256898627176\n",
      ">>>>>step_norm<<<<<< 0.21652651648150734\n",
      ">>>>>step_norm<<<<<< 0.46612581789376467\n",
      ">>>>>step_norm<<<<<< 0.9569603674305223\n",
      ">>>>>step_norm<<<<<< 0.7346554162543306\n",
      ">>>>>step_norm<<<<<< 0.4306992655400208\n",
      ">>>>>step_norm<<<<<< 0.8080619668271133\n",
      ">>>>>step_norm<<<<<< 0.6081688876909107\n",
      ">>>>>step_norm<<<<<< 0.4652924325456991\n",
      ">>>>>step_norm<<<<<< 0.8006984543254658\n",
      ">>>>>step_norm<<<<<< 0.32902321080025676\n",
      ">>>>>step_norm<<<<<< 1.1033434808160822\n",
      ">>>>>step_norm<<<<<< 0.8354687906981345\n",
      ">>>>>step_norm<<<<<< 0.47159423535908923\n",
      ">>>>>step_norm<<<<<< 0.18994847045429913\n",
      ">>>>>step_norm<<<<<< 0.7471216244629176\n",
      ">>>>>step_norm<<<<<< 0.7176637873634675\n",
      ">>>>>step_norm<<<<<< 0.9462445885164275\n",
      ">>>>>step_norm<<<<<< 0.21684019475217653\n",
      ">>>>>step_norm<<<<<< 0.8233217691898838\n",
      ">>>>>step_norm<<<<<< 0.5889771340992872\n",
      ">>>>>step_norm<<<<<< 0.6218552732596078\n",
      ">>>>>step_norm<<<<<< 0.5733980302345029\n",
      ">>>>>step_norm<<<<<< 0.8257965089933252\n",
      ">>>>>step_norm<<<<<< 0.45761872082901606\n",
      ">>>>>step_norm<<<<<< 0.31210461064846645\n",
      ">>>>>step_norm<<<<<< 0.3773569805755775\n",
      ">>>>>step_norm<<<<<< 0.22516552431195389\n",
      ">>>>>step_norm<<<<<< 0.30340666219341306\n",
      ">>>>>step_norm<<<<<< 0.4889525657643071\n",
      ">>>>>step_norm<<<<<< 0.3335675096543013\n",
      ">>>>>step_norm<<<<<< 0.6080691783219864\n",
      ">>>>>step_norm<<<<<< 0.762400727940848\n",
      ">>>>>step_norm<<<<<< 0.4765900774515912\n",
      ">>>>>step_norm<<<<<< 0.6575071668416312\n",
      ">>>>>step_norm<<<<<< 1.1789509434956795\n",
      ">>>>>step_norm<<<<<< 0.7549492823859163\n",
      ">>>>>step_norm<<<<<< 0.4269755789775566\n",
      ">>>>>step_norm<<<<<< 0.5340021397717687\n",
      ">>>>>step_norm<<<<<< 0.4660475585901861\n",
      ">>>>>step_norm<<<<<< 0.6599721653103382\n",
      ">>>>>step_norm<<<<<< 0.3934740209434453\n",
      ">>>>>step_norm<<<<<< 0.39413459354667085\n",
      ">>>>>step_norm<<<<<< 0.37280930001772183\n",
      ">>>>>step_norm<<<<<< 0.6115246429075757\n",
      ">>>>>step_norm<<<<<< 0.4706889804666478\n",
      ">>>>>step_norm<<<<<< 1.2255449725924343\n",
      ">>>>>step_norm<<<<<< 0.3448624472103662\n",
      ">>>>>step_norm<<<<<< 0.4737854891624601\n",
      ">>>>>step_norm<<<<<< 0.4976992695932661\n",
      ">>>>>step_norm<<<<<< 0.4071015890894968\n",
      ">>>>>step_norm<<<<<< 0.6575355543041637\n",
      ">>>>>step_norm<<<<<< 0.4415357752913192\n",
      ">>>>>step_norm<<<<<< 0.8065008440895381\n",
      ">>>>>step_norm<<<<<< 0.42873092715040956\n",
      ">>>>>step_norm<<<<<< 1.0895759086693857\n",
      ">>>>>step_norm<<<<<< 0.3321233729248688\n",
      ">>>>>step_norm<<<<<< 0.6650446826479872\n",
      ">>>>>step_norm<<<<<< 0.36654643202606246\n",
      ">>>>>step_norm<<<<<< 0.44618318444345145\n",
      ">>>>>step_norm<<<<<< 1.566543584229499\n",
      ">>>>>step_norm<<<<<< 0.6539836423046935\n",
      ">>>>>step_norm<<<<<< 0.4805943895807086\n",
      ">>>>>step_norm<<<<<< 0.5778122949730505\n",
      ">>>>>step_norm<<<<<< 0.21010853789273692\n",
      ">>>>>step_norm<<<<<< 0.19523822104402777\n",
      ">>>>>step_norm<<<<<< 0.5306209587282754\n",
      ">>>>>step_norm<<<<<< 0.24143114137385924\n",
      ">>>>>step_norm<<<<<< 0.4278572897160785\n",
      ">>>>>step_norm<<<<<< 0.3362817590411485\n",
      ">>>>>step_norm<<<<<< 0.3524469661781365\n",
      ">>>>>step_norm<<<<<< 0.3503337539270432\n",
      ">>>>>step_norm<<<<<< 0.6338630620004001\n",
      ">>>>>step_norm<<<<<< 1.6550704607523024\n",
      ">>>>>step_norm<<<<<< 0.7529505337006126\n",
      ">>>>>step_norm<<<<<< 0.37044248032599575\n",
      ">>>>>step_norm<<<<<< 0.783318646344572\n",
      ">>>>>step_norm<<<<<< 0.8349489982133871\n",
      ">>>>>step_norm<<<<<< 0.273336670162093\n",
      ">>>>>step_norm<<<<<< 0.955177174807689\n",
      ">>>>>step_norm<<<<<< 0.4247641235976135\n",
      ">>>>>step_norm<<<<<< 0.5408539415005391\n",
      ">>>>>step_norm<<<<<< 0.7275023445072237\n",
      ">>>>>step_norm<<<<<< 0.7905954000540019\n",
      ">>>>>step_norm<<<<<< 0.6883400176528528\n",
      ">>>>>step_norm<<<<<< 0.34777981222491405\n",
      ">>>>>step_norm<<<<<< 0.38409479057532475\n",
      ">>>>>step_norm<<<<<< 0.4460236706941069\n",
      ">>>>>step_norm<<<<<< 0.3528870738178461\n",
      ">>>>>step_norm<<<<<< 0.3618527467969257\n",
      ">>>>>step_norm<<<<<< 0.7232311647037614\n",
      ">>>>>step_norm<<<<<< 1.0202578954357777\n",
      ">>>>>step_norm<<<<<< 0.6044247025900065\n",
      ">>>>>step_norm<<<<<< 0.749943166887298\n",
      ">>>>>step_norm<<<<<< 0.738815922335361\n",
      ">>>>>step_norm<<<<<< 0.3963014193141083\n",
      ">>>>>step_norm<<<<<< 0.5221886880923103\n",
      ">>>>>step_norm<<<<<< 0.5629016638902382\n",
      ">>>>>step_norm<<<<<< 0.4230070655173523\n",
      ">>>>>step_norm<<<<<< 0.9128222783236682\n",
      ">>>>>step_norm<<<<<< 0.3745411536242083\n",
      ">>>>>step_norm<<<<<< 0.20742071472604096\n",
      ">>>>>step_norm<<<<<< 0.2738959853371601\n",
      ">>>>>step_norm<<<<<< 0.3659985970552314\n",
      ">>>>>step_norm<<<<<< 0.3816979110030357\n",
      ">>>>>step_norm<<<<<< 0.30414723311113684\n",
      ">>>>>step_norm<<<<<< 1.0675514858401511\n",
      ">>>>>step_norm<<<<<< 0.4404162337658656\n",
      ">>>>>step_norm<<<<<< 0.3793797819282477\n",
      ">>>>>step_norm<<<<<< 1.0351689402988262\n",
      ">>>>>step_norm<<<<<< 0.42701012020145135\n",
      ">>>>>step_norm<<<<<< 0.3740880731483277\n",
      ">>>>>step_norm<<<<<< 0.474886698427715\n",
      ">>>>>step_norm<<<<<< 0.5000278193545328\n",
      ">>>>>step_norm<<<<<< 0.40327991018526027\n",
      ">>>>>step_norm<<<<<< 1.161515960681751\n",
      ">>>>>step_norm<<<<<< 0.46975564655998886\n",
      ">>>>>step_norm<<<<<< 0.22905962783858738\n",
      ">>>>>step_norm<<<<<< 0.6864560531958848\n",
      ">>>>>step_norm<<<<<< 0.8034683559623287\n",
      ">>>>>step_norm<<<<<< 0.6029640976637504\n",
      ">>>>>step_norm<<<<<< 0.7281689267785296\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 14\n",
      ">>>>>step_norm<<<<<< 1.020692827837718\n",
      ">>>>>step_norm<<<<<< 0.7048866713458082\n",
      ">>>>>step_norm<<<<<< 0.3794976918530346\n",
      ">>>>>step_norm<<<<<< 1.2289099197431426\n",
      ">>>>>step_norm<<<<<< 1.2974461135222708\n",
      ">>>>>step_norm<<<<<< 1.0600536074413198\n",
      ">>>>>step_norm<<<<<< 1.013956264299959\n",
      ">>>>>step_norm<<<<<< 0.6017319612299252\n",
      ">>>>>step_norm<<<<<< 0.3310848445406762\n",
      ">>>>>step_norm<<<<<< 0.2386370797580099\n",
      ">>>>>step_norm<<<<<< 1.1306962288417213\n",
      ">>>>>step_norm<<<<<< 0.44275713739796857\n",
      ">>>>>step_norm<<<<<< 2.108740909807003\n",
      ">>>>>step_norm<<<<<< 0.735947398012249\n",
      ">>>>>step_norm<<<<<< 0.9329875391259093\n",
      ">>>>>step_norm<<<<<< 0.8037981290385533\n",
      ">>>>>step_norm<<<<<< 0.328250274762857\n",
      ">>>>>step_norm<<<<<< 0.8256606602169143\n",
      ">>>>>step_norm<<<<<< 0.40159360345366074\n",
      ">>>>>step_norm<<<<<< 0.4071730382667422\n",
      ">>>>>step_norm<<<<<< 0.9454610981242884\n",
      ">>>>>step_norm<<<<<< 0.6087713826891381\n",
      ">>>>>step_norm<<<<<< 0.3488733247654062\n",
      ">>>>>step_norm<<<<<< 0.890248841409268\n",
      ">>>>>step_norm<<<<<< 0.6848269864043133\n",
      ">>>>>step_norm<<<<<< 0.741465344610673\n",
      ">>>>>step_norm<<<<<< 1.2607714663487746\n",
      ">>>>>step_norm<<<<<< 0.4075431666600098\n",
      ">>>>>step_norm<<<<<< 1.5594236154359171\n",
      ">>>>>step_norm<<<<<< 0.5538881929435698\n",
      ">>>>>step_norm<<<<<< 0.7866462054005612\n",
      ">>>>>step_norm<<<<<< 0.7125850817364834\n",
      ">>>>>step_norm<<<<<< 0.44070735485657764\n",
      ">>>>>step_norm<<<<<< 0.49866702258442497\n",
      ">>>>>step_norm<<<<<< 0.2403943719739664\n",
      ">>>>>step_norm<<<<<< 0.4478358596137567\n",
      ">>>>>step_norm<<<<<< 0.4436981954615491\n",
      ">>>>>step_norm<<<<<< 1.6382623656449087\n",
      ">>>>>step_norm<<<<<< 1.476958378780302\n",
      ">>>>>step_norm<<<<<< 0.4353877137078411\n",
      ">>>>>step_norm<<<<<< 0.5641566089646166\n",
      ">>>>>step_norm<<<<<< 0.4120083834674097\n",
      ">>>>>step_norm<<<<<< 1.3392671393392852\n",
      ">>>>>step_norm<<<<<< 1.1494173929384788\n",
      ">>>>>step_norm<<<<<< 1.0509579667008921\n",
      ">>>>>step_norm<<<<<< 1.3338613745129009\n",
      ">>>>>step_norm<<<<<< 1.6007382848009042\n",
      ">>>>>step_norm<<<<<< 0.5545158598641932\n",
      ">>>>>step_norm<<<<<< 0.9111255922136837\n",
      ">>>>>step_norm<<<<<< 1.7151436541336438\n",
      ">>>>>step_norm<<<<<< 0.6714505407784328\n",
      ">>>>>step_norm<<<<<< 0.4040636597671764\n",
      ">>>>>step_norm<<<<<< 0.6714864687463635\n",
      ">>>>>step_norm<<<<<< 0.4701807312082091\n",
      ">>>>>step_norm<<<<<< 0.9293974727289857\n",
      ">>>>>step_norm<<<<<< 1.067115287467797\n",
      ">>>>>step_norm<<<<<< 0.5930321810906146\n",
      ">>>>>step_norm<<<<<< 2.121779837717169\n",
      ">>>>>step_norm<<<<<< 0.4707166306337464\n",
      ">>>>>step_norm<<<<<< 1.0433251499334368\n",
      ">>>>>step_norm<<<<<< 1.1757014895049056\n",
      ">>>>>step_norm<<<<<< 1.111046776403267\n",
      ">>>>>step_norm<<<<<< 0.6230264354649765\n",
      ">>>>>step_norm<<<<<< 0.9709638304371188\n",
      ">>>>>step_norm<<<<<< 0.7092808881005119\n",
      ">>>>>step_norm<<<<<< 0.7750630477422029\n",
      ">>>>>step_norm<<<<<< 0.4950894561395482\n",
      ">>>>>step_norm<<<<<< 0.8452945390919545\n",
      ">>>>>step_norm<<<<<< 0.5489685864868779\n",
      ">>>>>step_norm<<<<<< 0.6568622865876779\n",
      ">>>>>step_norm<<<<<< 0.5025124839013871\n",
      ">>>>>step_norm<<<<<< 0.5749397555374\n",
      ">>>>>step_norm<<<<<< 1.1045667840773645\n",
      ">>>>>step_norm<<<<<< 0.7096197087661936\n",
      ">>>>>step_norm<<<<<< 0.3662935230694696\n",
      ">>>>>step_norm<<<<<< 0.9825213653129694\n",
      ">>>>>step_norm<<<<<< 0.4526230924714915\n",
      ">>>>>step_norm<<<<<< 0.4921777068381735\n",
      ">>>>>step_norm<<<<<< 0.9053949113744797\n",
      ">>>>>step_norm<<<<<< 1.0709279596339385\n",
      ">>>>>step_norm<<<<<< 0.5882335663566212\n",
      ">>>>>step_norm<<<<<< 0.7107684232512617\n",
      ">>>>>step_norm<<<<<< 0.9243819107570687\n",
      ">>>>>step_norm<<<<<< 0.8132544433261404\n",
      ">>>>>step_norm<<<<<< 0.5254738682429853\n",
      ">>>>>step_norm<<<<<< 1.3308603345849963\n",
      ">>>>>step_norm<<<<<< 0.4291389621908079\n",
      ">>>>>step_norm<<<<<< 0.6948232859576738\n",
      ">>>>>step_norm<<<<<< 0.5918817446974246\n",
      ">>>>>step_norm<<<<<< 0.6650743083589098\n",
      ">>>>>step_norm<<<<<< 0.9893870730681019\n",
      ">>>>>step_norm<<<<<< 0.30695576744449266\n",
      ">>>>>step_norm<<<<<< 1.25227612790993\n",
      ">>>>>step_norm<<<<<< 1.7143765386767724\n",
      ">>>>>step_norm<<<<<< 0.6805685908890673\n",
      ">>>>>step_norm<<<<<< 1.1502946974840709\n",
      ">>>>>step_norm<<<<<< 0.5455002458631606\n",
      ">>>>>step_norm<<<<<< 0.8956729285665065\n",
      ">>>>>step_norm<<<<<< 0.7788090052750376\n",
      ">>>>>step_norm<<<<<< 0.4212153960738916\n",
      ">>>>>step_norm<<<<<< 0.8023122663438992\n",
      ">>>>>step_norm<<<<<< 0.9134558066413349\n",
      ">>>>>step_norm<<<<<< 0.5904344135296631\n",
      ">>>>>step_norm<<<<<< 0.6348528417278839\n",
      ">>>>>step_norm<<<<<< 0.8144069657061204\n",
      ">>>>>step_norm<<<<<< 0.7911331788227023\n",
      ">>>>>step_norm<<<<<< 0.7685210125009463\n",
      ">>>>>step_norm<<<<<< 0.7841070719324077\n",
      ">>>>>step_norm<<<<<< 1.0786140248912708\n",
      ">>>>>step_norm<<<<<< 0.679718020172217\n",
      ">>>>>step_norm<<<<<< 0.587689056969548\n",
      ">>>>>step_norm<<<<<< 0.7071097410883468\n",
      ">>>>>step_norm<<<<<< 0.6314578100340752\n",
      ">>>>>step_norm<<<<<< 1.1230414179030643\n",
      ">>>>>step_norm<<<<<< 0.5194738905476666\n",
      ">>>>>step_norm<<<<<< 0.8179427116175219\n",
      ">>>>>step_norm<<<<<< 0.7397885140771696\n",
      ">>>>>step_norm<<<<<< 0.9276028134845585\n",
      ">>>>>step_norm<<<<<< 0.9422817184681167\n",
      ">>>>>step_norm<<<<<< 0.7917831867671588\n",
      ">>>>>step_norm<<<<<< 0.6389482693322156\n",
      ">>>>>step_norm<<<<<< 0.6508226518010709\n",
      ">>>>>step_norm<<<<<< 0.3575922666397386\n",
      ">>>>>step_norm<<<<<< 0.8374054363469603\n",
      ">>>>>step_norm<<<<<< 2.5708958821818513\n",
      ">>>>>step_norm<<<<<< 1.3976902265941913\n",
      ">>>>>step_norm<<<<<< 1.2772380082091428\n",
      ">>>>>step_norm<<<<<< 0.5121048323483853\n",
      ">>>>>step_norm<<<<<< 0.27634790636699497\n",
      ">>>>>step_norm<<<<<< 0.5922390201896011\n",
      ">>>>>step_norm<<<<<< 0.5630763526924705\n",
      ">>>>>step_norm<<<<<< 0.405134350040084\n",
      ">>>>>step_norm<<<<<< 0.7020817306773999\n",
      ">>>>>step_norm<<<<<< 0.5711880153510838\n",
      ">>>>>step_norm<<<<<< 1.1144399809952037\n",
      ">>>>>step_norm<<<<<< 0.7085780142858784\n",
      ">>>>>step_norm<<<<<< 0.7117595675477644\n",
      ">>>>>step_norm<<<<<< 0.6166038554590442\n",
      ">>>>>step_norm<<<<<< 0.7325915871566657\n",
      ">>>>>step_norm<<<<<< 0.7352185055796341\n",
      ">>>>>step_norm<<<<<< 0.6171366607505836\n",
      ">>>>>step_norm<<<<<< 0.2849176013983758\n",
      ">>>>>step_norm<<<<<< 1.6803965155923608\n",
      ">>>>>step_norm<<<<<< 0.2952755533884471\n",
      ">>>>>step_norm<<<<<< 1.0393396346989627\n",
      ">>>>>step_norm<<<<<< 1.0070438449993406\n",
      ">>>>>step_norm<<<<<< 1.2857138100603434\n",
      ">>>>>step_norm<<<<<< 0.25644223889483025\n",
      ">>>>>step_norm<<<<<< 1.4254481699223183\n",
      ">>>>>step_norm<<<<<< 1.5471395907460859\n",
      ">>>>>step_norm<<<<<< 0.6195807652900841\n",
      ">>>>>step_norm<<<<<< 0.2123519052390622\n",
      ">>>>>step_norm<<<<<< 0.6106407970521964\n",
      ">>>>>step_norm<<<<<< 0.8215826625993796\n",
      ">>>>>step_norm<<<<<< 1.144360468330805\n",
      ">>>>>step_norm<<<<<< 0.32276529952180416\n",
      ">>>>>step_norm<<<<<< 0.6053238083329293\n",
      ">>>>>step_norm<<<<<< 0.3849117446197245\n",
      ">>>>>step_norm<<<<<< 0.33403225197575054\n",
      ">>>>>step_norm<<<<<< 1.1283054154855015\n",
      ">>>>>step_norm<<<<<< 0.7299904389484586\n",
      ">>>>>step_norm<<<<<< 0.6418211171149808\n",
      ">>>>>step_norm<<<<<< 0.6797366717569768\n",
      ">>>>>step_norm<<<<<< 0.6410710759763255\n",
      ">>>>>step_norm<<<<<< 0.3911622620190744\n",
      ">>>>>step_norm<<<<<< 0.6270081019822046\n",
      ">>>>>step_norm<<<<<< 0.7106127066352607\n",
      ">>>>>step_norm<<<<<< 1.1314127559699203\n",
      ">>>>>step_norm<<<<<< 0.6688158863451928\n",
      ">>>>>step_norm<<<<<< 0.672502838409884\n",
      ">>>>>step_norm<<<<<< 0.48925339552137526\n",
      ">>>>>step_norm<<<<<< 0.3809582876671074\n",
      ">>>>>step_norm<<<<<< 0.6177312482475241\n",
      ">>>>>step_norm<<<<<< 1.4292243886108231\n",
      ">>>>>step_norm<<<<<< 0.7815031195629133\n",
      ">>>>>step_norm<<<<<< 0.8651461417813694\n",
      ">>>>>step_norm<<<<<< 0.40236484423344104\n",
      ">>>>>step_norm<<<<<< 1.3148785551224962\n",
      ">>>>>step_norm<<<<<< 0.36016010550055333\n",
      ">>>>>step_norm<<<<<< 0.44146447813646095\n",
      ">>>>>step_norm<<<<<< 0.4680500599913482\n",
      ">>>>>step_norm<<<<<< 0.714700631609775\n",
      ">>>>>step_norm<<<<<< 0.6621203410962958\n",
      ">>>>>step_norm<<<<<< 0.8517792440102591\n",
      ">>>>>step_norm<<<<<< 1.0182988355797709\n",
      ">>>>>step_norm<<<<<< 0.4936127463765717\n",
      ">>>>>step_norm<<<<<< 0.6139138310889956\n",
      ">>>>>step_norm<<<<<< 1.3712100681710533\n",
      ">>>>>step_norm<<<<<< 0.48593481742002903\n",
      ">>>>>step_norm<<<<<< 0.22866459156322108\n",
      ">>>>>step_norm<<<<<< 0.6543650652332127\n",
      ">>>>>step_norm<<<<<< 1.172317465564967\n",
      ">>>>>step_norm<<<<<< 0.48269925995460905\n",
      ">>>>>step_norm<<<<<< 0.35865855732251\n",
      ">>>>>step_norm<<<<<< 0.6249085835617086\n",
      ">>>>>step_norm<<<<<< 0.7831796022287504\n",
      ">>>>>step_norm<<<<<< 0.6321113464925198\n",
      ">>>>>step_norm<<<<<< 0.4454058734728189\n",
      ">>>>>step_norm<<<<<< 0.7243719928163406\n",
      ">>>>>step_norm<<<<<< 0.6516950106036317\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 15\n",
      ">>>>>step_norm<<<<<< 0.7999685278305817\n",
      ">>>>>step_norm<<<<<< 0.253633546300559\n",
      ">>>>>step_norm<<<<<< 0.36459352458064676\n",
      ">>>>>step_norm<<<<<< 1.3516168006768188\n",
      ">>>>>step_norm<<<<<< 1.1018732488766636\n",
      ">>>>>step_norm<<<<<< 0.6218604132946348\n",
      ">>>>>step_norm<<<<<< 0.33496548403765364\n",
      ">>>>>step_norm<<<<<< 0.4414068013683221\n",
      ">>>>>step_norm<<<<<< 0.48798071488773526\n",
      ">>>>>step_norm<<<<<< 0.4808031838040039\n",
      ">>>>>step_norm<<<<<< 0.4431430033282307\n",
      ">>>>>step_norm<<<<<< 0.8123021987985048\n",
      ">>>>>step_norm<<<<<< 0.5557647413618904\n",
      ">>>>>step_norm<<<<<< 0.9059522308555605\n",
      ">>>>>step_norm<<<<<< 1.1062614233829027\n",
      ">>>>>step_norm<<<<<< 2.021681103370017\n",
      ">>>>>step_norm<<<<<< 0.6341847479867463\n",
      ">>>>>step_norm<<<<<< 0.7695616343430017\n",
      ">>>>>step_norm<<<<<< 1.0655751588899727\n",
      ">>>>>step_norm<<<<<< 0.40793864288790926\n",
      ">>>>>step_norm<<<<<< 0.34468937451024784\n",
      ">>>>>step_norm<<<<<< 0.8532950900062686\n",
      ">>>>>step_norm<<<<<< 0.493045291483256\n",
      ">>>>>step_norm<<<<<< 0.9100133945391231\n",
      ">>>>>step_norm<<<<<< 0.29560976040888404\n",
      ">>>>>step_norm<<<<<< 0.42913143922523017\n",
      ">>>>>step_norm<<<<<< 0.38127725215393315\n",
      ">>>>>step_norm<<<<<< 0.6814982201874519\n",
      ">>>>>step_norm<<<<<< 0.5422944342073794\n",
      ">>>>>step_norm<<<<<< 0.7341208049131694\n",
      ">>>>>step_norm<<<<<< 0.8549118288226597\n",
      ">>>>>step_norm<<<<<< 0.7831177580465916\n",
      ">>>>>step_norm<<<<<< 0.3074622761741638\n",
      ">>>>>step_norm<<<<<< 0.5510498907146353\n",
      ">>>>>step_norm<<<<<< 0.32439571206438245\n",
      ">>>>>step_norm<<<<<< 1.296196985926621\n",
      ">>>>>step_norm<<<<<< 0.5811091280936084\n",
      ">>>>>step_norm<<<<<< 1.2297503028998134\n",
      ">>>>>step_norm<<<<<< 0.3501694145173453\n",
      ">>>>>step_norm<<<<<< 0.2773385589204012\n",
      ">>>>>step_norm<<<<<< 0.30074642423159925\n",
      ">>>>>step_norm<<<<<< 0.4801529760192182\n",
      ">>>>>step_norm<<<<<< 1.11534544276964\n",
      ">>>>>step_norm<<<<<< 1.1119938113623553\n",
      ">>>>>step_norm<<<<<< 0.5201285301015474\n",
      ">>>>>step_norm<<<<<< 0.3952011018992716\n",
      ">>>>>step_norm<<<<<< 0.8828469356175119\n",
      ">>>>>step_norm<<<<<< 0.4540650288692766\n",
      ">>>>>step_norm<<<<<< 1.2284092054193787\n",
      ">>>>>step_norm<<<<<< 0.3644138201029107\n",
      ">>>>>step_norm<<<<<< 0.593934731223038\n",
      ">>>>>step_norm<<<<<< 0.31106632304672627\n",
      ">>>>>step_norm<<<<<< 0.3094430025213179\n",
      ">>>>>step_norm<<<<<< 0.2867590105236117\n",
      ">>>>>step_norm<<<<<< 0.24649245961277463\n",
      ">>>>>step_norm<<<<<< 0.45546497897880095\n",
      ">>>>>step_norm<<<<<< 0.41554790991330837\n",
      ">>>>>step_norm<<<<<< 0.8824909643108995\n",
      ">>>>>step_norm<<<<<< 0.25060405196947005\n",
      ">>>>>step_norm<<<<<< 0.27798777953490994\n",
      ">>>>>step_norm<<<<<< 0.38272815337710914\n",
      ">>>>>step_norm<<<<<< 0.4356355786674173\n",
      ">>>>>step_norm<<<<<< 0.39100698925415295\n",
      ">>>>>step_norm<<<<<< 0.388335465261405\n",
      ">>>>>step_norm<<<<<< 0.4878604648113964\n",
      ">>>>>step_norm<<<<<< 0.34263760997212694\n",
      ">>>>>step_norm<<<<<< 0.8535640520595401\n",
      ">>>>>step_norm<<<<<< 0.9514814590693649\n",
      ">>>>>step_norm<<<<<< 0.5590529864914995\n",
      ">>>>>step_norm<<<<<< 0.3055345311190931\n",
      ">>>>>step_norm<<<<<< 0.3893408644552673\n",
      ">>>>>step_norm<<<<<< 0.9718336714276093\n",
      ">>>>>step_norm<<<<<< 0.14499320188501374\n",
      ">>>>>step_norm<<<<<< 0.735029679257904\n",
      ">>>>>step_norm<<<<<< 0.4769830102559384\n",
      ">>>>>step_norm<<<<<< 0.24547203317568572\n",
      ">>>>>step_norm<<<<<< 0.47398753131107857\n",
      ">>>>>step_norm<<<<<< 0.6488462657782005\n",
      ">>>>>step_norm<<<<<< 0.18658180045523617\n",
      ">>>>>step_norm<<<<<< 0.5002079429280057\n",
      ">>>>>step_norm<<<<<< 0.7566992681449345\n",
      ">>>>>step_norm<<<<<< 0.6660572302821745\n",
      ">>>>>step_norm<<<<<< 0.6103914491510717\n",
      ">>>>>step_norm<<<<<< 0.46798954195820774\n",
      ">>>>>step_norm<<<<<< 0.2223416385376645\n",
      ">>>>>step_norm<<<<<< 0.22597288337605792\n",
      ">>>>>step_norm<<<<<< 0.5325891128333039\n",
      ">>>>>step_norm<<<<<< 0.7096006747129429\n",
      ">>>>>step_norm<<<<<< 0.49492102803306204\n",
      ">>>>>step_norm<<<<<< 0.277115464455377\n",
      ">>>>>step_norm<<<<<< 0.4549934040316786\n",
      ">>>>>step_norm<<<<<< 0.339268295075964\n",
      ">>>>>step_norm<<<<<< 1.0673976168207275\n",
      ">>>>>step_norm<<<<<< 1.1731566841096857\n",
      ">>>>>step_norm<<<<<< 0.2955259430056518\n",
      ">>>>>step_norm<<<<<< 0.6541634554438066\n",
      ">>>>>step_norm<<<<<< 0.22304802411677777\n",
      ">>>>>step_norm<<<<<< 1.1505615220271073\n",
      ">>>>>step_norm<<<<<< 0.35572752094837623\n",
      ">>>>>step_norm<<<<<< 0.16047956955290504\n",
      ">>>>>step_norm<<<<<< 0.4307774576785239\n",
      ">>>>>step_norm<<<<<< 0.3434724479884342\n",
      ">>>>>step_norm<<<<<< 0.7134638658933444\n",
      ">>>>>step_norm<<<<<< 0.2620161759872912\n",
      ">>>>>step_norm<<<<<< 0.35236501831990463\n",
      ">>>>>step_norm<<<<<< 0.7129883563921019\n",
      ">>>>>step_norm<<<<<< 0.6578738695010478\n",
      ">>>>>step_norm<<<<<< 0.4934152668605357\n",
      ">>>>>step_norm<<<<<< 0.9106259878072763\n",
      ">>>>>step_norm<<<<<< 1.1937861591755843\n",
      ">>>>>step_norm<<<<<< 0.3242523141868063\n",
      ">>>>>step_norm<<<<<< 0.5549561556964925\n",
      ">>>>>step_norm<<<<<< 0.2757852410304989\n",
      ">>>>>step_norm<<<<<< 1.0213986293826869\n",
      ">>>>>step_norm<<<<<< 0.29064650129727176\n",
      ">>>>>step_norm<<<<<< 0.7079605653735809\n",
      ">>>>>step_norm<<<<<< 1.3698690238574418\n",
      ">>>>>step_norm<<<<<< 0.7210546484010955\n",
      ">>>>>step_norm<<<<<< 0.38700869443502167\n",
      ">>>>>step_norm<<<<<< 0.6880304422412603\n",
      ">>>>>step_norm<<<<<< 0.3129169164825108\n",
      ">>>>>step_norm<<<<<< 0.8645151934285262\n",
      ">>>>>step_norm<<<<<< 0.7083666371188921\n",
      ">>>>>step_norm<<<<<< 0.7109069880261293\n",
      ">>>>>step_norm<<<<<< 0.6575393283273611\n",
      ">>>>>step_norm<<<<<< 0.3236299747315137\n",
      ">>>>>step_norm<<<<<< 0.6408284096646806\n",
      ">>>>>step_norm<<<<<< 0.2687510832143921\n",
      ">>>>>step_norm<<<<<< 0.26632882646576334\n",
      ">>>>>step_norm<<<<<< 0.48140547179795756\n",
      ">>>>>step_norm<<<<<< 1.3976981484430058\n",
      ">>>>>step_norm<<<<<< 1.2712070193706952\n",
      ">>>>>step_norm<<<<<< 0.7015848662920989\n",
      ">>>>>step_norm<<<<<< 0.6488038118141035\n",
      ">>>>>step_norm<<<<<< 0.3296456989303362\n",
      ">>>>>step_norm<<<<<< 0.5232041215526374\n",
      ">>>>>step_norm<<<<<< 0.46857389638940494\n",
      ">>>>>step_norm<<<<<< 0.5610977151852514\n",
      ">>>>>step_norm<<<<<< 0.21593004924051742\n",
      ">>>>>step_norm<<<<<< 0.5178745837903083\n",
      ">>>>>step_norm<<<<<< 0.4540298535254466\n",
      ">>>>>step_norm<<<<<< 0.5153046871387964\n",
      ">>>>>step_norm<<<<<< 0.738993038634865\n",
      ">>>>>step_norm<<<<<< 1.7759394149471717\n",
      ">>>>>step_norm<<<<<< 0.7504927679469671\n",
      ">>>>>step_norm<<<<<< 0.3186377637678551\n",
      ">>>>>step_norm<<<<<< 0.42891998768566963\n",
      ">>>>>step_norm<<<<<< 0.6221307377368014\n",
      ">>>>>step_norm<<<<<< 1.178317042347361\n",
      ">>>>>step_norm<<<<<< 0.19253624683803167\n",
      ">>>>>step_norm<<<<<< 0.5386202117126813\n",
      ">>>>>step_norm<<<<<< 0.7157814420360529\n",
      ">>>>>step_norm<<<<<< 0.32477754197625336\n",
      ">>>>>step_norm<<<<<< 1.2832803492151863\n",
      ">>>>>step_norm<<<<<< 1.152941463894378\n",
      ">>>>>step_norm<<<<<< 0.8489396537469489\n",
      ">>>>>step_norm<<<<<< 0.4420658674032692\n",
      ">>>>>step_norm<<<<<< 0.6487137220820179\n",
      ">>>>>step_norm<<<<<< 0.7633326362881324\n",
      ">>>>>step_norm<<<<<< 1.7368455961429132\n",
      ">>>>>step_norm<<<<<< 0.6944172226633947\n",
      ">>>>>step_norm<<<<<< 0.3913103297725079\n",
      ">>>>>step_norm<<<<<< 0.8745372987717904\n",
      ">>>>>step_norm<<<<<< 0.7369438119459539\n",
      ">>>>>step_norm<<<<<< 0.25945289392210086\n",
      ">>>>>step_norm<<<<<< 0.2016969477874857\n",
      ">>>>>step_norm<<<<<< 0.6450178374954367\n",
      ">>>>>step_norm<<<<<< 0.2401179893330131\n",
      ">>>>>step_norm<<<<<< 0.8321176838985492\n",
      ">>>>>step_norm<<<<<< 0.38769037349619084\n",
      ">>>>>step_norm<<<<<< 0.29376548132071595\n",
      ">>>>>step_norm<<<<<< 0.2969996293736209\n",
      ">>>>>step_norm<<<<<< 0.653970429272573\n",
      ">>>>>step_norm<<<<<< 0.6417565705657059\n",
      ">>>>>step_norm<<<<<< 0.3183282150209653\n",
      ">>>>>step_norm<<<<<< 0.4204771001613189\n",
      ">>>>>step_norm<<<<<< 0.753841904985703\n",
      ">>>>>step_norm<<<<<< 0.5726618718726115\n",
      ">>>>>step_norm<<<<<< 0.42839805461396113\n",
      ">>>>>step_norm<<<<<< 0.5281505978369074\n",
      ">>>>>step_norm<<<<<< 1.2026282360259763\n",
      ">>>>>step_norm<<<<<< 0.9816942576202744\n",
      ">>>>>step_norm<<<<<< 1.14419282867826\n",
      ">>>>>step_norm<<<<<< 0.6408582637354452\n",
      ">>>>>step_norm<<<<<< 0.3861350976667373\n",
      ">>>>>step_norm<<<<<< 0.5224888638088495\n",
      ">>>>>step_norm<<<<<< 0.4185764608330578\n",
      ">>>>>step_norm<<<<<< 0.6582439794967395\n",
      ">>>>>step_norm<<<<<< 0.37457127396019435\n",
      ">>>>>step_norm<<<<<< 1.5378158164881763\n",
      ">>>>>step_norm<<<<<< 0.3581845525029677\n",
      ">>>>>step_norm<<<<<< 1.410213744911877\n",
      ">>>>>step_norm<<<<<< 0.6620643180829852\n",
      ">>>>>step_norm<<<<<< 0.541358812883294\n",
      ">>>>>step_norm<<<<<< 0.8024697833942376\n",
      ">>>>>step_norm<<<<<< 1.08190212165888\n",
      ">>>>>step_norm<<<<<< 0.3831696325460831\n",
      ">>>>>step_norm<<<<<< 0.8084526626048593\n",
      ">>>>>step_norm<<<<<< 0.7050040198105728\n",
      ">>>>>step_norm<<<<<< 0.4565495131842561\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 16\n",
      ">>>>>step_norm<<<<<< 0.43212773020521345\n",
      ">>>>>step_norm<<<<<< 0.5672657277435807\n",
      ">>>>>step_norm<<<<<< 0.7898774579939531\n",
      ">>>>>step_norm<<<<<< 0.33141139036569345\n",
      ">>>>>step_norm<<<<<< 0.43011905297475733\n",
      ">>>>>step_norm<<<<<< 0.17271859347877513\n",
      ">>>>>step_norm<<<<<< 0.35491972979308206\n",
      ">>>>>step_norm<<<<<< 0.577435156172729\n",
      ">>>>>step_norm<<<<<< 0.9503931998124134\n",
      ">>>>>step_norm<<<<<< 0.5155310918436804\n",
      ">>>>>step_norm<<<<<< 0.5299956752465228\n",
      ">>>>>step_norm<<<<<< 0.4360989217334302\n",
      ">>>>>step_norm<<<<<< 0.39584283375215257\n",
      ">>>>>step_norm<<<<<< 0.6784418450855699\n",
      ">>>>>step_norm<<<<<< 0.8317626887486662\n",
      ">>>>>step_norm<<<<<< 0.25581346316070924\n",
      ">>>>>step_norm<<<<<< 0.7122979058835546\n",
      ">>>>>step_norm<<<<<< 0.6644756532248656\n",
      ">>>>>step_norm<<<<<< 0.5447225374792248\n",
      ">>>>>step_norm<<<<<< 0.33167980792490276\n",
      ">>>>>step_norm<<<<<< 0.6100057003508833\n",
      ">>>>>step_norm<<<<<< 0.4938868345432672\n",
      ">>>>>step_norm<<<<<< 0.428801668149013\n",
      ">>>>>step_norm<<<<<< 0.7317726369129972\n",
      ">>>>>step_norm<<<<<< 0.5836983141141017\n",
      ">>>>>step_norm<<<<<< 0.26012019014063004\n",
      ">>>>>step_norm<<<<<< 0.4150446442342422\n",
      ">>>>>step_norm<<<<<< 0.21769433163069074\n",
      ">>>>>step_norm<<<<<< 2.064657391639406\n",
      ">>>>>step_norm<<<<<< 0.24676319277968184\n",
      ">>>>>step_norm<<<<<< 2.0765437061226675\n",
      ">>>>>step_norm<<<<<< 0.9399015926085633\n",
      ">>>>>step_norm<<<<<< 0.29346548626709207\n",
      ">>>>>step_norm<<<<<< 0.42702120535693683\n",
      ">>>>>step_norm<<<<<< 0.2330815371600949\n",
      ">>>>>step_norm<<<<<< 0.8285913311800651\n",
      ">>>>>step_norm<<<<<< 0.7745908692609196\n",
      ">>>>>step_norm<<<<<< 0.4747037668382602\n",
      ">>>>>step_norm<<<<<< 0.3686911349683354\n",
      ">>>>>step_norm<<<<<< 1.1122425374980813\n",
      ">>>>>step_norm<<<<<< 0.26096764384889676\n",
      ">>>>>step_norm<<<<<< 0.8317647088527412\n",
      ">>>>>step_norm<<<<<< 0.41613027501501926\n",
      ">>>>>step_norm<<<<<< 0.7254405479416434\n",
      ">>>>>step_norm<<<<<< 0.22041045000643458\n",
      ">>>>>step_norm<<<<<< 0.4084007791620429\n",
      ">>>>>step_norm<<<<<< 0.5270941953171077\n",
      ">>>>>step_norm<<<<<< 0.17802245322668242\n",
      ">>>>>step_norm<<<<<< 0.8760825951715203\n",
      ">>>>>step_norm<<<<<< 0.6179370192053462\n",
      ">>>>>step_norm<<<<<< 0.4813986802128242\n",
      ">>>>>step_norm<<<<<< 1.3252324924313077\n",
      ">>>>>step_norm<<<<<< 0.3688549667633079\n",
      ">>>>>step_norm<<<<<< 0.5417368175154428\n",
      ">>>>>step_norm<<<<<< 0.3623183915910462\n",
      ">>>>>step_norm<<<<<< 0.671234122509278\n",
      ">>>>>step_norm<<<<<< 0.5337598980124613\n",
      ">>>>>step_norm<<<<<< 0.2762312830356145\n",
      ">>>>>step_norm<<<<<< 0.5516134302507799\n",
      ">>>>>step_norm<<<<<< 0.46771626589033166\n",
      ">>>>>step_norm<<<<<< 0.7800002148952966\n",
      ">>>>>step_norm<<<<<< 0.40620326531688666\n",
      ">>>>>step_norm<<<<<< 0.4758719553863775\n",
      ">>>>>step_norm<<<<<< 0.5937000103593258\n",
      ">>>>>step_norm<<<<<< 0.2757149837088487\n",
      ">>>>>step_norm<<<<<< 0.27468872188861926\n",
      ">>>>>step_norm<<<<<< 0.3728532959188684\n",
      ">>>>>step_norm<<<<<< 0.1957073999203182\n",
      ">>>>>step_norm<<<<<< 0.49297147482108555\n",
      ">>>>>step_norm<<<<<< 0.2629250090014761\n",
      ">>>>>step_norm<<<<<< 0.8837931555049198\n",
      ">>>>>step_norm<<<<<< 0.5811749154540852\n",
      ">>>>>step_norm<<<<<< 0.7977618890367504\n",
      ">>>>>step_norm<<<<<< 1.4865964769464368\n",
      ">>>>>step_norm<<<<<< 0.7366036384678023\n",
      ">>>>>step_norm<<<<<< 0.17278186625425884\n",
      ">>>>>step_norm<<<<<< 0.4964137275626251\n",
      ">>>>>step_norm<<<<<< 0.3284867631542426\n",
      ">>>>>step_norm<<<<<< 0.3181255617780593\n",
      ">>>>>step_norm<<<<<< 0.7720803228785807\n",
      ">>>>>step_norm<<<<<< 1.1169165974713533\n",
      ">>>>>step_norm<<<<<< 1.2501762458538066\n",
      ">>>>>step_norm<<<<<< 0.42910271414697115\n",
      ">>>>>step_norm<<<<<< 0.5892025609229884\n",
      ">>>>>step_norm<<<<<< 0.36813279892599177\n",
      ">>>>>step_norm<<<<<< 0.34719370685880885\n",
      ">>>>>step_norm<<<<<< 0.27108336780828907\n",
      ">>>>>step_norm<<<<<< 0.46344739642961186\n",
      ">>>>>step_norm<<<<<< 2.0656196020285185\n",
      ">>>>>step_norm<<<<<< 0.29282275936029367\n",
      ">>>>>step_norm<<<<<< 0.9505969180062817\n",
      ">>>>>step_norm<<<<<< 0.3596967050428695\n",
      ">>>>>step_norm<<<<<< 0.6087398399296808\n",
      ">>>>>step_norm<<<<<< 0.3113115697290286\n",
      ">>>>>step_norm<<<<<< 0.5907734333566182\n",
      ">>>>>step_norm<<<<<< 0.424599607149144\n",
      ">>>>>step_norm<<<<<< 0.33181474668532224\n",
      ">>>>>step_norm<<<<<< 0.4665022124131628\n",
      ">>>>>step_norm<<<<<< 0.5054388837581705\n",
      ">>>>>step_norm<<<<<< 0.218519808788613\n",
      ">>>>>step_norm<<<<<< 0.6893396668503905\n",
      ">>>>>step_norm<<<<<< 0.5927489147514418\n",
      ">>>>>step_norm<<<<<< 0.71169879228217\n",
      ">>>>>step_norm<<<<<< 0.6069564263985603\n",
      ">>>>>step_norm<<<<<< 0.9454562487186847\n",
      ">>>>>step_norm<<<<<< 0.4437281395890869\n",
      ">>>>>step_norm<<<<<< 1.2793657829268803\n",
      ">>>>>step_norm<<<<<< 0.7693194691982468\n",
      ">>>>>step_norm<<<<<< 0.6185841004803858\n",
      ">>>>>step_norm<<<<<< 0.4070705716598646\n",
      ">>>>>step_norm<<<<<< 0.4348115364970892\n",
      ">>>>>step_norm<<<<<< 0.42561814686214106\n",
      ">>>>>step_norm<<<<<< 0.6204250718618585\n",
      ">>>>>step_norm<<<<<< 0.4459641968924278\n",
      ">>>>>step_norm<<<<<< 0.34606686348887433\n",
      ">>>>>step_norm<<<<<< 0.34016846568095205\n",
      ">>>>>step_norm<<<<<< 0.36963521364386437\n",
      ">>>>>step_norm<<<<<< 0.8071049923032281\n",
      ">>>>>step_norm<<<<<< 0.5308968297831448\n",
      ">>>>>step_norm<<<<<< 0.8507464524893144\n",
      ">>>>>step_norm<<<<<< 0.42354501066515315\n",
      ">>>>>step_norm<<<<<< 0.7458199240099294\n",
      ">>>>>step_norm<<<<<< 0.28773993947624815\n",
      ">>>>>step_norm<<<<<< 1.1174080514548814\n",
      ">>>>>step_norm<<<<<< 1.2195652852492747\n",
      ">>>>>step_norm<<<<<< 0.3198218744360234\n",
      ">>>>>step_norm<<<<<< 0.3073406389192049\n",
      ">>>>>step_norm<<<<<< 0.4746314472881799\n",
      ">>>>>step_norm<<<<<< 0.27244706690124176\n",
      ">>>>>step_norm<<<<<< 0.4708821654638247\n",
      ">>>>>step_norm<<<<<< 0.6044966367856842\n",
      ">>>>>step_norm<<<<<< 0.8359282080353957\n",
      ">>>>>step_norm<<<<<< 0.5200243081213677\n",
      ">>>>>step_norm<<<<<< 0.5023997370494072\n",
      ">>>>>step_norm<<<<<< 0.5326685443881454\n",
      ">>>>>step_norm<<<<<< 0.41437733051599523\n",
      ">>>>>step_norm<<<<<< 0.3560479563225857\n",
      ">>>>>step_norm<<<<<< 0.20759890865745623\n",
      ">>>>>step_norm<<<<<< 0.5630534465679442\n",
      ">>>>>step_norm<<<<<< 0.3763130502776575\n",
      ">>>>>step_norm<<<<<< 0.4134014721471407\n",
      ">>>>>step_norm<<<<<< 0.9966970822895187\n",
      ">>>>>step_norm<<<<<< 0.5935369742081544\n",
      ">>>>>step_norm<<<<<< 0.42512589577583537\n",
      ">>>>>step_norm<<<<<< 0.8000059165550272\n",
      ">>>>>step_norm<<<<<< 0.3156025522326404\n",
      ">>>>>step_norm<<<<<< 0.21599019195710728\n",
      ">>>>>step_norm<<<<<< 0.8351890907033064\n",
      ">>>>>step_norm<<<<<< 0.36709563745884716\n",
      ">>>>>step_norm<<<<<< 0.39168058572803943\n",
      ">>>>>step_norm<<<<<< 0.4368171331564715\n",
      ">>>>>step_norm<<<<<< 0.4894950128291041\n",
      ">>>>>step_norm<<<<<< 0.42722463866988775\n",
      ">>>>>step_norm<<<<<< 0.9827819580974761\n",
      ">>>>>step_norm<<<<<< 0.44136145688082506\n",
      ">>>>>step_norm<<<<<< 0.3569259830526929\n",
      ">>>>>step_norm<<<<<< 0.8558357170625701\n",
      ">>>>>step_norm<<<<<< 0.3905141860483876\n",
      ">>>>>step_norm<<<<<< 0.22631448574881796\n",
      ">>>>>step_norm<<<<<< 0.776591056062331\n",
      ">>>>>step_norm<<<<<< 0.6084591914972889\n",
      ">>>>>step_norm<<<<<< 0.39063431582792496\n",
      ">>>>>step_norm<<<<<< 0.7079070412513174\n",
      ">>>>>step_norm<<<<<< 1.8116889539326875\n",
      ">>>>>step_norm<<<<<< 0.4096770046917387\n",
      ">>>>>step_norm<<<<<< 0.36199325213252675\n",
      ">>>>>step_norm<<<<<< 0.21704021073487953\n",
      ">>>>>step_norm<<<<<< 1.043723135795104\n",
      ">>>>>step_norm<<<<<< 0.6229212699903537\n",
      ">>>>>step_norm<<<<<< 0.551045698046198\n",
      ">>>>>step_norm<<<<<< 0.43886317978734884\n",
      ">>>>>step_norm<<<<<< 0.8272338365993603\n",
      ">>>>>step_norm<<<<<< 0.33153095612227657\n",
      ">>>>>step_norm<<<<<< 0.38987054144291816\n",
      ">>>>>step_norm<<<<<< 0.4564293453612304\n",
      ">>>>>step_norm<<<<<< 0.3153002989094258\n",
      ">>>>>step_norm<<<<<< 0.49679317007882834\n",
      ">>>>>step_norm<<<<<< 0.5369182632899663\n",
      ">>>>>step_norm<<<<<< 0.36729936147493153\n",
      ">>>>>step_norm<<<<<< 0.7648584534528123\n",
      ">>>>>step_norm<<<<<< 0.4659717041357386\n",
      ">>>>>step_norm<<<<<< 0.28365081857385305\n",
      ">>>>>step_norm<<<<<< 0.33750515601423225\n",
      ">>>>>step_norm<<<<<< 0.8049092448002017\n",
      ">>>>>step_norm<<<<<< 0.8898203698339119\n",
      ">>>>>step_norm<<<<<< 0.5088840961129889\n",
      ">>>>>step_norm<<<<<< 0.5163608207524436\n",
      ">>>>>step_norm<<<<<< 0.25627531797359815\n",
      ">>>>>step_norm<<<<<< 0.6215011583214073\n",
      ">>>>>step_norm<<<<<< 0.2545974164830599\n",
      ">>>>>step_norm<<<<<< 0.6146298414148663\n",
      ">>>>>step_norm<<<<<< 0.8312276992766361\n",
      ">>>>>step_norm<<<<<< 1.3094013785809253\n",
      ">>>>>step_norm<<<<<< 1.3160774543210727\n",
      ">>>>>step_norm<<<<<< 0.21091529029959993\n",
      ">>>>>step_norm<<<<<< 0.9374932197737205\n",
      ">>>>>step_norm<<<<<< 0.28573676955497945\n",
      ">>>>>step_norm<<<<<< 0.7586854102849423\n",
      ">>>>>step_norm<<<<<< 0.8429847678650908\n",
      ">>>>>step_norm<<<<<< 0.4032173954086255\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 17\n",
      ">>>>>step_norm<<<<<< 0.26845073249619916\n",
      ">>>>>step_norm<<<<<< 0.5278251217844341\n",
      ">>>>>step_norm<<<<<< 0.42076350391141965\n",
      ">>>>>step_norm<<<<<< 1.0954600518310105\n",
      ">>>>>step_norm<<<<<< 1.0500141415171687\n",
      ">>>>>step_norm<<<<<< 0.65501434405758\n",
      ">>>>>step_norm<<<<<< 0.1584877682143167\n",
      ">>>>>step_norm<<<<<< 0.37050791394652915\n",
      ">>>>>step_norm<<<<<< 0.9096834513626336\n",
      ">>>>>step_norm<<<<<< 0.38012102627629973\n",
      ">>>>>step_norm<<<<<< 0.27766423032422877\n",
      ">>>>>step_norm<<<<<< 0.47608780460114325\n",
      ">>>>>step_norm<<<<<< 0.5904720302242745\n",
      ">>>>>step_norm<<<<<< 0.6015085324980526\n",
      ">>>>>step_norm<<<<<< 0.5787716222225693\n",
      ">>>>>step_norm<<<<<< 0.23480939784548316\n",
      ">>>>>step_norm<<<<<< 0.36812055852324205\n",
      ">>>>>step_norm<<<<<< 1.2853684190584203\n",
      ">>>>>step_norm<<<<<< 0.35212930943331283\n",
      ">>>>>step_norm<<<<<< 0.378836038712178\n",
      ">>>>>step_norm<<<<<< 0.39943200259758843\n",
      ">>>>>step_norm<<<<<< 0.9381242821011112\n",
      ">>>>>step_norm<<<<<< 0.44117387712503303\n",
      ">>>>>step_norm<<<<<< 1.0558855525659583\n",
      ">>>>>step_norm<<<<<< 0.9895943154236267\n",
      ">>>>>step_norm<<<<<< 0.5213497265989475\n",
      ">>>>>step_norm<<<<<< 0.7807542734697626\n",
      ">>>>>step_norm<<<<<< 0.770134906791482\n",
      ">>>>>step_norm<<<<<< 0.30647296680818187\n",
      ">>>>>step_norm<<<<<< 0.7995932443564769\n",
      ">>>>>step_norm<<<<<< 0.6062133355136984\n",
      ">>>>>step_norm<<<<<< 0.36655087613395165\n",
      ">>>>>step_norm<<<<<< 0.7166322461815624\n",
      ">>>>>step_norm<<<<<< 0.6973804923794118\n",
      ">>>>>step_norm<<<<<< 0.3282977944022476\n",
      ">>>>>step_norm<<<<<< 0.15363649670933302\n",
      ">>>>>step_norm<<<<<< 0.4671422261888686\n",
      ">>>>>step_norm<<<<<< 0.5160586425808732\n",
      ">>>>>step_norm<<<<<< 0.21296539985497215\n",
      ">>>>>step_norm<<<<<< 0.23420877215422975\n",
      ">>>>>step_norm<<<<<< 0.7678113400572366\n",
      ">>>>>step_norm<<<<<< 0.6618202114595872\n",
      ">>>>>step_norm<<<<<< 0.37092117190138507\n",
      ">>>>>step_norm<<<<<< 0.2981413886503371\n",
      ">>>>>step_norm<<<<<< 0.6280976576454876\n",
      ">>>>>step_norm<<<<<< 0.33411632040639894\n",
      ">>>>>step_norm<<<<<< 0.88225246601915\n",
      ">>>>>step_norm<<<<<< 0.7204968037320325\n",
      ">>>>>step_norm<<<<<< 0.17725316440849703\n",
      ">>>>>step_norm<<<<<< 0.7804483847296446\n",
      ">>>>>step_norm<<<<<< 0.35260809594882075\n",
      ">>>>>step_norm<<<<<< 0.13803789038725223\n",
      ">>>>>step_norm<<<<<< 0.7602841208724069\n",
      ">>>>>step_norm<<<<<< 0.2871900688921626\n",
      ">>>>>step_norm<<<<<< 0.25563167794415326\n",
      ">>>>>step_norm<<<<<< 0.2583588732894494\n",
      ">>>>>step_norm<<<<<< 0.5057583122908071\n",
      ">>>>>step_norm<<<<<< 0.9529533783479083\n",
      ">>>>>step_norm<<<<<< 0.37792275796459773\n",
      ">>>>>step_norm<<<<<< 0.34956281062208633\n",
      ">>>>>step_norm<<<<<< 0.3028248685651134\n",
      ">>>>>step_norm<<<<<< 0.2797941051056012\n",
      ">>>>>step_norm<<<<<< 0.3028353840872476\n",
      ">>>>>step_norm<<<<<< 0.18474569442522623\n",
      ">>>>>step_norm<<<<<< 0.4161932704307999\n",
      ">>>>>step_norm<<<<<< 0.18150374199777794\n",
      ">>>>>step_norm<<<<<< 0.5394503329934229\n",
      ">>>>>step_norm<<<<<< 0.9071079132267763\n",
      ">>>>>step_norm<<<<<< 0.1706269328923596\n",
      ">>>>>step_norm<<<<<< 0.342232981484249\n",
      ">>>>>step_norm<<<<<< 0.39972495002387864\n",
      ">>>>>step_norm<<<<<< 0.3404207820103391\n",
      ">>>>>step_norm<<<<<< 0.37912399952614306\n",
      ">>>>>step_norm<<<<<< 0.36987645875021175\n",
      ">>>>>step_norm<<<<<< 0.33284489775706055\n",
      ">>>>>step_norm<<<<<< 0.46343415634602986\n",
      ">>>>>step_norm<<<<<< 0.36031698220148645\n",
      ">>>>>step_norm<<<<<< 0.32219901140995244\n",
      ">>>>>step_norm<<<<<< 0.4391552216360743\n",
      ">>>>>step_norm<<<<<< 0.567193062481456\n",
      ">>>>>step_norm<<<<<< 0.44661879131859944\n",
      ">>>>>step_norm<<<<<< 0.4794228557034686\n",
      ">>>>>step_norm<<<<<< 1.0313628935784032\n",
      ">>>>>step_norm<<<<<< 0.11402892699653196\n",
      ">>>>>step_norm<<<<<< 0.20424083219698183\n",
      ">>>>>step_norm<<<<<< 0.9701697404366219\n",
      ">>>>>step_norm<<<<<< 0.2088763558696825\n",
      ">>>>>step_norm<<<<<< 0.7191075479368514\n",
      ">>>>>step_norm<<<<<< 0.6421073718264998\n",
      ">>>>>step_norm<<<<<< 0.6078278462762506\n",
      ">>>>>step_norm<<<<<< 0.3672185335375638\n",
      ">>>>>step_norm<<<<<< 0.507459656712424\n",
      ">>>>>step_norm<<<<<< 0.5700064995940208\n",
      ">>>>>step_norm<<<<<< 0.4418326494828155\n",
      ">>>>>step_norm<<<<<< 0.4164192325946677\n",
      ">>>>>step_norm<<<<<< 0.3842428630994537\n",
      ">>>>>step_norm<<<<<< 0.24518706693513978\n",
      ">>>>>step_norm<<<<<< 0.8536872565362973\n",
      ">>>>>step_norm<<<<<< 0.4241342991284925\n",
      ">>>>>step_norm<<<<<< 0.39443410902542936\n",
      ">>>>>step_norm<<<<<< 0.6692435325603522\n",
      ">>>>>step_norm<<<<<< 0.6800770004450919\n",
      ">>>>>step_norm<<<<<< 0.4210634433593909\n",
      ">>>>>step_norm<<<<<< 0.5803832068529063\n",
      ">>>>>step_norm<<<<<< 1.204777946329604\n",
      ">>>>>step_norm<<<<<< 1.3179523275836087\n",
      ">>>>>step_norm<<<<<< 0.5787606316650751\n",
      ">>>>>step_norm<<<<<< 0.49917515741980195\n",
      ">>>>>step_norm<<<<<< 0.8679008918906851\n",
      ">>>>>step_norm<<<<<< 0.39344178496975096\n",
      ">>>>>step_norm<<<<<< 0.6413478465095176\n",
      ">>>>>step_norm<<<<<< 0.7395900532851141\n",
      ">>>>>step_norm<<<<<< 1.3121540812898373\n",
      ">>>>>step_norm<<<<<< 0.3246736742072824\n",
      ">>>>>step_norm<<<<<< 0.5855351399660921\n",
      ">>>>>step_norm<<<<<< 0.5883631734991863\n",
      ">>>>>step_norm<<<<<< 0.2664121345103303\n",
      ">>>>>step_norm<<<<<< 0.5087705274007432\n",
      ">>>>>step_norm<<<<<< 0.5129681732365412\n",
      ">>>>>step_norm<<<<<< 0.6292086439232428\n",
      ">>>>>step_norm<<<<<< 0.6423031197713261\n",
      ">>>>>step_norm<<<<<< 1.1629646510211946\n",
      ">>>>>step_norm<<<<<< 0.524272094828574\n",
      ">>>>>step_norm<<<<<< 0.8245852490321471\n",
      ">>>>>step_norm<<<<<< 0.9328259582067054\n",
      ">>>>>step_norm<<<<<< 0.38227470736343755\n",
      ">>>>>step_norm<<<<<< 0.4886253144984954\n",
      ">>>>>step_norm<<<<<< 0.15384523675905784\n",
      ">>>>>step_norm<<<<<< 0.5570996435084778\n",
      ">>>>>step_norm<<<<<< 0.28526852701981853\n",
      ">>>>>step_norm<<<<<< 0.7819835709082095\n",
      ">>>>>step_norm<<<<<< 0.7815793767188911\n",
      ">>>>>step_norm<<<<<< 0.45706108264853185\n",
      ">>>>>step_norm<<<<<< 0.3870992570498995\n",
      ">>>>>step_norm<<<<<< 0.6440038048720137\n",
      ">>>>>step_norm<<<<<< 0.8134960863699109\n",
      ">>>>>step_norm<<<<<< 0.4221089970039717\n",
      ">>>>>step_norm<<<<<< 0.6995268338655529\n",
      ">>>>>step_norm<<<<<< 0.5956993227423545\n",
      ">>>>>step_norm<<<<<< 0.5105153626755982\n",
      ">>>>>step_norm<<<<<< 0.28306930147476916\n",
      ">>>>>step_norm<<<<<< 0.3202095847016044\n",
      ">>>>>step_norm<<<<<< 0.516462684201768\n",
      ">>>>>step_norm<<<<<< 0.49567223368036534\n",
      ">>>>>step_norm<<<<<< 0.34322041983929286\n",
      ">>>>>step_norm<<<<<< 0.2995581051592867\n",
      ">>>>>step_norm<<<<<< 1.4472814547082025\n",
      ">>>>>step_norm<<<<<< 0.5267675061002866\n",
      ">>>>>step_norm<<<<<< 0.39189714579315493\n",
      ">>>>>step_norm<<<<<< 0.24131797689509715\n",
      ">>>>>step_norm<<<<<< 0.6175287377997322\n",
      ">>>>>step_norm<<<<<< 0.31065632996423037\n",
      ">>>>>step_norm<<<<<< 0.25195749225715425\n",
      ">>>>>step_norm<<<<<< 1.0395730327042165\n",
      ">>>>>step_norm<<<<<< 0.5050797926998092\n",
      ">>>>>step_norm<<<<<< 0.586605586093638\n",
      ">>>>>step_norm<<<<<< 0.5214085742923126\n",
      ">>>>>step_norm<<<<<< 0.8811448018310695\n",
      ">>>>>step_norm<<<<<< 0.40928829082536367\n",
      ">>>>>step_norm<<<<<< 0.34188536494471167\n",
      ">>>>>step_norm<<<<<< 0.687996185721773\n",
      ">>>>>step_norm<<<<<< 0.4388771793722331\n",
      ">>>>>step_norm<<<<<< 0.3257847503658709\n",
      ">>>>>step_norm<<<<<< 0.3637015829609307\n",
      ">>>>>step_norm<<<<<< 0.21515998859238136\n",
      ">>>>>step_norm<<<<<< 0.20672616813083444\n",
      ">>>>>step_norm<<<<<< 0.6489885601318706\n",
      ">>>>>step_norm<<<<<< 0.7555619514509713\n",
      ">>>>>step_norm<<<<<< 0.3880963576069962\n",
      ">>>>>step_norm<<<<<< 0.25981887371274415\n",
      ">>>>>step_norm<<<<<< 0.30734811395897293\n",
      ">>>>>step_norm<<<<<< 0.6163491365632412\n",
      ">>>>>step_norm<<<<<< 0.4173240491665931\n",
      ">>>>>step_norm<<<<<< 0.48672268949601855\n",
      ">>>>>step_norm<<<<<< 0.3005248347280612\n",
      ">>>>>step_norm<<<<<< 0.27723225607557267\n",
      ">>>>>step_norm<<<<<< 0.6175902379105574\n",
      ">>>>>step_norm<<<<<< 0.23150792752061258\n",
      ">>>>>step_norm<<<<<< 0.37580516637717254\n",
      ">>>>>step_norm<<<<<< 1.11857393684237\n",
      ">>>>>step_norm<<<<<< 0.20507241118168631\n",
      ">>>>>step_norm<<<<<< 0.47999154572253067\n",
      ">>>>>step_norm<<<<<< 0.32478700159410556\n",
      ">>>>>step_norm<<<<<< 0.4246039967181067\n",
      ">>>>>step_norm<<<<<< 0.6693828714670427\n",
      ">>>>>step_norm<<<<<< 0.4245897247916576\n",
      ">>>>>step_norm<<<<<< 0.7290377830688924\n",
      ">>>>>step_norm<<<<<< 0.1565800225792947\n",
      ">>>>>step_norm<<<<<< 0.6442197962761848\n",
      ">>>>>step_norm<<<<<< 0.7504181713544228\n",
      ">>>>>step_norm<<<<<< 1.575298022219423\n",
      ">>>>>step_norm<<<<<< 0.6455759899010034\n",
      ">>>>>step_norm<<<<<< 0.47959609249688007\n",
      ">>>>>step_norm<<<<<< 0.304953265625424\n",
      ">>>>>step_norm<<<<<< 0.31694287280664096\n",
      ">>>>>step_norm<<<<<< 0.3496032961231096\n",
      ">>>>>step_norm<<<<<< 0.5366040588704669\n",
      ">>>>>step_norm<<<<<< 0.2966714034650127\n",
      ">>>>>step_norm<<<<<< 0.882023934886063\n",
      ">>>>>step_norm<<<<<< 0.37716276448506186\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 18\n",
      ">>>>>step_norm<<<<<< 0.4314659700207026\n",
      ">>>>>step_norm<<<<<< 0.889326023057143\n",
      ">>>>>step_norm<<<<<< 0.6711581116095172\n",
      ">>>>>step_norm<<<<<< 0.7310059090819794\n",
      ">>>>>step_norm<<<<<< 0.3458217127967882\n",
      ">>>>>step_norm<<<<<< 0.3172406403837045\n",
      ">>>>>step_norm<<<<<< 0.3570754896380111\n",
      ">>>>>step_norm<<<<<< 0.4093807255662431\n",
      ">>>>>step_norm<<<<<< 1.1608537168038706\n",
      ">>>>>step_norm<<<<<< 0.7833591683087011\n",
      ">>>>>step_norm<<<<<< 0.6047105403558671\n",
      ">>>>>step_norm<<<<<< 0.391566195461575\n",
      ">>>>>step_norm<<<<<< 0.3961114720977456\n",
      ">>>>>step_norm<<<<<< 0.8090341233138885\n",
      ">>>>>step_norm<<<<<< 0.2922767603541242\n",
      ">>>>>step_norm<<<<<< 0.387167375466195\n",
      ">>>>>step_norm<<<<<< 0.23484921629382394\n",
      ">>>>>step_norm<<<<<< 0.7597422581455282\n",
      ">>>>>step_norm<<<<<< 0.36911245494114747\n",
      ">>>>>step_norm<<<<<< 0.4640689243038213\n",
      ">>>>>step_norm<<<<<< 0.7774969304198274\n",
      ">>>>>step_norm<<<<<< 0.621776346594499\n",
      ">>>>>step_norm<<<<<< 0.3845539238877101\n",
      ">>>>>step_norm<<<<<< 0.49411209736389583\n",
      ">>>>>step_norm<<<<<< 0.6248343830001163\n",
      ">>>>>step_norm<<<<<< 0.47668048173355404\n",
      ">>>>>step_norm<<<<<< 0.7626234839512451\n",
      ">>>>>step_norm<<<<<< 0.3668050544904495\n",
      ">>>>>step_norm<<<<<< 0.5810338156068753\n",
      ">>>>>step_norm<<<<<< 0.26686208290692937\n",
      ">>>>>step_norm<<<<<< 0.33376183394984166\n",
      ">>>>>step_norm<<<<<< 1.0853641145676292\n",
      ">>>>>step_norm<<<<<< 0.3948025364954162\n",
      ">>>>>step_norm<<<<<< 0.2926330099077195\n",
      ">>>>>step_norm<<<<<< 0.9746165318392942\n",
      ">>>>>step_norm<<<<<< 0.632966376907405\n",
      ">>>>>step_norm<<<<<< 0.49916317056231896\n",
      ">>>>>step_norm<<<<<< 0.32537419740779117\n",
      ">>>>>step_norm<<<<<< 0.5912104950521144\n",
      ">>>>>step_norm<<<<<< 0.33323754876134987\n",
      ">>>>>step_norm<<<<<< 0.6553913320390962\n",
      ">>>>>step_norm<<<<<< 0.9431306043558092\n",
      ">>>>>step_norm<<<<<< 1.1060575397015209\n",
      ">>>>>step_norm<<<<<< 0.7148138940539193\n",
      ">>>>>step_norm<<<<<< 0.4465805169198756\n",
      ">>>>>step_norm<<<<<< 0.49022693996967875\n",
      ">>>>>step_norm<<<<<< 1.0199214783479658\n",
      ">>>>>step_norm<<<<<< 0.43833084328439087\n",
      ">>>>>step_norm<<<<<< 0.5443259217145651\n",
      ">>>>>step_norm<<<<<< 0.8264699458572039\n",
      ">>>>>step_norm<<<<<< 0.5227477679987784\n",
      ">>>>>step_norm<<<<<< 0.3659643005006855\n",
      ">>>>>step_norm<<<<<< 0.42193371274108743\n",
      ">>>>>step_norm<<<<<< 0.6884500533680648\n",
      ">>>>>step_norm<<<<<< 0.5935303492580243\n",
      ">>>>>step_norm<<<<<< 0.6104333669162421\n",
      ">>>>>step_norm<<<<<< 0.2277803017102962\n",
      ">>>>>step_norm<<<<<< 0.40265203434685515\n",
      ">>>>>step_norm<<<<<< 0.4937138077757055\n",
      ">>>>>step_norm<<<<<< 0.2544746823119366\n",
      ">>>>>step_norm<<<<<< 0.5296995134705256\n",
      ">>>>>step_norm<<<<<< 0.9059656177254497\n",
      ">>>>>step_norm<<<<<< 0.3807589673432933\n",
      ">>>>>step_norm<<<<<< 0.37887458330665824\n",
      ">>>>>step_norm<<<<<< 0.32511283665127966\n",
      ">>>>>step_norm<<<<<< 0.17869637233494098\n",
      ">>>>>step_norm<<<<<< 0.8020223604412441\n",
      ">>>>>step_norm<<<<<< 0.15850035900118772\n",
      ">>>>>step_norm<<<<<< 1.0085603006259718\n",
      ">>>>>step_norm<<<<<< 0.5107463652282955\n",
      ">>>>>step_norm<<<<<< 0.555656344597974\n",
      ">>>>>step_norm<<<<<< 0.9545704359921964\n",
      ">>>>>step_norm<<<<<< 1.0805106086314296\n",
      ">>>>>step_norm<<<<<< 0.9873530697110465\n",
      ">>>>>step_norm<<<<<< 0.5729511558407601\n",
      ">>>>>step_norm<<<<<< 0.8445939206411258\n",
      ">>>>>step_norm<<<<<< 0.47359845493514313\n",
      ">>>>>step_norm<<<<<< 0.3549595140166987\n",
      ">>>>>step_norm<<<<<< 0.3180167852464269\n",
      ">>>>>step_norm<<<<<< 0.2957753297175922\n",
      ">>>>>step_norm<<<<<< 0.46539208222243594\n",
      ">>>>>step_norm<<<<<< 0.5376307955957517\n",
      ">>>>>step_norm<<<<<< 0.3702179943973302\n",
      ">>>>>step_norm<<<<<< 1.1287910345097742\n",
      ">>>>>step_norm<<<<<< 0.7642986546567255\n",
      ">>>>>step_norm<<<<<< 0.5500840341544864\n",
      ">>>>>step_norm<<<<<< 0.2556096348275615\n",
      ">>>>>step_norm<<<<<< 0.47718287576669854\n",
      ">>>>>step_norm<<<<<< 0.8761101530332175\n",
      ">>>>>step_norm<<<<<< 0.46996828539129576\n",
      ">>>>>step_norm<<<<<< 1.780851265893715\n",
      ">>>>>step_norm<<<<<< 0.9435750556911049\n",
      ">>>>>step_norm<<<<<< 0.32229684391721486\n",
      ">>>>>step_norm<<<<<< 0.34480852354287905\n",
      ">>>>>step_norm<<<<<< 0.7839464030848705\n",
      ">>>>>step_norm<<<<<< 0.35850218222661256\n",
      ">>>>>step_norm<<<<<< 0.3311910793139502\n",
      ">>>>>step_norm<<<<<< 0.41737298847941834\n",
      ">>>>>step_norm<<<<<< 0.3705280927231109\n",
      ">>>>>step_norm<<<<<< 0.8961335772496524\n",
      ">>>>>step_norm<<<<<< 0.571909965379402\n",
      ">>>>>step_norm<<<<<< 0.3396457283739084\n",
      ">>>>>step_norm<<<<<< 0.7638687071536162\n",
      ">>>>>step_norm<<<<<< 0.7413947291102605\n",
      ">>>>>step_norm<<<<<< 0.36523905637674653\n",
      ">>>>>step_norm<<<<<< 0.8945992161021876\n",
      ">>>>>step_norm<<<<<< 0.6133198722377093\n",
      ">>>>>step_norm<<<<<< 0.7924857288203099\n",
      ">>>>>step_norm<<<<<< 0.5262281824188965\n",
      ">>>>>step_norm<<<<<< 0.28349146356323035\n",
      ">>>>>step_norm<<<<<< 0.23620899582426602\n",
      ">>>>>step_norm<<<<<< 0.29074541399112547\n",
      ">>>>>step_norm<<<<<< 0.48984963429850875\n",
      ">>>>>step_norm<<<<<< 0.40536364149262044\n",
      ">>>>>step_norm<<<<<< 0.5161477524819197\n",
      ">>>>>step_norm<<<<<< 0.9826850763570735\n",
      ">>>>>step_norm<<<<<< 0.9975430254141883\n",
      ">>>>>step_norm<<<<<< 0.1998535313306843\n",
      ">>>>>step_norm<<<<<< 0.6523888231260777\n",
      ">>>>>step_norm<<<<<< 1.6816171297109184\n",
      ">>>>>step_norm<<<<<< 1.2428677685008644\n",
      ">>>>>step_norm<<<<<< 0.8174437582741313\n",
      ">>>>>step_norm<<<<<< 1.2401294441053587\n",
      ">>>>>step_norm<<<<<< 0.2769020939018465\n",
      ">>>>>step_norm<<<<<< 0.5004213422724646\n",
      ">>>>>step_norm<<<<<< 1.1810294220220567\n",
      ">>>>>step_norm<<<<<< 1.2676314331632812\n",
      ">>>>>step_norm<<<<<< 0.22524635243811653\n",
      ">>>>>step_norm<<<<<< 0.29940528704960806\n",
      ">>>>>step_norm<<<<<< 0.40402775578857475\n",
      ">>>>>step_norm<<<<<< 0.5759404571905713\n",
      ">>>>>step_norm<<<<<< 0.5409715321833267\n",
      ">>>>>step_norm<<<<<< 0.2452858152747873\n",
      ">>>>>step_norm<<<<<< 0.6450047490918697\n",
      ">>>>>step_norm<<<<<< 0.6656929303890518\n",
      ">>>>>step_norm<<<<<< 0.3252495664253208\n",
      ">>>>>step_norm<<<<<< 0.542114874587709\n",
      ">>>>>step_norm<<<<<< 0.9480163722519643\n",
      ">>>>>step_norm<<<<<< 0.3432344695106775\n",
      ">>>>>step_norm<<<<<< 0.8372120621484881\n",
      ">>>>>step_norm<<<<<< 0.40539255524596723\n",
      ">>>>>step_norm<<<<<< 0.21881415959297418\n",
      ">>>>>step_norm<<<<<< 0.6036702953312915\n",
      ">>>>>step_norm<<<<<< 0.5222241770963254\n",
      ">>>>>step_norm<<<<<< 0.13781520607335832\n",
      ">>>>>step_norm<<<<<< 0.3095297060375093\n",
      ">>>>>step_norm<<<<<< 0.7750926249788906\n",
      ">>>>>step_norm<<<<<< 0.37485086544285434\n",
      ">>>>>step_norm<<<<<< 0.6409761141912813\n",
      ">>>>>step_norm<<<<<< 0.49562109452974185\n",
      ">>>>>step_norm<<<<<< 0.3654509341628541\n",
      ">>>>>step_norm<<<<<< 0.7689398820525136\n",
      ">>>>>step_norm<<<<<< 0.5502834697158344\n",
      ">>>>>step_norm<<<<<< 0.8613702132405082\n",
      ">>>>>step_norm<<<<<< 0.4505492751535214\n",
      ">>>>>step_norm<<<<<< 0.8816838832917298\n",
      ">>>>>step_norm<<<<<< 0.596160341008793\n",
      ">>>>>step_norm<<<<<< 1.4308948987450556\n",
      ">>>>>step_norm<<<<<< 0.2395970428369855\n",
      ">>>>>step_norm<<<<<< 0.7212746567810125\n",
      ">>>>>step_norm<<<<<< 0.5911153511100232\n",
      ">>>>>step_norm<<<<<< 0.42868249465227815\n",
      ">>>>>step_norm<<<<<< 0.2505607775304435\n",
      ">>>>>step_norm<<<<<< 0.48502148305771153\n",
      ">>>>>step_norm<<<<<< 0.28932795130775707\n",
      ">>>>>step_norm<<<<<< 0.3661950202020523\n",
      ">>>>>step_norm<<<<<< 0.3083818868631112\n",
      ">>>>>step_norm<<<<<< 0.2712797925704897\n",
      ">>>>>step_norm<<<<<< 0.4659093620585051\n",
      ">>>>>step_norm<<<<<< 1.1603540278725433\n",
      ">>>>>step_norm<<<<<< 0.2813891299171829\n",
      ">>>>>step_norm<<<<<< 0.6160182557935686\n",
      ">>>>>step_norm<<<<<< 0.5861329577505541\n",
      ">>>>>step_norm<<<<<< 0.25936921641483124\n",
      ">>>>>step_norm<<<<<< 0.18337679329932183\n",
      ">>>>>step_norm<<<<<< 0.9958089558218057\n",
      ">>>>>step_norm<<<<<< 1.054068863649571\n",
      ">>>>>step_norm<<<<<< 0.60282039640013\n",
      ">>>>>step_norm<<<<<< 1.1492487531226963\n",
      ">>>>>step_norm<<<<<< 0.3358585315295638\n",
      ">>>>>step_norm<<<<<< 0.27699457470224115\n",
      ">>>>>step_norm<<<<<< 0.4404923650977093\n",
      ">>>>>step_norm<<<<<< 0.9191191012710719\n",
      ">>>>>step_norm<<<<<< 1.1209048311262615\n",
      ">>>>>step_norm<<<<<< 0.38585040543796506\n",
      ">>>>>step_norm<<<<<< 1.0897219700652097\n",
      ">>>>>step_norm<<<<<< 0.8791935855502462\n",
      ">>>>>step_norm<<<<<< 1.6286482209816895\n",
      ">>>>>step_norm<<<<<< 1.3711342725537892\n",
      ">>>>>step_norm<<<<<< 1.113509774596262\n",
      ">>>>>step_norm<<<<<< 0.14906909246648156\n",
      ">>>>>step_norm<<<<<< 0.2712558727469729\n",
      ">>>>>step_norm<<<<<< 0.31922927455419237\n",
      ">>>>>step_norm<<<<<< 0.5028775592550478\n",
      ">>>>>step_norm<<<<<< 0.45483999757045335\n",
      ">>>>>step_norm<<<<<< 0.24511739108493077\n",
      ">>>>>step_norm<<<<<< 0.7255963658450294\n",
      ">>>>>step_norm<<<<<< 0.6508045126066493\n",
      ">>>>>step_norm<<<<<< 0.2579564379741943\n",
      ">>>>>step_norm<<<<<< 1.0460820942713251\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 19\n",
      ">>>>>step_norm<<<<<< 0.4095391368010823\n",
      ">>>>>step_norm<<<<<< 0.5095465717969102\n",
      ">>>>>step_norm<<<<<< 0.7107764576369674\n",
      ">>>>>step_norm<<<<<< 1.12362918993626\n",
      ">>>>>step_norm<<<<<< 0.7167617550391603\n",
      ">>>>>step_norm<<<<<< 0.38922847175383174\n",
      ">>>>>step_norm<<<<<< 0.7361971739841124\n",
      ">>>>>step_norm<<<<<< 0.6628430600968405\n",
      ">>>>>step_norm<<<<<< 0.3060682038131635\n",
      ">>>>>step_norm<<<<<< 0.6269025863257657\n",
      ">>>>>step_norm<<<<<< 0.6677278971315541\n",
      ">>>>>step_norm<<<<<< 0.3111265966207331\n",
      ">>>>>step_norm<<<<<< 0.31876609867672123\n",
      ">>>>>step_norm<<<<<< 0.569424641561062\n",
      ">>>>>step_norm<<<<<< 0.6514269076148669\n",
      ">>>>>step_norm<<<<<< 0.5465847465760107\n",
      ">>>>>step_norm<<<<<< 0.911898276162365\n",
      ">>>>>step_norm<<<<<< 0.5384949539017033\n",
      ">>>>>step_norm<<<<<< 1.0537869112110618\n",
      ">>>>>step_norm<<<<<< 0.9341092983865668\n",
      ">>>>>step_norm<<<<<< 0.42888598095694325\n",
      ">>>>>step_norm<<<<<< 0.3311813591434634\n",
      ">>>>>step_norm<<<<<< 0.49951455827880725\n",
      ">>>>>step_norm<<<<<< 0.27654795785558106\n",
      ">>>>>step_norm<<<<<< 0.5207947098946341\n",
      ">>>>>step_norm<<<<<< 0.36432625326693\n",
      ">>>>>step_norm<<<<<< 0.3510521442953782\n",
      ">>>>>step_norm<<<<<< 1.2548610977938706\n",
      ">>>>>step_norm<<<<<< 0.4332068909507368\n",
      ">>>>>step_norm<<<<<< 0.5685809733958774\n",
      ">>>>>step_norm<<<<<< 0.40339568512410523\n",
      ">>>>>step_norm<<<<<< 0.4067530022099823\n",
      ">>>>>step_norm<<<<<< 0.2635096986491837\n",
      ">>>>>step_norm<<<<<< 1.0435987031683305\n",
      ">>>>>step_norm<<<<<< 1.264306756717103\n",
      ">>>>>step_norm<<<<<< 0.6528166308257166\n",
      ">>>>>step_norm<<<<<< 0.36257406693458255\n",
      ">>>>>step_norm<<<<<< 0.444753218139083\n",
      ">>>>>step_norm<<<<<< 0.944161320122567\n",
      ">>>>>step_norm<<<<<< 0.7097514452872951\n",
      ">>>>>step_norm<<<<<< 0.6060952518369576\n",
      ">>>>>step_norm<<<<<< 0.3863707748664286\n",
      ">>>>>step_norm<<<<<< 0.28246703409612967\n",
      ">>>>>step_norm<<<<<< 0.567850171381472\n",
      ">>>>>step_norm<<<<<< 0.34199329271550655\n",
      ">>>>>step_norm<<<<<< 1.0470480173802221\n",
      ">>>>>step_norm<<<<<< 0.6433785938679667\n",
      ">>>>>step_norm<<<<<< 0.9957063292589702\n",
      ">>>>>step_norm<<<<<< 0.5963205252582707\n",
      ">>>>>step_norm<<<<<< 0.541517145740253\n",
      ">>>>>step_norm<<<<<< 0.7224149491050916\n",
      ">>>>>step_norm<<<<<< 0.6635632254680263\n",
      ">>>>>step_norm<<<<<< 0.839262728159127\n",
      ">>>>>step_norm<<<<<< 0.4379164943688283\n",
      ">>>>>step_norm<<<<<< 0.3437636707757692\n",
      ">>>>>step_norm<<<<<< 0.2448743077392552\n",
      ">>>>>step_norm<<<<<< 1.1132577488965851\n",
      ">>>>>step_norm<<<<<< 0.5843133405582407\n",
      ">>>>>step_norm<<<<<< 0.6829181281383772\n",
      ">>>>>step_norm<<<<<< 0.34813582422717426\n",
      ">>>>>step_norm<<<<<< 0.26979296628550514\n",
      ">>>>>step_norm<<<<<< 0.8650788160235904\n",
      ">>>>>step_norm<<<<<< 1.0080800183501897\n",
      ">>>>>step_norm<<<<<< 0.3950050089500446\n",
      ">>>>>step_norm<<<<<< 0.46260527212826646\n",
      ">>>>>step_norm<<<<<< 0.3650428154898619\n",
      ">>>>>step_norm<<<<<< 0.5913542579753033\n",
      ">>>>>step_norm<<<<<< 0.2642249266430729\n",
      ">>>>>step_norm<<<<<< 0.35678696359247664\n",
      ">>>>>step_norm<<<<<< 0.38298003034823536\n",
      ">>>>>step_norm<<<<<< 0.2530511617179894\n",
      ">>>>>step_norm<<<<<< 0.4562724639735807\n",
      ">>>>>step_norm<<<<<< 0.7536986812674638\n",
      ">>>>>step_norm<<<<<< 0.6657635970452005\n",
      ">>>>>step_norm<<<<<< 0.3325412673523859\n",
      ">>>>>step_norm<<<<<< 0.9299830754912919\n",
      ">>>>>step_norm<<<<<< 0.5997096050018461\n",
      ">>>>>step_norm<<<<<< 0.6744591850337234\n",
      ">>>>>step_norm<<<<<< 0.6658568764521824\n",
      ">>>>>step_norm<<<<<< 0.618682470632564\n",
      ">>>>>step_norm<<<<<< 0.6469050274193383\n",
      ">>>>>step_norm<<<<<< 0.5716117953770183\n",
      ">>>>>step_norm<<<<<< 1.1125209786016015\n",
      ">>>>>step_norm<<<<<< 0.6593007336804402\n",
      ">>>>>step_norm<<<<<< 0.661376200742473\n",
      ">>>>>step_norm<<<<<< 0.379222501725411\n",
      ">>>>>step_norm<<<<<< 0.309578057217691\n",
      ">>>>>step_norm<<<<<< 0.42149674776249396\n",
      ">>>>>step_norm<<<<<< 0.378493180500905\n",
      ">>>>>step_norm<<<<<< 0.2681227737733639\n",
      ">>>>>step_norm<<<<<< 0.7158879505428115\n",
      ">>>>>step_norm<<<<<< 0.7917810629220796\n",
      ">>>>>step_norm<<<<<< 0.9380142066686316\n",
      ">>>>>step_norm<<<<<< 0.9745928007774255\n",
      ">>>>>step_norm<<<<<< 0.5104291955405525\n",
      ">>>>>step_norm<<<<<< 0.29937038387085874\n",
      ">>>>>step_norm<<<<<< 0.3074296540019439\n",
      ">>>>>step_norm<<<<<< 0.609608320092546\n",
      ">>>>>step_norm<<<<<< 0.4027931522706965\n",
      ">>>>>step_norm<<<<<< 1.0337986200333125\n",
      ">>>>>step_norm<<<<<< 0.9320348871861548\n",
      ">>>>>step_norm<<<<<< 0.4544796458698189\n",
      ">>>>>step_norm<<<<<< 0.741714910312626\n",
      ">>>>>step_norm<<<<<< 0.27588105009426017\n",
      ">>>>>step_norm<<<<<< 0.819322140602253\n",
      ">>>>>step_norm<<<<<< 0.8695349949308685\n",
      ">>>>>step_norm<<<<<< 1.1684227401909146\n",
      ">>>>>step_norm<<<<<< 0.658903867292764\n",
      ">>>>>step_norm<<<<<< 0.294228572884817\n",
      ">>>>>step_norm<<<<<< 0.45888513507647233\n",
      ">>>>>step_norm<<<<<< 0.2092899475758802\n",
      ">>>>>step_norm<<<<<< 0.41671642406278814\n",
      ">>>>>step_norm<<<<<< 0.35268452019600094\n",
      ">>>>>step_norm<<<<<< 0.493507279790052\n",
      ">>>>>step_norm<<<<<< 0.8552648330143308\n",
      ">>>>>step_norm<<<<<< 0.4551915064792159\n",
      ">>>>>step_norm<<<<<< 0.6456154863953923\n",
      ">>>>>step_norm<<<<<< 0.5738207682931122\n",
      ">>>>>step_norm<<<<<< 0.8777837477731594\n",
      ">>>>>step_norm<<<<<< 0.1292029285783472\n",
      ">>>>>step_norm<<<<<< 0.8669993246793897\n",
      ">>>>>step_norm<<<<<< 1.043475240792782\n",
      ">>>>>step_norm<<<<<< 0.6314474765746063\n",
      ">>>>>step_norm<<<<<< 0.5001122897309549\n",
      ">>>>>step_norm<<<<<< 0.3619116989481409\n",
      ">>>>>step_norm<<<<<< 0.35619461405067127\n",
      ">>>>>step_norm<<<<<< 1.4416859087860265\n",
      ">>>>>step_norm<<<<<< 0.6374451456710067\n",
      ">>>>>step_norm<<<<<< 0.3942857201263897\n",
      ">>>>>step_norm<<<<<< 1.6047932553868618\n",
      ">>>>>step_norm<<<<<< 0.3350516644208833\n",
      ">>>>>step_norm<<<<<< 0.6001522415487884\n",
      ">>>>>step_norm<<<<<< 0.6192953573171991\n",
      ">>>>>step_norm<<<<<< 0.5745866638225273\n",
      ">>>>>step_norm<<<<<< 0.49172475102837204\n",
      ">>>>>step_norm<<<<<< 0.5022428695759962\n",
      ">>>>>step_norm<<<<<< 0.6708603327350046\n",
      ">>>>>step_norm<<<<<< 1.2623567752937164\n",
      ">>>>>step_norm<<<<<< 0.49423267452364167\n",
      ">>>>>step_norm<<<<<< 0.5540101390977804\n",
      ">>>>>step_norm<<<<<< 0.3046379295017153\n",
      ">>>>>step_norm<<<<<< 0.6650701071052194\n",
      ">>>>>step_norm<<<<<< 0.3286170840138004\n",
      ">>>>>step_norm<<<<<< 0.8016359334247259\n",
      ">>>>>step_norm<<<<<< 0.13460111087795368\n",
      ">>>>>step_norm<<<<<< 0.8706561745340138\n",
      ">>>>>step_norm<<<<<< 0.14723084630578442\n",
      ">>>>>step_norm<<<<<< 0.3450477281092897\n",
      ">>>>>step_norm<<<<<< 0.5065885295718002\n",
      ">>>>>step_norm<<<<<< 0.5015391708602055\n",
      ">>>>>step_norm<<<<<< 0.4467711360900488\n",
      ">>>>>step_norm<<<<<< 0.90057131470181\n",
      ">>>>>step_norm<<<<<< 0.32587049293031506\n",
      ">>>>>step_norm<<<<<< 0.3323453485752313\n",
      ">>>>>step_norm<<<<<< 0.3196744971498219\n",
      ">>>>>step_norm<<<<<< 0.25531512144779933\n",
      ">>>>>step_norm<<<<<< 0.38829575760338203\n",
      ">>>>>step_norm<<<<<< 1.5286840912469768\n",
      ">>>>>step_norm<<<<<< 0.18873661631157404\n",
      ">>>>>step_norm<<<<<< 0.22379469073290847\n",
      ">>>>>step_norm<<<<<< 0.9183784625581658\n",
      ">>>>>step_norm<<<<<< 0.7101630454332953\n",
      ">>>>>step_norm<<<<<< 0.46262942697471177\n",
      ">>>>>step_norm<<<<<< 0.6281261608497117\n",
      ">>>>>step_norm<<<<<< 0.2550688548752841\n",
      ">>>>>step_norm<<<<<< 0.37884009372438515\n",
      ">>>>>step_norm<<<<<< 0.3724036870649686\n",
      ">>>>>step_norm<<<<<< 0.31847595057546735\n",
      ">>>>>step_norm<<<<<< 0.5038949135097404\n",
      ">>>>>step_norm<<<<<< 0.9122804240297163\n",
      ">>>>>step_norm<<<<<< 0.3624534518847383\n",
      ">>>>>step_norm<<<<<< 0.6346395023939988\n",
      ">>>>>step_norm<<<<<< 0.4640578377146852\n",
      ">>>>>step_norm<<<<<< 0.3337440913326787\n",
      ">>>>>step_norm<<<<<< 1.0987008185006844\n",
      ">>>>>step_norm<<<<<< 0.9123801918318312\n",
      ">>>>>step_norm<<<<<< 0.29200513343808493\n",
      ">>>>>step_norm<<<<<< 0.2531318199742285\n",
      ">>>>>step_norm<<<<<< 0.39271569072274237\n",
      ">>>>>step_norm<<<<<< 0.6138341347563527\n",
      ">>>>>step_norm<<<<<< 0.7734530684240678\n",
      ">>>>>step_norm<<<<<< 0.33368476524761426\n",
      ">>>>>step_norm<<<<<< 0.43181274875959896\n",
      ">>>>>step_norm<<<<<< 1.6573504127647953\n",
      ">>>>>step_norm<<<<<< 0.37640752426156177\n",
      ">>>>>step_norm<<<<<< 1.3238973709156516\n",
      ">>>>>step_norm<<<<<< 0.3196260479643392\n",
      ">>>>>step_norm<<<<<< 0.3474638134149209\n",
      ">>>>>step_norm<<<<<< 0.26029352563142594\n",
      ">>>>>step_norm<<<<<< 0.47262782277457666\n",
      ">>>>>step_norm<<<<<< 0.508764213277113\n",
      ">>>>>step_norm<<<<<< 0.4923340901070786\n",
      ">>>>>step_norm<<<<<< 0.2855122848832781\n",
      ">>>>>step_norm<<<<<< 0.5204396737259127\n",
      ">>>>>step_norm<<<<<< 0.5579039006234228\n",
      ">>>>>step_norm<<<<<< 0.22291114313742283\n",
      ">>>>>step_norm<<<<<< 0.5927800408057178\n",
      ">>>>>step_norm<<<<<< 0.45308750355681865\n",
      ">>>>>step_norm<<<<<< 0.4542328524399238\n",
      ">>>>>step_norm<<<<<< 0.6472748056144672\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL 20\n",
      ">>>>>step_norm<<<<<< 0.32320238248432953\n",
      ">>>>>step_norm<<<<<< 0.5040102912134841\n",
      ">>>>>step_norm<<<<<< 0.9548717879139024\n",
      ">>>>>step_norm<<<<<< 0.6655978960128296\n",
      ">>>>>step_norm<<<<<< 0.6044138496049283\n",
      ">>>>>step_norm<<<<<< 0.6703832899052933\n",
      ">>>>>step_norm<<<<<< 0.7127414514714501\n",
      ">>>>>step_norm<<<<<< 0.5000466972341481\n",
      ">>>>>step_norm<<<<<< 0.7401884608685445\n",
      ">>>>>step_norm<<<<<< 1.2471910231736074\n",
      ">>>>>step_norm<<<<<< 0.5148577196573372\n",
      ">>>>>step_norm<<<<<< 1.5023220714708334\n",
      ">>>>>step_norm<<<<<< 0.291552370155697\n",
      ">>>>>step_norm<<<<<< 0.725167576594768\n",
      ">>>>>step_norm<<<<<< 0.3263834364245804\n",
      ">>>>>step_norm<<<<<< 0.6837434249183598\n",
      ">>>>>step_norm<<<<<< 0.471376128014519\n",
      ">>>>>step_norm<<<<<< 0.5819006948320506\n",
      ">>>>>step_norm<<<<<< 0.7160175534451966\n",
      ">>>>>step_norm<<<<<< 0.8593689777576072\n",
      ">>>>>step_norm<<<<<< 0.2946669456181799\n",
      ">>>>>step_norm<<<<<< 0.6433328704442753\n",
      ">>>>>step_norm<<<<<< 0.3948606758746332\n",
      ">>>>>step_norm<<<<<< 2.1228491180869544\n",
      ">>>>>step_norm<<<<<< 1.050355844965849\n",
      ">>>>>step_norm<<<<<< 0.3714044647356573\n",
      ">>>>>step_norm<<<<<< 1.2246556262886152\n",
      ">>>>>step_norm<<<<<< 1.6378450280760923\n",
      ">>>>>step_norm<<<<<< 0.8311365403453111\n",
      ">>>>>step_norm<<<<<< 0.4771717176102939\n",
      ">>>>>step_norm<<<<<< 4.244810394198124\n",
      ">>>>>step_norm<<<<<< 0.8403493001513181\n",
      ">>>>>step_norm<<<<<< 0.47521414914155446\n",
      ">>>>>step_norm<<<<<< 0.4667320236220687\n",
      ">>>>>step_norm<<<<<< 0.6218061745948584\n",
      ">>>>>step_norm<<<<<< 1.2730564464198746\n",
      ">>>>>step_norm<<<<<< 0.4959698306416389\n",
      ">>>>>step_norm<<<<<< 0.4759077010740195\n",
      ">>>>>step_norm<<<<<< 0.6040716833766788\n",
      ">>>>>step_norm<<<<<< 0.8888026434236431\n",
      ">>>>>step_norm<<<<<< 0.9948186866470208\n",
      ">>>>>step_norm<<<<<< 2.519559732581883\n",
      ">>>>>step_norm<<<<<< 1.360310193317483\n",
      ">>>>>step_norm<<<<<< 0.37259738947210175\n",
      ">>>>>step_norm<<<<<< 0.410833760298516\n",
      ">>>>>step_norm<<<<<< 0.41601432501797425\n",
      ">>>>>step_norm<<<<<< 0.4714655263683928\n",
      ">>>>>step_norm<<<<<< 0.3558839598706399\n",
      ">>>>>step_norm<<<<<< 1.1713739060883641\n",
      ">>>>>step_norm<<<<<< 0.6410574064326586\n",
      ">>>>>step_norm<<<<<< 0.5267251650200463\n",
      ">>>>>step_norm<<<<<< 0.4522854505983676\n",
      ">>>>>step_norm<<<<<< 0.9086410091266541\n",
      ">>>>>step_norm<<<<<< 0.4144837353075209\n",
      ">>>>>step_norm<<<<<< 0.9014024549499166\n",
      ">>>>>step_norm<<<<<< 0.9541034949008325\n",
      ">>>>>step_norm<<<<<< 0.6582160898262268\n",
      ">>>>>step_norm<<<<<< 1.5339139930839345\n",
      ">>>>>step_norm<<<<<< 1.318304428303328\n",
      ">>>>>step_norm<<<<<< 0.7607165835667288\n",
      ">>>>>step_norm<<<<<< 0.384454083722334\n",
      ">>>>>step_norm<<<<<< 0.47573703187213534\n",
      ">>>>>step_norm<<<<<< 0.8551190896374697\n",
      ">>>>>step_norm<<<<<< 0.4495624598570284\n",
      ">>>>>step_norm<<<<<< 0.4182168586211498\n",
      ">>>>>step_norm<<<<<< 1.135142798244362\n",
      ">>>>>step_norm<<<<<< 0.6282815869792726\n",
      ">>>>>step_norm<<<<<< 0.95695107310546\n",
      ">>>>>step_norm<<<<<< 1.7681838898362385\n",
      ">>>>>step_norm<<<<<< 1.6317474550139837\n",
      ">>>>>step_norm<<<<<< 0.9974370426262766\n",
      ">>>>>step_norm<<<<<< 0.878013929316793\n",
      ">>>>>step_norm<<<<<< 0.9526051213365471\n",
      ">>>>>step_norm<<<<<< 2.3091597308223717\n",
      ">>>>>step_norm<<<<<< 0.6474803887137268\n",
      ">>>>>step_norm<<<<<< 1.5141285082789584\n",
      ">>>>>step_norm<<<<<< 1.089660700311075\n",
      ">>>>>step_norm<<<<<< 1.121290526879724\n",
      ">>>>>step_norm<<<<<< 0.9190812664672937\n",
      ">>>>>step_norm<<<<<< 1.2181075712489315\n",
      ">>>>>step_norm<<<<<< 3.14436708479498\n",
      ">>>>>step_norm<<<<<< 1.7275569984185557\n",
      ">>>>>step_norm<<<<<< 0.6117883509627676\n",
      ">>>>>step_norm<<<<<< 1.3376983866525436\n",
      ">>>>>step_norm<<<<<< 0.6273799670305671\n",
      ">>>>>step_norm<<<<<< 1.26928226997876\n",
      ">>>>>step_norm<<<<<< 0.5536388520673567\n",
      ">>>>>step_norm<<<<<< 0.3197527501804757\n",
      ">>>>>step_norm<<<<<< 12.710535615468544\n",
      ">>>>>step_norm<<<<<< 0.8043615494976497\n",
      ">>>>>step_norm<<<<<< 0.4983450858418041\n",
      ">>>>>step_norm<<<<<< 0.6007851103457504\n",
      ">>>>>step_norm<<<<<< 0.34726290705710605\n",
      ">>>>>step_norm<<<<<< 0.3115636056133727\n",
      ">>>>>step_norm<<<<<< 0.17079177152997346\n",
      ">>>>>step_norm<<<<<< 0.36910479168240307\n",
      ">>>>>step_norm<<<<<< 0.493897362740369\n",
      ">>>>>step_norm<<<<<< 1.0047109466931226\n",
      ">>>>>step_norm<<<<<< 0.4368036185896884\n",
      ">>>>>step_norm<<<<<< 0.46560590858590584\n",
      ">>>>>step_norm<<<<<< 5.589194768106742\n",
      ">>>>>step_norm<<<<<< 0.7229554384879425\n",
      ">>>>>step_norm<<<<<< 0.5089158076094045\n",
      ">>>>>step_norm<<<<<< 0.3078851590081381\n",
      ">>>>>step_norm<<<<<< 0.6405997725792685\n",
      ">>>>>step_norm<<<<<< 1.2372438120313607\n",
      ">>>>>step_norm<<<<<< 0.6070200639261902\n",
      ">>>>>step_norm<<<<<< 1.7585386645244108\n",
      ">>>>>step_norm<<<<<< 0.6152253938491906\n",
      ">>>>>step_norm<<<<<< 5.677456946426465\n",
      ">>>>>step_norm<<<<<< 0.7859161322778541\n",
      ">>>>>step_norm<<<<<< 0.7748273707872896\n",
      ">>>>>step_norm<<<<<< 0.916515775783282\n",
      ">>>>>step_norm<<<<<< 1.2758775596689476\n",
      ">>>>>step_norm<<<<<< 0.8871777903186383\n",
      ">>>>>step_norm<<<<<< 0.5451490095389138\n",
      ">>>>>step_norm<<<<<< 0.3937311300945347\n",
      ">>>>>step_norm<<<<<< 0.9988402185847777\n",
      ">>>>>step_norm<<<<<< 2.7586773787218672\n",
      ">>>>>step_norm<<<<<< 0.4403158730694489\n",
      ">>>>>step_norm<<<<<< 0.703316654500268\n",
      ">>>>>step_norm<<<<<< 1.4903069353377618\n",
      ">>>>>step_norm<<<<<< 1.0479434700733277\n",
      ">>>>>step_norm<<<<<< 0.33606638167870906\n",
      ">>>>>step_norm<<<<<< 0.8024562064769476\n",
      ">>>>>step_norm<<<<<< 0.3486837445377176\n",
      ">>>>>step_norm<<<<<< 0.6291185673195954\n",
      ">>>>>step_norm<<<<<< 1.2229566674765675\n",
      ">>>>>step_norm<<<<<< 0.3563440424851158\n",
      ">>>>>step_norm<<<<<< 0.1824012914164135\n",
      ">>>>>step_norm<<<<<< 0.8005081962972469\n",
      ">>>>>step_norm<<<<<< 0.3034944186984421\n",
      ">>>>>step_norm<<<<<< 0.4588021695103733\n",
      ">>>>>step_norm<<<<<< 0.8009782124945791\n",
      ">>>>>step_norm<<<<<< 0.8696495630733854\n",
      ">>>>>step_norm<<<<<< 0.29983257380126915\n",
      ">>>>>step_norm<<<<<< 0.6395483336534301\n",
      ">>>>>step_norm<<<<<< 0.2395511960833052\n",
      ">>>>>step_norm<<<<<< 0.8350605767508628\n",
      ">>>>>step_norm<<<<<< 0.8122380382172518\n",
      ">>>>>step_norm<<<<<< 0.3407043471792346\n",
      ">>>>>step_norm<<<<<< 0.2434676193993114\n",
      ">>>>>step_norm<<<<<< 0.3292543180760453\n",
      ">>>>>step_norm<<<<<< 0.8611897792769381\n",
      ">>>>>step_norm<<<<<< 0.47229434898514505\n",
      ">>>>>step_norm<<<<<< 0.3867587391228602\n",
      ">>>>>step_norm<<<<<< 0.2736359450890721\n",
      ">>>>>step_norm<<<<<< 0.32300585545890065\n",
      ">>>>>step_norm<<<<<< 0.35617311738293667\n",
      ">>>>>step_norm<<<<<< 0.5242862484873931\n",
      ">>>>>step_norm<<<<<< 0.571508167593976\n",
      ">>>>>step_norm<<<<<< 0.6819349786028022\n",
      ">>>>>step_norm<<<<<< 0.40467567920032843\n",
      ">>>>>step_norm<<<<<< 0.40760043068646806\n",
      ">>>>>step_norm<<<<<< 1.7496407444607052\n",
      ">>>>>step_norm<<<<<< 0.3329313167095934\n",
      ">>>>>step_norm<<<<<< 0.5651593066234706\n",
      ">>>>>step_norm<<<<<< 0.34656949751794036\n",
      ">>>>>step_norm<<<<<< 0.6379506301917872\n",
      ">>>>>step_norm<<<<<< 0.25564528770128636\n",
      ">>>>>step_norm<<<<<< 0.8029369885398243\n",
      ">>>>>step_norm<<<<<< 0.3384640858164994\n",
      ">>>>>step_norm<<<<<< 0.5855855629226533\n",
      ">>>>>step_norm<<<<<< 0.7901508990376491\n",
      ">>>>>step_norm<<<<<< 0.41840171456317926\n",
      ">>>>>step_norm<<<<<< 1.9401405325545757\n",
      ">>>>>step_norm<<<<<< 0.7937084408714381\n",
      ">>>>>step_norm<<<<<< 0.6591548720786646\n",
      ">>>>>step_norm<<<<<< 0.8353395932065526\n",
      ">>>>>step_norm<<<<<< 0.4337839695324594\n",
      ">>>>>step_norm<<<<<< 0.24996303442378787\n",
      ">>>>>step_norm<<<<<< 0.5558116317628033\n",
      ">>>>>step_norm<<<<<< 1.251632754740047\n",
      ">>>>>step_norm<<<<<< 0.2777057844152793\n",
      ">>>>>step_norm<<<<<< 0.9113511298070587\n",
      ">>>>>step_norm<<<<<< 4.076958164490678\n",
      ">>>>>step_norm<<<<<< 0.8989203313357877\n",
      ">>>>>step_norm<<<<<< 0.9485958785828577\n",
      ">>>>>step_norm<<<<<< 0.354253385642933\n",
      ">>>>>step_norm<<<<<< 0.2752207731942839\n",
      ">>>>>step_norm<<<<<< 0.9262176049385922\n",
      ">>>>>step_norm<<<<<< 0.8706639488886393\n",
      ">>>>>step_norm<<<<<< 0.6173398827023033\n",
      ">>>>>step_norm<<<<<< 2.6103448248555634\n",
      ">>>>>step_norm<<<<<< 1.1127409268642219\n",
      ">>>>>step_norm<<<<<< 0.8604826088161811\n",
      ">>>>>step_norm<<<<<< 0.28943527934522173\n",
      ">>>>>step_norm<<<<<< 0.17784430996578451\n",
      ">>>>>step_norm<<<<<< 0.48409600121945157\n",
      ">>>>>step_norm<<<<<< 0.28608501560219307\n",
      ">>>>>step_norm<<<<<< 0.8296380864001189\n",
      ">>>>>step_norm<<<<<< 0.8119700670761623\n",
      ">>>>>step_norm<<<<<< 0.7488867330136774\n",
      ">>>>>step_norm<<<<<< 0.5396265502590356\n",
      ">>>>>step_norm<<<<<< 1.542569916205465\n",
      ">>>>>step_norm<<<<<< 0.2658959105382059\n",
      ">>>>>step_norm<<<<<< 1.1361184063217373\n",
      ">>>>>step_norm<<<<<< 0.13204681171871455\n",
      ">>>>>step_norm<<<<<< 0.5682936145537818\n",
      ">>>>>step_norm<<<<<< 1.9336650343107773\n"
     ]
    }
   ],
   "source": [
    "######Training loop######\n",
    "trials = 21\n",
    "maxiter = 200\n",
    "acc_arr = []\n",
    "lossbound1 = 1e-1\n",
    "max_acc = 0\n",
    "ftrial = np.zeros((maxiter, trials))\n",
    "ctrial1 = np.zeros((maxiter, trials))\n",
    "ctrial2 = np.zeros((maxiter, trials))\n",
    "initsaved = []\n",
    "#x_train, x_val, y_train, y_val = train_test_split(in_df.values, out_df.values, test_size=0.3, random_state=42)\n",
    "ip_size = x_train.shape[1]\n",
    "#scaler = StandardScaler()\n",
    "#X_train = scaler.fit_transform(x_train)\n",
    "#X_val = scaler.transform(x_val)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "Y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "saved_model = []\n",
    "TPR_black = np.zeros(trials)\n",
    "TPR_white = np.zeros(trials)\n",
    "FPR_black = np.zeros(trials)\n",
    "FPR_white = np.zeros(trials)\n",
    "TNR_black = np.zeros(trials)\n",
    "FNR_black = np.zeros(trials)\n",
    "TNR_white = np.zeros(trials)\n",
    "FNR_white = np.zeros(trials)\n",
    "for trial in range(trials):\n",
    "    print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>TRIAL\", trial)\n",
    "    \n",
    "    #print(type(X_train))\n",
    "    hid_size1 = 16\n",
    "    hid_size2 = 16\n",
    "    op_size = 1\n",
    "    #print(X_val.shape)\n",
    "    #print(Y_val.shape)\n",
    "    layer_sizes = [ip_size, hid_size1, hid_size2, op_size]\n",
    "    \n",
    "    #x_len = x_train[:, 4]\n",
    "    num_trials = min(len(y_train[((x_train[:, RACE_IND]) == SENSITIVE_CODE_1)]), len(y_train[(x_train[:, RACE_IND] == SENSITIVE_CODE_0)]))\n",
    "\n",
    "    #num_trials = min(len(y_val[((x_val[:, 1]) == 0)]), len(y_val[(x_val[:, 1] == 1)]))\n",
    "    #num_trials = min((y_train.reshape(-1) == 0)]), len(y_train[(x_len == 1) & (y_train.reshape(-1) == 0)]))\n",
    "    #num_trials = len(y_val[(y_val.reshape(-1) == 1)])\n",
    "    #print(num_trials)\n",
    "    #print(num_trials)\n",
    "    net = CustomNetwork(\n",
    "        layer_sizes, X_train[:, :ip_size], Y_train, X_val[:, :ip_size], Y_val, torch.tensor(x_train))\n",
    "    #print(net)\n",
    "    # net.apply(net.init_weights)\n",
    "    nn_parameters = list(net.parameters())\n",
    "    # print(net)\n",
    "    initw = [param.data for param in nn_parameters]\n",
    "    # print(len(initw))\n",
    "    num_param = sum(p.numel() for p in net.parameters())\n",
    "    params = paramvals(maxiter=maxiter, beta=10., rho=3e-2, lamb=0.5, hess='diag', tau=1., mbsz=100,\n",
    "                       numcon=2, geomp=0.2, stepdecay='dimin', gammazero=0.1, zeta=0.1, N=num_trials, n=num_param, lossbound=[lossbound1, lossbound1], scalef=[1., 1.])\n",
    "    w, iterfs, itercs = StochasticGhost.StochasticGhost(\n",
    "        net.obj_fun, net.obj_grad, [net.conf1, net.conf2], [net.conJ1, net.conJ2], initw, params)\n",
    "    ftrial[:, trial] = iterfs\n",
    "    ctrial1[:, trial] = itercs[:,0]\n",
    "    ctrial2[:, trial] = itercs[:,1]\n",
    "\n",
    "    outputs = net.forward(X_val)\n",
    "    predictions = (outputs >= 0.5).float()\n",
    "    true = Y_val\n",
    "    #print(predictions.flatten())\n",
    "    #print(Y_val.flatten())\n",
    "    acc = len(np.where(predictions.flatten() == Y_val.flatten())[0]) / len(Y_val.flatten())\n",
    "    TP_black = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_1) & (np.array(predictions.flatten()).astype(int) == 1) & (y_val.flatten()==1))[0])\n",
    "    FN_black = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_1) & (np.array(predictions.flatten()).astype(int) == 0) & (y_val.flatten()==1))[0])\n",
    "\n",
    "    FP_black = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_1) & (np.array(predictions.flatten()).astype(int) == 1) & (y_val.flatten()==0))[0])\n",
    "    TN_black = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_1) & (np.array(predictions.flatten()).astype(int) == 0) & (y_val.flatten()==0))[0])\n",
    "    TPR_black[trial] = TP_black/(TP_black + FN_black)\n",
    "    FPR_black[trial] = FP_black/(FP_black + TN_black)\n",
    "    TNR_black[trial] = TN_black/(TN_black + FP_black)\n",
    "    FNR_black[trial] = FN_black/(FN_black + TP_black)\n",
    "\n",
    "    TP_white = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_0) & (np.array(predictions.flatten()).astype(int) == 1) & (y_val.flatten() == 1))[0])\n",
    "    FN_white = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_0) & (np.array(predictions.flatten()).astype(int) == 0) & (y_val.flatten() == 1))[0])\n",
    "\n",
    "    FP_white = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_0) & (np.array(predictions.flatten()).astype(int) == 1) & (y_val.flatten() == 0))[0])\n",
    "    TN_white = len(np.where((x_val[:, RACE_IND] == SENSITIVE_CODE_0) & (np.array(predictions.flatten()).astype(int) == 0) & (y_val.flatten() == 0))[0])\n",
    "    TPR_white[trial] = TP_white/(TP_white + FN_white)\n",
    "    FPR_white[trial] = FP_white/(FP_white + TN_white)\n",
    "    TNR_white[trial] = TN_white/(TN_white + FP_white)\n",
    "    FNR_white[trial] = FN_white/(FN_white + TP_white)\n",
    "    saved_model.append(net)\n",
    "    acc_arr.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(saved_model):\n",
    "    torch.save(model, 'compas_models/saved_model'+str(i)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(np.array(x_val), columns=[\n",
    "                      'priors_count', 'score_code', 'age_code', 'gender_code', 'race_code', 'crime_code', 'charge_degree_code'])\n",
    "df_out[\"pred_labels\"] = np.array(predictions).astype(int)\n",
    "df_out[\"true_labels\"] = np.array(true).astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ghost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
